
# 【ラビットチャレンジ】　応用数学

以下は、JDLA E資格の認定プログラム「ラビットチャレンジ」における応用数学のレポートである。  
次の３つの科目についてレポートにまとめた。

* 線形代数
* 確率・統計
* 情報理論

***
## 1. 線形代数
### 行列  

1. スカラーとベクトルの違い  
スカラーは、ただの数値。それに対し、ベクトルは、向きと大きさを持っている。

1. 行列とは  
スカラーを表にしたり、ベクトルを並べたもので、ベクトルの変換や連立方程式を解いたりできる。  

<img src="https://latex.codecogs.com/png.latex?{\color{White}\vec{x}&space;=&space;\binom{1}{2}"/>

### 逆行列・行列式  

1. 逆行列  
任意の行列Aがあるとすると、Aの逆数のようなもの。  
<img src="https://latex.codecogs.com/png.latex?\large&space;{\color{White}AA^{-1}=&space;A^{-1}A=&space;I"/>  
※A^-1を逆行列、Iを単位行列とする  
* 単位行列  
    <img src="https://latex.codecogs.com/png.latex?\large&space;{\color{White}I=&space;\begin{pmatrix}&space;1&space;&&space;0&space;&&space;\cdots&space;&&space;0&space;\\&space;0&space;&&space;1&space;&&space;\cdots&space;&&space;0&space;\\&space;\vdots&space;&&space;\vdots&space;&&space;\ddots&space;&0&space;\\&space;0&space;&&space;0&space;&&space;\cdots&space;&1&space;\end{pmatrix}"/>
    * 行列式  
    正方行列に対して、定義されるスカラー。逆行列が存在条件に利用できる。detAや|A|で表す。  

* 逆行列が存在しない場合  
逆数が存在しない数(0)はある。同様に、逆行列が存在しない場合もある。  
→例えば、解が存在しない連立方程式の場合。  
連立1次方程式で考えると、  
    * 2つの関数の傾きが同じ
    * 2つの関数が一致
    * 2つの関数のうち1つの関数がまったく情報を持たない（xやyにおける係数が0の場合）  
    などが存在する。これらを一般化すると、以下のようになる。  
    <img src="https://latex.codecogs.com/png.latex?\large&space;{\color{White}A=&space;\begin{pmatrix}&space;a&space;&&space;b&space;\\&space;c&space;&&space;d&space;\end{pmatrix}" />  
    において、a:b=c:dとなる場合（連立1次方程式が、平行である条件）、  
    a:b=c:d  
    ⇔ ad = bc  
    ⇔ ad - bc = 0  
    この場合、逆行列が存在しないと言える。  
    ※逆に言えば、ad - bc ≠ 0の場合逆行列は存在するといえる。  
<br>
1. 逆行列の求め方  
    * 掃き出し法  
    ad - bc ≠ 0の行列Aがあるとすると、
    <img src="https://latex.codecogs.com/png.latex?\inline&space;\large&space;{\color{White}A=&space;\begin{pmatrix}&space;a&space;&&space;b&space;\\&space;c&space;&&space;d&space;\end{pmatrix}" />の拡大行列を考える。  
    以下のような、Aに単位行列を付け加えたような
    <img src="https://latex.codecogs.com/png.latex?\inline&space;\large&space;{\color{White}\begin{pmatrix}&space;a&space;&&space;b&space;&&space;1&space;&&space;0&space;\\&space;c&space;&&space;d&space;&&space;0&space;&&space;1&space;\end{pmatrix}" />
    に対し、a~dの部分が単位行列になるように、以下の操作を繰り返す。
        * i行目をc倍する。
        * c倍したものをj行目に足し合わせる
        * i,jを入れ替える  
<br>

1. 行列式  
逆行列を持つか判別する式。|A|やdetAというように表される。  
ある一つの正方行列に、ある一つの数値が対応する。  
<img src="https://latex.codecogs.com/png.latex?\large&space;{\color{White}\begin{vmatrix}&space;a&space;&&space;b&space;\\&space;c&space;&&space;d&space;\end{vmatrix}=&space;ad-bc" />  
<br>

### 固有値・固有ベクトル  
ある行列Aに対し、以下のような式が成り立つような特殊なベクトルxと右辺の係数λがある。  
<img src="https://latex.codecogs.com/png.latex?\large&space;{\color{white}&space;A\vec{x}=\lambda&space;\vec{x}}"/>  
これは、行列Aを作用させても、ベクトルxが定数倍になっているという特殊なパターン。上記より、  
<img src="https://latex.codecogs.com/png.latex?\large&space;{\color{white}&space;A\vec{x}=\lambda&space;\vec{x}}"/>  
<img src="https://latex.codecogs.com/png.latex?\large&space;{\color{white}&space;\Leftrightarrow&space;A\vec{x}-\lambda&space;\vec{x}=&space;\vec{0}}"/>  
<img src="https://latex.codecogs.com/png.latex?\large&space;{\color{white}\Leftrightarrow&space;(A&space;-\lambda&space;I)\vec{x}=&space;\vec{0}}" />  
ここで、（自明である）
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{white}\vec{x}\neq&space;0}" />
より、
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{white}\&space;A&space;-\lambda&space;I&space;&space;}">
が逆行列を持つとすると、ベクトルxが０ベクトルであるということになる。
つまり、
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{white}\vec{x}\neq&space;0}" />　
に反する。よって、
<img src="https://latex.codecogs.com/png.latex?{\color{white}\&space;A&space;-\lambda&space;I&space;&space;}">
が逆行列を持たない条件について考えればよい。  
<img src="https://latex.codecogs.com/png.latex?\large&space;{\color{white}\therefore&space;|A&space;-\lambda&space;I|&space;=&space;0}">  
これを解くと、固有値と固有ベクトルについての解が算出される。  
<br>

1. 固有値分解  
ある実数を並べて作られた正方形の行列Aが、固有値
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{white}&space;\lambda&space;_{1},\lambda&space;_{2},\lambda&space;_{3\cdots&space;}}" />
とそれに対応する固有値ベクトル
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{white}&space;\vec{v}_{1},\vec{v}_{2},\vec{v}_{3}{\cdots&space;}}" />
を持っているとする。  
この固有値を対角線上に並べた行列  
<img src="https://latex.codecogs.com/png.latex?\inline&space;\large&space;{\color{white}&space;\lambda&space;=&space;\begin{pmatrix}&space;\lambda&space;_{1}&space;&&space;&&space;\\&space;&&space;\lambda&space;_{2}&space;&&space;\\&space;&&space;&&space;\ddots&space;\end{pmatrix}}">  
と、それに対応する固有ベクトルを並べた行列  
<img src="https://latex.codecogs.com/png.latex?\inline&space;\large&space;{\color{white}&space;V&space;=&space;\begin{pmatrix}&space;\vec{v_{1}}&space;&&space;\vec{v_{2}}&space;&&space;\cdots&space;\end{pmatrix}&space;}" />  
を用意したとき、それらは、  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;AV=&space;\lambda&space;V}" />  
と関連付けられる。したがって、  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;A=&space;V\lambda&space;V^{-1}\Leftrightarrow&space;\lambda&space;=&space;V^{-1}AV}" />  
と変形できる。このように正方形の行列を上記のような３つの行列の積に変換することができ、これを固有値分解という。  
この変形により、累乗の計算が楽になったり、分類や似ている箇所を発見できる利点がある。

1. 特異値分解  
正方形の行列以外にも固有値分解をしたいという発想のもと考えられたもの。
次の条件を持つ長方形の行列は特異値分解のようなものが可能となる。  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;M\vec{v}=&space;\sigma&space;\vec{u}}" />  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{white}&space;M^{t}\vec{u}=&space;\sigma&space;\vec{v}" />  
上記のような、特殊な単位ベクトル（大きさが1）があるならば、特異値分解が可能となる。  
<img src="https://latex.codecogs.com/png.latex?\inline&space;\large&space;{\color{white}&space;M=&space;USV^{t}&space;}" />  
※Sはシグマ  
※U、Sは直行行列  
    * 特異値の求め方  
    <img src="https://latex.codecogs.com/png.latex?\inline&space;\large&space;{\color{White}&space;\left\{\begin{matrix}&space;MV=&space;US&space;\\&space;M^{t}U=&space;VS^{t}&space;\end{matrix}\right.\Leftrightarrow&space;\left\{\begin{matrix}&space;M=&space;USV^{t}&space;\\&space;M^{t}&space;=&space;VS^{t}U^{t}&space;\end{matrix}\right.}" />  
    以上より、  
    <img src="https://latex.codecogs.com/png.latex?\inline&space;\large&space;{\color{White}&space;MM^{t}=&space;USV^{t}VS^{t}U^{t}=&space;USS^{t}U^{t}}" />  
    固有値分解の式を見比べると、
    <img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;MM^{t}&space;=&space;A,&space;V=U,&space;V^{-1}=&space;U^{t}}" />となっていることが分かる。※VとUは直交行列

***
## 2. 確率・統計

### 和集合と共通部分
和集合：
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;A\cup&space;B}" />  
共通部分：
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;A\cap&space;B}" />  
と表す。

### 相対補と絶対補
絶対補：
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}U\setminus&space;A=&space;\overline{A}}" />  
と表し、全体から自分以外を取り除いた部分で、全体から取り除いているので絶対的な領域。  
相対補：
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;B\setminus&space;A}" />  
と表し、Bという領域からAを取り除いた部分で、Bという集合から相対的にAを取り除いた領域。

<br>

### 確率
* 頻度確率→客観確率とも言い、発生する頻度を示す
* ベイズ確率→信念の度合いのようなもの示し、あまり数学的ではない

<br>

### 条件付き確率
ある事象Bが与えられた条件下で、Aとなる確率  
例）雨が降っている条件下で、事故に遭う確率  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;P\left&space;(&space;A\mid&space;B&space;\right&space;)&space;=&space;\frac{P\left&space;(&space;A\cap&space;B&space;\right&space;)}{P\left&space;(&space;B&space;\right&space;)}}" />
* 独立な事象の同時確率
お互いの発生に影響がない事象A,Bが同時に発生する確率は、  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;P\left&space;(&space;A\cap&space;B&space;\right&space;)&space;=&space;P\left&space;(&space;A&space;\right&space;)P\left&space;(&space;B&space;\right&space;)}" />

<br>

### 記述統計と推測統計
記述統計は、集団の性質を要約し記述するような統計。主に平均値や分散、標準偏差などがある。  
推測統計は、全体のデータから一部を取り出し、部分についての平均値や分散などについて導き、最終的に元の全体を推測するような統計。

* 期待値  
その分布における確率変数の平均値or’ありえそう’な値  

|  事象(x)  |  x1  | x2  |  ...  | xn  |
| ---- | ---- |---- | ---- |---- |
|  確率変数f(x)  |  f(x1)  |  f(x2)  |  ...  |  f(xn)  |
|  確率P(x)  |  P(x1)  |  P(x1)  |  ...  |  P(x1)  |

期待値(f)  
<img src="https://latex.codecogs.com/png.latex?\large&space;{\color{White}&space;\sum_{k=1}^{n}P\left&space;(&space;X=&space;x_{k}&space;\right&space;)f\left&space;(&space;X=&space;x_{k}&space;\right&space;)}" />  
で表され、期待値が連続する値ならば、  
<img src="https://latex.codecogs.com/png.latex?\large&space;{\color{White}&space;\int_{k=1}^{k=n}&space;P\left&space;(&space;X=&space;x_{k}&space;\right&space;)f\left&space;(&space;X=&space;x_{k}&space;\right&space;)}" />  
で表される。


<br>

### 分散と共分散
分散はデータの散らばり具合を表す。データの各値が期待値からどれだけずれているか平均したもの。  
以下の式で表される。  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;Var\left&space;(&space;f&space;\right&space;)&space;=&space;E&space;\left&space;(\left&space;(&space;f_{\left&space;(&space;X=x&space;\right&space;)&space;}&space;-&space;E&space;\left&space;(&space;f&space;\right&space;)\right&space;)&space;^{2}&space;\right&space;)}" />
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}=&space;\left&space;(&space;\left&space;(&space;f^{^{2}}_{\left&space;(&space;X=x&space;\right&space;)&space;}\right&space;)&space;-&space;\left&space;(E\left&space;(&space;f&space;\right&space;)&space;\right&space;)^{2}&space;\right&space;)&space;}" />  

分散はｍ２つのデータの傾向の違いを示す。
* 正の値：似た傾向
* 負の値：逆の傾向
* ゼロ：関係性に乏しい
ということが分かる。  

<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;Cov\left&space;(&space;f,g&space;\right&space;)&space;=&space;E&space;\left&space;(&space;f_{\left&space;(&space;X=x&space;\right&space;)&space;}&space;-&space;E&space;\left&space;(&space;f&space;\right&space;)\right&space;)&space;\left&space;(&space;g_{\left&space;(&space;Y=y&space;\right&space;)&space;}&space;-&space;E&space;\left&space;(&space;g&space;\right&space;)\right&space;)&space;=&space;E\left&space;(&space;fg&space;\right&space;)-E\left&space;(&space;f&space;\right&space;)E\left&space;(&space;g&space;\right&space;)&space;}" />  


<br>


### 分散と標準偏差  
分散では２乗して算出するので、元データとの単位が異なる→２乗の逆演算、つまり平方根を取れば元の単位になる。  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;\sigma&space;=&space;\sqrt{&space;Var\left&space;(&space;f&space;\right&space;)}&space;=&space;\sqrt{E&space;\left&space;(\left&space;(&space;f_{\left&space;(&space;X=x&space;\right&space;)&space;}&space;-&space;E&space;\left&space;(&space;f&space;\right&space;)\right&space;)^{2}&space;\right&space;)}}" />

<br>

### 確率分布
* ベルヌーイ分布  
コイントスのイメージ。
* マルチヌーイ分布  
サイコロを転がしたときのイメージ。
* 二項分布  
コイントスのn回試行した場合を考える。
* ガウス分布  
釣鐘型の連続分布。  

などがある。

<br>

### 推定
母集団を特徴づける母数を統計的に推測する。  
* 点推定
* 区間推定
の２つがある。

<br>

### 標本平均、標本分散
母集団から取り出した標本の平均値。同様に、標本の分散値。  
これらは次の特徴を持つ。
* 一致性  
サンプル数が大きくなればなるほど、母集団の値に近づく。
* 不偏性  
サンプルがいくつであっても、その期待値は母集団の値と同じ。

<br>

### 不偏分散
標本分散では、データ数が小さいばらつきが少なくなるということが予想できる。つまり、本来の値よりも小さくなってしまう。その特徴を解消するため、標本分散を1/n-1倍したものを標本分散とする。

***
## 3. 情報理論

### 自己情報量
情報の珍しさは、確率P(x)で表される。※珍しい＝情報量が大きい
* 対数が２のとき単位はbit
* 対数の低がネイピア数eのとき単位はnat  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;I\left&space;(&space;x&space;\right&space;)=&space;-log\left&space;(&space;P\left&space;(&space;x&space;\right&space;)&space;\right&space;)=&space;log\left&space;(&space;w\left&space;(&space;x&space;\right&space;)&space;\right&space;)}" />  
x：ある事象、P(x)：確率、w(x)：事象xのときの情報量を表したもの。

### シャノンエントロピー
自己情報量の期待値(＝事象xの情報の珍しさの平均)  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;H\left&space;(&space;x&space;\right&space;)=&space;E\left&space;(&space;I\left&space;(&space;x&space;\right&space;)&space;\right&space;)}" />  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;=&space;-E\left&space;(&space;log\left&space;(&space;P\left&space;(&space;x&space;\right&space;)&space;\right&space;)&space;\right&space;)}" />  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;=&space;-\sum&space;\left&space;(&space;P\left&space;(&space;x&space;\right&space;)&space;logP\left&space;(&space;x&space;\right&space;)&space;\right&space;)}" />  

### カルバック・ライブラー　ダイバージェンス
同じ事象・確率変数における異なる確率分布P,Qの違いを表す。  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;D_{KL}\left&space;(&space;p\parallel&space;q&space;\right&space;)&space;=&space;\mathbb{E}_{x\sim&space;p}\left&space;[&space;log\frac{P\left&space;(&space;x&space;\right&space;)}{Q\left&space;(&space;x&space;\right&space;)}&space;\right&space;]=&space;\mathbb{E}_{x\sim&space;p}\left&space;[&space;logP\left&space;(&space;x&space;\right&space;)&space;-logQ\left&space;(&space;x&space;\right&space;)\right&space;]}" />  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}D_{KL}\left&space;(&space;p\parallel&space;q&space;\right&space;)&space;=&space;\sum&space;_{x}P\left&space;(&space;x&space;\right&space;)log\frac{P\left&space;(&space;x&space;\right&space;)}{Q\left&space;(&space;x&space;\right&space;)}}" />  


### 交差エントロピー
* KLダイバージェンスの一部分を取り出したもの
* Qについての自己情報量をPの分布で平均している  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;H\left&space;(&space;P,Q&space;\right&space;)=&space;H\left&space;(&space;P&space;\right&space;)&space;&plus;&space;D_{KL}\left&space;(&space;P\parallel&space;Q&space;\right&space;)}" />  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;\Leftrightarrow&space;H\left&space;(&space;P,Q&space;\right&space;)=&space;E_{x\sim&space;p}logQ(x)}" />  
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;\Leftrightarrow&space;H\left&space;(&space;P,Q&space;\right&space;)=&space;-\sum&space;_{x}P(x)logQ(x)}" />  
