{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YKFyb5LwBhDn",
        "vV1oRtN2BzqJ",
        "XE_KUf8cB-Fb"
      ],
      "authorship_tag": "ABX9TyNmPov8k1yQ5HMuVStV6UkX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcms2ll/AI-Study/blob/main/ETest/src/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXS1dGt09reD",
        "outputId": "217b6bc4-e76b-475f-c1e1-28cec31f5465"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O5xRfKi_YzF"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/rabbit_challenge/DNN_code')\n",
        "sys.path.append('/content/drive/MyDrive/rabbit_challenge/DNN_code/lesson_3')\n",
        "\n",
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA14C3U3BYti"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A2myuvM7_2z-",
        "outputId": "59d4c278-cfac-46da-93b5-b01f9780bd18"
      },
      "source": [
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.1186413023449804\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "83 + 26 = 83\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.10445370539109\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "38 + 93 = 126\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.9434020249894146\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "53 + 26 = 3\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.92814968866773\n",
            "Pred:[0 0 0 0 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "63 + 27 = 11\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.0319883945191148\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "39 + 99 = 32\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.7520268561188292\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "1 + 113 = 98\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.9278639607106972\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "60 + 23 = 106\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.9158223797875685\n",
            "Pred:[1 1 1 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "37 + 102 = 233\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.8988549322535245\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "18 + 68 = 0\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.8624702997173188\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "74 + 125 = 183\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.9613324157133831\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "31 + 86 = 97\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.5495587454991628\n",
            "Pred:[0 0 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "6 + 69 = 10\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.23115351999391479\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 1 0 0 0 0]\n",
            "0 + 16 = 0\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.8040390191273109\n",
            "Pred:[0 0 0 1 0 0 0 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "15 + 70 = 17\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.8668406609925328\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "23 + 120 = 111\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.6280950587983326\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "77 + 89 = 166\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.8338476145929655\n",
            "Pred:[1 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "55 + 71 = 248\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.6516382218678277\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "6 + 102 = 106\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.6985720585884476\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "39 + 11 = 56\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.5339440865064778\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "38 + 18 = 62\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.08859166630919936\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 0 0 0 0 0 0 1]\n",
            "1 + 0 = 1\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.4719025378351795\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "76 + 24 = 116\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.7640470142027588\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "37 + 83 = 126\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.507093549108673\n",
            "Pred:[0 0 1 1 1 0 1 0]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "5 + 45 = 58\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.7450511699878035\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "73 + 72 = 89\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.7591141250571366\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "5 + 79 = 90\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.42294196285193464\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "72 + 19 = 95\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.6943375226698029\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "48 + 51 = 87\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.6474572914300456\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "103 + 38 = 137\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.19896088294379954\n",
            "Pred:[0 0 1 0 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "16 + 31 = 47\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.6746475230476809\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 0 1 0 1 1 0 1]\n",
            "15 + 30 = 33\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.649042865094298\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 1 0 0 0 1 0 0]\n",
            "83 + 113 = 164\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.07735409719138195\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "89 + 0 = 89\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.4583131648157185\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "85 + 112 = 133\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.2555512176708929\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "48 + 94 = 142\n",
            "------------\n",
            "iters:3500\n",
            "Loss:1.3121725255727763\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "37 + 107 = 142\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.5627100545892055\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 0 1 1 1 1 1]\n",
            "0 + 31 = 63\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.14350735296100017\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "84 + 82 = 166\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.35764822888927905\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "79 + 7 = 82\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.1723083408403902\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "105 + 51 = 156\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.5183026564154369\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 1 0 1 0 1 1 1]\n",
            "122 + 93 = 135\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.22298087892154603\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "80 + 59 = 139\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.08399814049315771\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "32 + 109 = 141\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.28475283784212846\n",
            "Pred:[1 1 1 0 1 1 0 1]\n",
            "True:[1 1 1 0 1 1 0 1]\n",
            "115 + 122 = 237\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.18098496336878528\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "17 + 43 = 60\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.08059001001259555\n",
            "Pred:[0 0 1 0 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "26 + 21 = 47\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.06124828872019828\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "53 + 9 = 62\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.09168775936351287\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "87 + 66 = 153\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.03084572201490544\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "40 + 24 = 64\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.08827874434268149\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "99 + 10 = 109\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.07496041374266459\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "18 + 102 = 120\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.01817273687661524\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "17 + 76 = 93\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.11462449265591153\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "46 + 58 = 104\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.021899402363250733\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "107 + 8 = 115\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.09360101251809666\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "23 + 59 = 82\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.05746972872574755\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "101 + 14 = 115\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.07712245354519272\n",
            "Pred:[1 0 1 1 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "124 + 52 = 176\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.051318897149939584\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "67 + 83 = 150\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.01673305365687592\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "57 + 21 = 78\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.05176642702926556\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 0 1 0 0 0 0 1]\n",
            "3 + 30 = 33\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.03505895348746259\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "124 + 22 = 146\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.015236782030570743\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "8 + 64 = 72\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.007413692960905054\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "76 + 65 = 141\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.014709669146693768\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "0 + 111 = 111\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.012607031911088324\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "96 + 52 = 148\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.009687723173474688\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "125 + 0 = 125\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.02073154138389056\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "120 + 92 = 212\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.01122064214850311\n",
            "Pred:[1 0 1 1 0 0 0 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "109 + 68 = 177\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.010282418570829632\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "87 + 36 = 123\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.007551272383984109\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "32 + 55 = 87\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.01083119936415479\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "106 + 96 = 202\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.018325458610148275\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "5 + 38 = 43\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.016456975845821092\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "27 + 61 = 88\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.0183457885338236\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "90 + 51 = 141\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.006960915269715343\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "87 + 68 = 155\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.005856835784502628\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "81 + 68 = 149\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.023741417991827624\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "79 + 87 = 166\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.013017743183238062\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "69 + 55 = 124\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.016285460024473567\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "19 + 119 = 138\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.005654937647853529\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "122 + 1 = 123\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.006698508444256674\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "75 + 108 = 183\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.005942739213581044\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "85 + 45 = 130\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.005102864764640616\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "29 + 35 = 64\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0032042553685358165\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "75 + 1 = 76\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.007207706454277947\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "100 + 39 = 139\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.006035180866348211\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[0 1 0 0 0 1 0 1]\n",
            "67 + 2 = 69\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.005007381438900044\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "36 + 40 = 76\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.0071852016364075625\n",
            "Pred:[0 0 0 1 0 1 0 1]\n",
            "True:[0 0 0 1 0 1 0 1]\n",
            "7 + 14 = 21\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.00697226617198845\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "26 + 70 = 96\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.008542544708304107\n",
            "Pred:[1 1 1 0 0 0 1 1]\n",
            "True:[1 1 1 0 0 0 1 1]\n",
            "116 + 111 = 227\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.004381555327456211\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "53 + 29 = 82\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.00513909449748426\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "2 + 116 = 118\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.0024697899539863556\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "68 + 41 = 109\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.004516844168819999\n",
            "Pred:[1 1 0 0 1 1 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "83 + 124 = 207\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.005487468034133143\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "19 + 70 = 89\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.005805363296921083\n",
            "Pred:[1 0 1 0 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "62 + 99 = 161\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.002687359591485173\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "37 + 45 = 82\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.006205412747897286\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "8 + 122 = 130\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0055211455554373574\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "59 + 125 = 184\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0023504384257335208\n",
            "Pred:[0 0 0 1 1 1 0 0]\n",
            "True:[0 0 0 1 1 1 0 0]\n",
            "17 + 11 = 28\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRrCSEJrBSCZ"
      },
      "source": [
        "## weight_init_stdやlearning_rate, hidden_layer_sizeを変更してみよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKFyb5LwBhDn"
      },
      "source": [
        "### weight_init_stdを変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xr-95dZYBeML",
        "outputId": "571ccbee-f256-4193-e359-3ee550047f09"
      },
      "source": [
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 2\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.947208166670134\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "61 + 74 = 255\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.3245468046217201\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[0 0 0 1 1 1 0 1]\n",
            "21 + 8 = 75\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.8541007835015179\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "29 + 69 = 107\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.2073170018750747\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "26 + 94 = 2\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.8861804991283968\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "27 + 74 = 67\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.8262116094686309\n",
            "Pred:[1 1 0 1 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "75 + 64 = 219\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.7546707797713088\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "50 + 83 = 1\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.9864393941106447\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 1 0 0 1 1 1 0]\n",
            "105 + 101 = 131\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.7037318202298041\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "42 + 105 = 149\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.7956298447476935\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "12 + 62 = 122\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.8366262905723689\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "122 + 26 = 0\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.7528154987197465\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "110 + 100 = 212\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.026737305656278\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "29 + 112 = 239\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.1502896200116206\n",
            "Pred:[1 1 0 1 1 0 0 0]\n",
            "True:[1 1 0 1 0 1 1 1]\n",
            "117 + 98 = 216\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.5950696803481221\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "4 + 123 = 255\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.6963210689617118\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "91 + 77 = 128\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.6912336963115768\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "85 + 39 = 120\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.7251392902857069\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "77 + 14 = 81\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.9037633235222934\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "83 + 45 = 72\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.9470314813827209\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 1 0 0 0 1]\n",
            "59 + 22 = 79\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.4887351417514324\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "81 + 14 = 79\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.566321610558339\n",
            "Pred:[1 1 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "51 + 90 = 207\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.3246475316938059\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "74 + 116 = 190\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.452431346555498\n",
            "Pred:[0 1 0 0 0 1 1 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "24 + 44 = 70\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.35531549731379897\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "99 + 28 = 123\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.23782217065364664\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "89 + 8 = 99\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.3946848106007656\n",
            "Pred:[0 0 1 0 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "12 + 35 = 47\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.08593727509420186\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "45 + 38 = 83\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.17232372887351904\n",
            "Pred:[1 1 0 0 1 0 0 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "98 + 102 = 200\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.22980943623479808\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "57 + 124 = 183\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.03189623032509981\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "56 + 10 = 66\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.08650059983943977\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "36 + 95 = 131\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.04562749723519319\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[0 0 0 1 1 1 1 1]\n",
            "21 + 10 = 31\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.025016023603229885\n",
            "Pred:[0 0 1 1 0 1 1 0]\n",
            "True:[0 0 1 1 0 1 1 0]\n",
            "18 + 36 = 54\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.07224026202607123\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "37 + 91 = 128\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.02517184612262523\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "51 + 65 = 116\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.038135632122113926\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "62 + 94 = 156\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.11479604715748787\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "89 + 100 = 189\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.025206238816576215\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "21 + 107 = 128\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.02895269808822383\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "19 + 24 = 43\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.018374155234383807\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "8 + 52 = 60\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.018507311641801007\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "61 + 30 = 91\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.11625374625893828\n",
            "Pred:[1 1 1 0 0 0 0 1]\n",
            "True:[1 1 1 0 0 0 0 1]\n",
            "101 + 124 = 225\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.02570382292354703\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "16 + 126 = 142\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.015208446054080069\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "44 + 46 = 90\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.0657868522021924\n",
            "Pred:[1 1 0 0 0 1 0 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "105 + 92 = 197\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.010259126794129603\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "89 + 75 = 164\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.014674588168317407\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "84 + 68 = 152\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.02434500284391251\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "8 + 126 = 134\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.015590908844108489\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "89 + 7 = 96\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.009135492769060574\n",
            "Pred:[1 1 0 1 0 0 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "116 + 94 = 210\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.00922341011491571\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "41 + 2 = 43\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.010784500202977705\n",
            "Pred:[0 0 0 1 1 0 1 1]\n",
            "True:[0 0 0 1 1 0 1 1]\n",
            "26 + 1 = 27\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.00883611051996894\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[0 0 0 0 1 0 0 0]\n",
            "2 + 6 = 8\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.008234617966989363\n",
            "Pred:[0 0 0 0 1 0 1 1]\n",
            "True:[0 0 0 0 1 0 1 1]\n",
            "4 + 7 = 11\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.008051984048930417\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "18 + 109 = 127\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.005141722460593525\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "76 + 2 = 78\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.008814580823624971\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "52 + 103 = 155\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.008034709009960634\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "61 + 18 = 79\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.001944771008314708\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "63 + 1 = 64\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.008511918043313365\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "33 + 119 = 152\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.007000642450628749\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "21 + 98 = 119\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.005453943965262725\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "44 + 107 = 151\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.035469706534333616\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "119 + 70 = 189\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.004560011560571233\n",
            "Pred:[1 1 0 1 0 0 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "98 + 112 = 210\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.0043273645257049295\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "43 + 23 = 66\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.005963819397773678\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 1 0 1 0 1 1 1]\n",
            "96 + 119 = 215\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.03183238204653603\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "103 + 86 = 189\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.006098907775695441\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "26 + 93 = 119\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.005167849198780866\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "56 + 83 = 139\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.003826650958653257\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "2 + 125 = 127\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.0034103463021542386\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "35 + 83 = 118\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.027880605324225677\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "41 + 36 = 77\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.004046445275829083\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "92 + 110 = 202\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.0022847461022834016\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "37 + 111 = 148\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.0037498184276066877\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "28 + 14 = 42\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.0029949072770642845\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "78 + 49 = 127\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.004449646057826235\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "62 + 23 = 85\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.003800365938344766\n",
            "Pred:[0 0 0 1 1 0 1 1]\n",
            "True:[0 0 0 1 1 0 1 1]\n",
            "21 + 6 = 27\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.003318858248193663\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "125 + 14 = 139\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.0011721512253037953\n",
            "Pred:[1 1 1 1 0 0 0 0]\n",
            "True:[1 1 1 1 0 0 0 0]\n",
            "125 + 115 = 240\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.005652765521978094\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "15 + 116 = 131\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.004007290160200222\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "74 + 109 = 183\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0027786576919710047\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "76 + 27 = 103\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.004781056614872077\n",
            "Pred:[1 1 0 0 1 1 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "94 + 113 = 207\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.0017002102990935945\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "117 + 1 = 118\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.0012368280715209482\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "85 + 67 = 152\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.0022930726890861204\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "126 + 16 = 142\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.0022928720500602962\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "38 + 84 = 122\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.001149206032609992\n",
            "Pred:[1 1 1 0 1 0 0 0]\n",
            "True:[1 1 1 0 1 0 0 0]\n",
            "109 + 123 = 232\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0014392630567072085\n",
            "Pred:[0 0 0 1 1 0 1 1]\n",
            "True:[0 0 0 1 1 0 1 1]\n",
            "19 + 8 = 27\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.001620992430229701\n",
            "Pred:[1 0 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "115 + 48 = 163\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.000757602597198708\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "55 + 25 = 80\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.002341066586134039\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "34 + 26 = 60\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.002075443390046906\n",
            "Pred:[1 1 1 0 0 1 1 1]\n",
            "True:[1 1 1 0 0 1 1 1]\n",
            "126 + 105 = 231\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.0024966086795097675\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "24 + 42 = 66\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.001372895319571216\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "103 + 32 = 135\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.001163434021454921\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "33 + 85 = 118\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0018194142377845946\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "56 + 99 = 155\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0014026568605423472\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "79 + 3 = 82\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av87tqpTDJYY"
      },
      "source": [
        "1->2に変更し、学習スピードが早くなった"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vV1oRtN2BzqJ"
      },
      "source": [
        "### learning_rateを変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EuGt7Q-kBy3j",
        "outputId": "3a426650-489f-4d0b-90b2-4f6f2ca1c8d6"
      },
      "source": [
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.2\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.0629360061128659\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "49 + 82 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.9373148493707424\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "74 + 112 = 255\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.9463350611120349\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[0 0 1 1 1 0 1 0]\n",
            "9 + 49 = 3\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.1017414082570847\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "62 + 63 = 0\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.907820740637854\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "89 + 29 = 255\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0822003993522384\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 1 0 1]\n",
            "49 + 12 = 0\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.0515627327117327\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "21 + 63 = 62\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.8493050277048653\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "9 + 100 = 108\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.9156111270222101\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "84 + 39 = 43\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.7464611092428216\n",
            "Pred:[0 0 1 0 1 1 1 1]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "18 + 37 = 47\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.048565530315108\n",
            "Pred:[1 1 1 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "55 + 82 = 237\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.7743986991478427\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "29 + 73 = 118\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.6625276340810264\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "0 + 47 = 127\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.6348197475044426\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "26 + 93 = 127\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.86314170559123\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "83 + 69 = 158\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.689123135900462\n",
            "Pred:[1 1 0 1 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "51 + 96 = 211\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.209165747579246\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "53 + 110 = 89\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.7306428227484469\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "15 + 69 = 94\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.8129000040420962\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "61 + 34 = 67\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.6421365523315188\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "29 + 69 = 122\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.6231410875267465\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "100 + 110 = 154\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.2027749767381832\n",
            "Pred:[0 0 0 0 1 0 1 1]\n",
            "True:[0 0 0 0 1 0 0 1]\n",
            "8 + 1 = 11\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.1526336955402461\n",
            "Pred:[0 0 0 0 1 1 0 0]\n",
            "True:[0 0 0 0 1 1 0 0]\n",
            "3 + 9 = 12\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.38765478808679366\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "38 + 87 = 125\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.3002619192488087\n",
            "Pred:[0 0 0 1 0 1 1 1]\n",
            "True:[0 0 0 1 0 1 0 1]\n",
            "16 + 5 = 23\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.28377339683826264\n",
            "Pred:[0 0 1 1 0 0 1 1]\n",
            "True:[0 0 1 0 0 0 1 1]\n",
            "12 + 23 = 51\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.03819421081322141\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "99 + 33 = 132\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.4018026187797576\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "92 + 125 = 153\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.3623230126810035\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "57 + 35 = 94\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.2711762761564375\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "58 + 95 = 153\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.02088469197791844\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "80 + 18 = 98\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.08463887377259993\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "100 + 13 = 113\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.04466911419393037\n",
            "Pred:[1 0 0 1 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "51 + 96 = 147\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.06421868411422393\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "43 + 29 = 72\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.020051257996866603\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "64 + 27 = 91\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.051454428238736395\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "60 + 61 = 121\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.019526229063115654\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "70 + 7 = 77\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.010179236244146884\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "21 + 64 = 85\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.022675636602559328\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "42 + 46 = 88\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.00625850427814326\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "30 + 48 = 78\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.007950995751447157\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "46 + 96 = 142\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.009387403353934105\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "62 + 3 = 65\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.0032983078530417257\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "18 + 84 = 102\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.00632144933171928\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "120 + 23 = 143\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.0026220771315716477\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "26 + 16 = 42\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.006876253958994118\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "14 + 87 = 101\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.0043607000614948755\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "85 + 13 = 98\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.004734725942696505\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "40 + 3 = 43\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.0032686218630706876\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "42 + 104 = 146\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.0029383086827497818\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "92 + 48 = 140\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.004844887360020148\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "67 + 60 = 127\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.00499296384415939\n",
            "Pred:[1 0 1 1 1 1 0 0]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "63 + 125 = 188\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.0015663618900311307\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "70 + 104 = 174\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.0039368614597730485\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "40 + 89 = 129\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.0023909590887015693\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "88 + 42 = 130\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.0009593682088928374\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "74 + 4 = 78\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.00402925230832645\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 1 0 1 0 1 1 1]\n",
            "105 + 110 = 215\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.004732601305675717\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "47 + 91 = 138\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.0012854630540288469\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "19 + 33 = 52\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.006792992671266446\n",
            "Pred:[1 1 0 0 0 1 0 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "70 + 127 = 197\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.0010201034176159079\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "69 + 17 = 86\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.0018983854872748097\n",
            "Pred:[1 0 1 1 1 0 0 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "111 + 74 = 185\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.004620232062973133\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "115 + 30 = 145\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.0008675733511124494\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "112 + 30 = 142\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.004254437146440397\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "117 + 31 = 148\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.001337301369211002\n",
            "Pred:[1 0 1 1 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "75 + 101 = 176\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.0011548672229855397\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "40 + 51 = 91\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.0012671075018696847\n",
            "Pred:[0 0 0 1 0 1 1 1]\n",
            "True:[0 0 0 1 0 1 1 1]\n",
            "19 + 4 = 23\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.000613300591203066\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "88 + 96 = 184\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.0005699555281820509\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "16 + 66 = 82\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.0020575281953341823\n",
            "Pred:[1 1 0 0 1 1 0 1]\n",
            "True:[1 1 0 0 1 1 0 1]\n",
            "95 + 110 = 205\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.0015914807740506503\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[1 1 1 0 1 1 1 1]\n",
            "127 + 112 = 239\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.0023798715317180008\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "93 + 119 = 212\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.0009521586421791644\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "33 + 84 = 117\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.0006907363632133371\n",
            "Pred:[0 0 1 1 0 1 1 1]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "24 + 31 = 55\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.0008680950069760343\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "78 + 86 = 164\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.0006615036225917449\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "86 + 54 = 140\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.000719190095653129\n",
            "Pred:[1 1 1 0 0 1 1 1]\n",
            "True:[1 1 1 0 0 1 1 1]\n",
            "110 + 121 = 231\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.0005492351109394913\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "54 + 29 = 83\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.0003501881187943826\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "88 + 8 = 96\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.0008191518744601745\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "45 + 70 = 115\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.0006140581306418539\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "83 + 12 = 95\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.000298612619134627\n",
            "Pred:[0 0 1 1 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "48 + 0 = 48\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0004244195342282837\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "126 + 25 = 151\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.0003834355046897576\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "8 + 88 = 96\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.0005729958589863934\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "127 + 43 = 170\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.0003059613532914999\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "126 + 36 = 162\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.0004135988909979446\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "50 + 90 = 140\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.000500421425487506\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "107 + 64 = 171\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.0005145886257491258\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "35 + 80 = 115\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0003356749353241594\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "52 + 44 = 96\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.00046950519093165146\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "89 + 52 = 141\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.000578203690617778\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "27 + 29 = 56\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.00025034461029009683\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "50 + 116 = 166\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0002482941340155366\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "106 + 26 = 132\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.00025208908916369064\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "44 + 97 = 141\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.00020988601873367884\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "106 + 19 = 125\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0001713806941235228\n",
            "Pred:[0 0 1 1 0 1 1 1]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "46 + 9 = 55\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0002427246391436939\n",
            "Pred:[1 1 1 0 1 0 0 1]\n",
            "True:[1 1 1 0 1 0 0 1]\n",
            "116 + 117 = 233\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0002512850886446879\n",
            "Pred:[1 1 1 0 1 0 1 0]\n",
            "True:[1 1 1 0 1 0 1 0]\n",
            "121 + 113 = 234\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L9QdrqBDaXV"
      },
      "source": [
        "0.1->0.2に変更し学習スピードが早くなった"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE_KUf8cB-Fb"
      },
      "source": [
        "### hidden_layer_sizeを変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "56X9NU2OCBVT",
        "outputId": "467c7bea-780b-4d80-e805-c7a0a0058cbc"
      },
      "source": [
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 8\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.7460807494259871\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "96 + 88 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.8720372822700231\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "63 + 17 = 68\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.95978930840153\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "13 + 93 = 8\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.9357003130685966\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "69 + 70 = 191\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.0108929465595888\n",
            "Pred:[1 1 1 1 0 1 0 1]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "74 + 124 = 245\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0347422479468018\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "100 + 94 = 168\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.0564823002131352\n",
            "Pred:[0 0 0 0 1 1 0 1]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "38 + 82 = 13\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0431529782951032\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "104 + 83 = 135\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.0941276270481808\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "102 + 28 = 121\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.0850907533951217\n",
            "Pred:[0 0 0 0 1 1 0 1]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "86 + 3 = 13\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.8995711797693067\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "103 + 78 = 157\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.0911564040369117\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "126 + 22 = 109\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.8397762607483874\n",
            "Pred:[1 1 1 1 0 0 1 1]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "96 + 121 = 243\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.1538050610659993\n",
            "Pred:[0 0 0 1 0 1 0 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "47 + 75 = 20\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.0783947477178863\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "93 + 41 = 251\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.8945703597102186\n",
            "Pred:[0 0 0 1 0 1 0 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "77 + 10 = 21\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.0126849627633778\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "1 + 105 = 2\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.1970293108311572\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "22 + 108 = 121\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.1239748986784708\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "118 + 13 = 123\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.9350894363981148\n",
            "Pred:[1 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "36 + 89 = 241\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.6261050011183418\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "49 + 52 = 101\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.7024765065725197\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 1 0 0 0 0 0 1]\n",
            "88 + 105 = 145\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.5113489764212399\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "70 + 119 = 189\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.8130468278442219\n",
            "Pred:[1 1 0 0 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "113 + 38 = 197\n",
            "------------\n",
            "iters:2400\n",
            "Loss:1.0183335135464822\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "75 + 124 = 179\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.6976020902737559\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "21 + 103 = 94\n",
            "------------\n",
            "iters:2600\n",
            "Loss:1.235161916064368\n",
            "Pred:[1 1 1 0 1 1 1 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "89 + 55 = 238\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.44286459160996894\n",
            "Pred:[1 1 0 0 1 1 0 1]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "99 + 102 = 205\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.37354737775359065\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "74 + 79 = 157\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.5194778887558817\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "83 + 0 = 67\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.7309986811318466\n",
            "Pred:[1 1 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "105 + 34 = 205\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.4444510914811301\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "46 + 107 = 149\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.44624985560621294\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "106 + 1 = 105\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.6825453522792799\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "8 + 119 = 117\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.20098365325108794\n",
            "Pred:[1 0 1 0 1 0 0 1]\n",
            "True:[1 0 1 0 1 0 0 1]\n",
            "89 + 80 = 169\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.36253399472131115\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "44 + 68 = 113\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.5511358711578103\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "54 + 42 = 113\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.5350329460725949\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "83 + 44 = 125\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.12728562558862108\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "112 + 53 = 165\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.15231063029827394\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "25 + 63 = 88\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.30445891123468966\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "25 + 54 = 77\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.15898310101375787\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "75 + 12 = 87\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.03387000003297394\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "71 + 67 = 138\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.11126484832814901\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "22 + 127 = 149\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.11872204886022686\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "50 + 10 = 60\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.027218929432735406\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "74 + 71 = 145\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.07205664039489953\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "114 + 29 = 143\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.020167790470206164\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "3 + 121 = 124\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.022936503534753103\n",
            "Pred:[0 0 0 1 0 0 0 1]\n",
            "True:[0 0 0 1 0 0 0 1]\n",
            "3 + 14 = 17\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.019171819861024578\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "11 + 101 = 112\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.026741193320629398\n",
            "Pred:[1 1 1 0 1 0 0 0]\n",
            "True:[1 1 1 0 1 0 0 0]\n",
            "121 + 111 = 232\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.021263784323912998\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "113 + 20 = 133\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.04563554826576379\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "96 + 106 = 202\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.04111395646005799\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "83 + 4 = 87\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.051611618799147316\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "4 + 38 = 42\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.052892601337845464\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "26 + 122 = 148\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.007080938354198725\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "89 + 79 = 168\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.015551310290127568\n",
            "Pred:[1 1 0 1 0 0 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "85 + 124 = 209\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.011269269652837977\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "102 + 9 = 111\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.007901198904363069\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "83 + 15 = 98\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.0031928124334249727\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "89 + 41 = 130\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.0032403899854664105\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "65 + 125 = 190\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.035722770081437275\n",
            "Pred:[1 1 1 1 0 1 0 0]\n",
            "True:[1 1 1 1 0 1 0 0]\n",
            "118 + 126 = 244\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.039959376098027515\n",
            "Pred:[1 1 0 1 1 1 0 0]\n",
            "True:[1 1 0 1 1 1 0 0]\n",
            "126 + 94 = 220\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.011668661791773397\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "77 + 74 = 151\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.007709124928535748\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 0 1 0 0 0 0 1]\n",
            "27 + 6 = 33\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.02663632549948775\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "52 + 20 = 72\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.005678329623472778\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "66 + 57 = 123\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.0133624600160995\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "59 + 12 = 71\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.01198420160577506\n",
            "Pred:[1 1 0 1 0 0 0 0]\n",
            "True:[1 1 0 1 0 0 0 0]\n",
            "117 + 91 = 208\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.0028131199865629305\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "67 + 79 = 146\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.02114752499849307\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "18 + 60 = 78\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.02020016904527656\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "86 + 96 = 182\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.016930001163447634\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "0 + 112 = 112\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.00750651799433299\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "93 + 34 = 127\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.017486107410473288\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "76 + 86 = 162\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.01643472775865028\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "118 + 48 = 166\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.013712995262745512\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "24 + 28 = 52\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.006661657862542466\n",
            "Pred:[1 1 0 0 0 1 0 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "71 + 126 = 197\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.004599805880413269\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "66 + 93 = 159\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.0008587346789295181\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "67 + 17 = 84\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.0013051590131902074\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "67 + 39 = 106\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.013374101477698635\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "2 + 72 = 74\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.004880916451436874\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "77 + 78 = 155\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.004799230483141963\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "71 + 68 = 139\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.011433231228130412\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "46 + 64 = 110\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.012666973400726452\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "66 + 30 = 96\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.002643030883186606\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "65 + 40 = 105\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.00103554555529324\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "97 + 47 = 144\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.011096258659965675\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "62 + 64 = 126\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.014582762667522398\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "62 + 98 = 160\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.010111863730261433\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "56 + 22 = 78\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.00043912299388408307\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "19 + 65 = 84\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.010776821520724185\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "58 + 86 = 144\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0031183153414740773\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "1 + 118 = 119\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.009438603276134699\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "96 + 76 = 172\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0005430271317858102\n",
            "Pred:[0 1 0 0 0 1 1 0]\n",
            "True:[0 1 0 0 0 1 1 0]\n",
            "19 + 51 = 70\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.003360992842136829\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "81 + 26 = 107\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0008899368275487152\n",
            "Pred:[1 0 1 1 0 0 1 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "67 + 111 = 178\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0014594423476013963\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "63 + 81 = 144\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxc5Xno8d8zuzTaN1uWZUnGNl5YDIgtJEBCMJC0QNKkNUkbkibl0yQ03dJbaO8NveTT3jS9t+1Nm4ZyU5o0TSCFhEAoS0ggkJTVgDHGO7ZsSZYtabSPltHMvPePOWc0kmaTPLKlo+f7+cyHmXPOzLxHY55553mf875ijEEppdTy4TrTDVBKKXV6aeBXSqllRgO/UkotMxr4lVJqmdHAr5RSy4znTDcgnZqaGtPc3Hymm6GUUkvGa6+91muMqc3n2EUZ+Jubm9mxY8eZboZSSi0ZInI032M11aOUUsuMBn6llFpmNPArpdQyo4FfKaWWGQ38Sim1zOSs6hGR+4BfAbqNMeek2f8nwMdTXm8TUGuM6RORNmAYiAFRY0xroRqulFJqfvLp8X8LuD7TTmPM3xhjthpjtgJ3As8ZY/pSDnmvtV+DvlJKLQI5A78x5nmgL9dxlluA+0+pRafgaz87yHMHes7U2yul1JJQsBy/iBST+GXwg5TNBviJiLwmIrfleP5tIrJDRHb09MwveN/z3Dv8QgO/UkplVcjB3V8F/mtGmufdxpgLgRuAz4vIlZmebIy51xjTaoxpra3N66rjWfweFxPR+Lyeq5RSy0UhA/92ZqR5jDGd1n+7gYeBSwr4frP4PW4morGFfAullFryChL4RaQcuAp4JGVbUERK7fvANmB3Id4vE79Xe/xKKZVLPuWc9wNXAzUi0gHcBXgBjDH3WId9CPiJMSac8tQVwMMiYr/P94wxTxau6bP5PS4iGviVUiqrnIHfGHNLHsd8i0TZZ+q2w8D5823YfCRSPRr4lVIqG0dduZsY3NUcv1JKZeOswO91MTGpPX6llMrGWYFfUz1KKZWTwwK/pnqUUioXBwZ+7fErpVQ2Dgv8bs3xK6VUDs4K/F5N9SilVC7OCvya6lFKqZwcFvi1qkcppXJxWOB3EYsbojEN/koplYmzAr83cTra61dKqcwcFfh9bg38SimVi6MCv9/rBtDKHqWUysJZgd9j9fi1ll8ppTJyWOC3e/wa+JVSKhOHBX47x6+pHqWUysRZgV+repRSKidnBX471aM5fqWUyshhgT9xOpGYpnqUUiqTnIFfRO4TkW4R2Z1h/9UiMigiO63bl1L2XS8i+0XkkIjcUciGp5NM9WiPXymlMsqnx/8t4Pocx/zCGLPVut0NICJu4OvADcBm4BYR2Xwqjc1Fq3qUUiq3nIHfGPM80DeP174EOGSMOWyMiQAPADfN43XyplU9SimVW6Fy/JeLyJsi8oSIbLG2NQDtKcd0WNvSEpHbRGSHiOzo6emZVyOmAr/2+JVSKpNCBP7XgSZjzPnAPwA/ms+LGGPuNca0GmNaa2tr59WQ5JQNmuNXSqmMTjnwG2OGjDEj1v3HAa+I1ACdQGPKoautbQtGUz1KKZXbKQd+EVkpImLdv8R6zRDwKrBeRFpExAdsBx491ffLxuMSXKKpHqWUysaT6wARuR+4GqgRkQ7gLsALYIy5B/gI8FkRiQJjwHZjjAGiInI78BTgBu4zxry9IGcx1VZdhUsppXLIGfiNMbfk2P+PwD9m2Pc48Pj8mjY/fq+LiUlN9SilVCaOunIXdMF1pZTKxYGBX1M9SimVjQMDv0urepRSKgvnBX6vS+v4lVIqC8cFfp9bc/xKKZWN4wJ/IsevqR6llMrEeYHfqz1+pZTKxnmB36M5fqWUysaBgV9TPUoplY0DA7+LiKZ6lFIqI+cFfs3xK6VUVs4L/HrlrlJKZeXAwK9X7iqlVDYODPxuJmOGWNyc6aYopdSi5LzA702ckg7wKqVUes4L/Lr8olJKZeXAwG8tuK49fqWUSsuBgd/q8evVu0oplZbzAr9XUz1KKZVNzsAvIveJSLeI7M6w/+MisktE3hKRF0Tk/JR9bdb2nSKyo5ANz0RTPUoplV0+Pf5vAddn2X8EuMoYcy7wZeDeGfvfa4zZaoxpnV8T50YHd5VSKjtPrgOMMc+LSHOW/S+kPHwJWH3qzZo/zfErpVR2hc7xfxp4IuWxAX4iIq+JyG3Znigit4nIDhHZ0dPTM+8G+L2a6lFKqWwKFvhF5L0kAv+fpmx+tzHmQuAG4PMicmWm5xtj7jXGtBpjWmtra+fdDk31zN+9z7/D4Z6RM90MpdQCK0jgF5HzgG8CNxljQvZ2Y0yn9d9u4GHgkkK8XzZTgV97/HMRnojyV4/v48dvdp3ppiilFtgpB34RWQP8EPgtY8yBlO1BESm17wPbgLSVQYXk0xz/vIxMRAH9paTUcpBzcFdE7geuBmpEpAO4C/ACGGPuAb4EVAP/JCIAUauCZwXwsLXNA3zPGPPkApzDNFPlnBrA5iJsBf5x/cJUyvHyqeq5Jcf+zwCfSbP9MHD+7GcsrKkLuJZ+AOseGmciGqexqnjB3ys8kfiiHNcvTKUcz3lX7joox/9nD+9m+70vET8NU0yPJHv8GviVcjrHBX6f2zmB/8DJYToHxnjxcCj3waconMzxL/2/m1IqO8cFfhFxxCpckWicjv5RAH7wWseCv184YgV+7fEr5XiOC/xgLb+4xAcpj/WNEjdQHfTxxO4TyVTMQhnRwV2llg1nBn7v4lxw/ZcHewmNTOR17JHeMACfvfosxiZjPPHWwtbXhzXHr9Sy4czAvwhTPZOxOJ/811f4q8f35XV8mxX4P3LRalpqgvzg9YVN94xoVY9Sy4aDA//i6vH3hyNE44an3j7BWCR3cD3cG6Yq6KOi2MeHL2jgpcN9tPeNLlj7koO7mupRyvEcGvjdiy6A9Y5EgEQu/em9J3Mef6R3hObqRP3+hy5sAOCHr3cuWPuSqR7t8SvleM4M/N7Fl+rptXL7IvCjN3IH8CO9YVpqSgBYXVnM5Wur+fGu4wvWPh3cVWr5cGbgX4SpnlA4Efi3bV7Bcwd6sg7yhieinByaYG1tMLmttbmSwz0jRBbovHRwV6nlw6GBf/FV9YSsVM9n3rOWWNzw2K7MVTptocTAbnP1VOBvrg4SNyRr+wstbI07LLa/m1Kq8Bwa+F0LciHSsdAof/rQLh7Z2Zm1rv6NY/1EY9MDaO9IBJ/bRWtTJZvqy3g4S7rHLuVsqUkJ/NZ9+0uh0OwefyQaPy1TRCilzhxnBn6ve0FSInc/tofv72jn9x/YyYVffprP/vtrs74AjvSG+dA/vcB/zqi7D41MUF3iQ0T40AWr2Nk+kAzwM9mlnM01U5Oz2QO9R3oXqMefch7a61fK2ZwZ+Bcgx7+jrY+f7j3JH1+7gYd+93JuPH8VT+w+wWtH+6cdd6g7sYLVzNLLUDhCdYkPgBvPb0AEHt2ZfrD2cG+YlWUBin1Tk6dWBX2UBjzJL4VCs+v4QfP8SjmdgwN/4YKXMYa/fnIftaV+Pv2eFlqbq/jT6zcCcGTGUoVHrVRM1+D4tO2hkQmqg34AVpYHWFdbwu7jg2nfL1HRE5y2TURoqQkuaKqn1J/4otGSTqWczaGB/9Tq+I8PjPHk7i4mrTz9s/u7ebWtny9csz7ZC68p8VHi99AWmt6zt9M3J4emB/7ekakePyTy95lSPUd6w7TUBmdtb67O/JxTEYsbxiZjyfYttmsglFKFlXMhlqUoUcc/v+D1wqFePv+91+kfnWR1ZRGfu3od//ZiG03VxWy/uDF5nIjQXFM8KxAftb4IUnv8xhh6RyaoKfEnt7XUBnl2fzexuMHtkuT2/nCEgdFJ1takCfw1QR7bdZyJaCy50lgh2DNzVgV9tIVGtcevlMM5ssfvc7uIxOZWnWKM4Zu/OMxv3fcK1SV+/s9Hz6e6xM+fPfwW+04M88fbzsbrnv7naqkpmRX47VTMiZTAH47EmIjGqQ5O9fjX1gSZjBk6+8emPf9ImlJOW3N1MXED7X1js/adCntgt9r6YtKLuJRyNsf2+AEisTgBV+6e8WQszp/98C0efK2D67as4P/8+lZK/B4+fGEDzx/sZW/XEL9ybv2s57VUF/Ofu44TicbxWeMKxwfG8HtchMKRZM/cvlirOqXHbwf2I6Ewa6qnqneO9FilnOlSPXZJZ2+YdXUl+f45crIDf42V6tHBXaWczZE9/uSC63n0XIfHJ/ntb73Kg6918IVr1vONj19EiTXIKSJctaGW373qLFwp6RhbS23ioqpjVgVPe98YcQMXrqkEoHsoEfDteXqm5fitwD5zcLgtFMbtEhorZ6+z21JdmFr+2IxfQnZFT5X1i0TLOZVytrwCv4jcJyLdIrI7w34Rka+JyCER2SUiF6bsu1VEDlq3WwvV8GyS6+7GsvdcTwyO89F7XuTFd0J89SPn8UfXbkgb4DOxe+12iaVd0XPZ2mpgKs9v9/hrU3r8tSV+SvyeWamiw71hVlcW4fPM/mgqgz7Ki7ynNMDbNTjG5i89Oa0MNZnqCdqpHu3xK+Vk+fb4vwVcn2X/DcB663Yb8A0AEakC7gIuBS4B7hKRyvk2Nl/JwJ+jx/9nD79Fe98o933yYn69tTHrsenYJZd2ILYrfC5bWwXACauyJxSe3eO3yzMPzwji+08Ms642cxqnubo4OYA8H3u7hpiIxtl/Yji5bSrHr6kepZaDvAK/MeZ5oC/LITcB/2YSXgIqRKQeuA542hjTZ4zpB54m+xdIQfi9VqonS8qiZ3iC5w70cOu7mrlyQ+283qei2EdlsTc5INvWG6Y04GHTqjIATgwmBmHtHn9VyuAuzC7pHBiNcKh7hAubMn83NmcpA82HPTCcOkmcXdVj9/i1nFMpZytUjr8BaE953GFty7R9FhG5TUR2iMiOnp6eU2pMssefpSzxx28eJxY3fOiCtM3JW3NNMDkg2xYK01wdpCzgpcTvSaZ6ekcilAY8s0owW2qCdA6MJdtpp18uyhb4q4McHxybd6/cHo+wf4XAVI4/2ePXck6lHG3RDO4aY+41xrQaY1pra+fXA7dNBf7MPdcf7ezknIYy1q8oPaX3Sr2a9mholCarQmdFmT95EdfMGv7U5xqTmPwNYMfRfjwu4fzVFVnfz5jZU0LkK13gn5nq0R6/Us5WqMDfCaQmyVdb2zJtX1C5qnoOdY+wq2OQm7eeWm8fEpU2XYPjDI1P0tE/msz715cXpQzuRqbV8Cefax1r5/lfa+tnS0M5Rb7MJajNM8YV5sr+wpiW6pmI4hKoKNIcv1LLQaEC/6PAJ6zqnsuAQWNMF/AUsE1EKq1B3W3WtgVl1/HbKZSd7QPs7pyaF+dHb3TiErjx/FWn/F52WeYvD/YSN9BkVfqsLA8kL+IKhSemDezaUoN4JBrnzY4BLlqTfezbnqVzPgO8xpipHv9IaqonStDnwesWXKKpHqWcLq8LuETkfuBqoEZEOkhU6ngBjDH3AI8DHwAOAaPAp6x9fSLyZeBV66XuNsZkGyQuiNRUTzxu+My3dzA4FuF/f/R8fvW8VfxoZyfvXl9LXVnglN/LLul8dl+39TgRmFeWBegeniAWN4RGIrQ2V816bnmRl5oSH0d6wrx9fJCJaJzW5uyBv6LYR0XKgPJchMIRRiMx3C5JrggGiR5/0O9BRAh43XrlrlIOl1fgN8bckmO/AT6fYd99wH1zb9r8JVM90ThvtA/QOzLBijI/v//ATp470ENH/xh/vG1DQd7LTtc8dyAxIJ3a44/FDSeHxukbjVCTJtVjP/9IKJwc2G3NMrBra64Ozmt6Zru3v3FlKXu7hojHDS6XEJ6IEfQn/mYBr3vRrVeslCqsRTO4W0hTdfwxnt5zEo9LeOz33sMHz6vnh693Uuxzc92WlQV5r6DfQ12pn+7hCUr8nuS0B/XliV8Te7uGMAZqSmcP7sJUSeeOtn4aq4ry+hXSUjO/wG/n97c2VhA3MDA2CSRSPfbVygGPS3v8SjmcMwO/dyrV85M9J7h0bRW1pX7+YfsFfHHbBu64YeO0RU5OlZ2rb6ouRiRx5e8KK4Dv7hwCpmrkZ2qpKaFneIIXD4dobZqdDkqnoaKIE0Pjs6ZeyMUO/HbVkD3Aa6d6ACvVoz1+pZzMmYHfSvXs7RricE+YbZsTvXuXS7j9fev5xOXNBX0/ewrl1Bk17R6/vdhKusFdgBZrecXBscms9fupakp8xA30j0ZyH5ziWN8odaV+VlcWAVMlnSMpgd+nPX6lHM+hgT9xWk/sPgHA+zevWND3S+3x26qCPnxuF29b1UQ1GQP/1PQMuQZ2bXbaKLUyJx/H+kZZU1VMldUW+/nhSJSgT3P8Si0Xjg78feEIW1aV0VBRtKDvZw/wNqcsniIirCj3c9wq6cyU6kmkh6DU72F9XX4Xk9mv1ZtSi5+P9r4x1lQVJ59vV/aMTsRSUj0uvYBLKYdzZOAXkeTsltcucG8f4OLmKq5YV80V62qmba8vS3zhuF1CeZE37XMDXjeNlcVc1Fw5bSWubGpLEz32uQT+SDTO8cExGquKqSz2IjLV4582uOt1ax2/Ug7nyIVYINHrj0TjpyXwVwV9fPczl83avtLK81cFfVmne/7Gb15IWSD9F0M6Uz3+/FM9nQNjGAONVcV43C4qiryEwhNEY3EmovFkj9/vcengrlIO5+DA76aswsvm+rIz1gY78KebriHVllXlc3rd8iIvHpdMm3YhF7uGf01VYhyiusRPaCRC2JqgbXpVj6Z6lHIyxwb+S1uqOG91ebK88kxYaZV0ppug7VS4XEJV0DenVM+swB/0ERqJMGJNyVxiX8Dl0cFdpZzOsYH/6x+/MPdBC8zu8Weq6DkVNVaPPV8dfaP4PC7qrIqg6hIf+08MJ2fmTB3c1R6/Us7myMHdxSKZ6ilwjz/xmj56w/kH/mN9ozRWFiXHGqqDfkLhCCOzAr9ewKWU02ngX0D1KYO7hVZb4qd3eG6pHjvNA4kvjoHRSQataRtKUgZ3J6JxEtMvKaWcSAP/AlpZFuDPP7CJm09xla90qkt8hMITeQVoYwzHQqM0Tgv8iV8hHVbuP2hNYZHPspVKqaXNsTn+xUBE+J0r1y7Ia9eU+BmfjBOOxJK99UwGxyYZnohO7/Fbv0Lsef1T6/ghsYiNfV8p5Sza41+i7B57PiWddkXP6srZgd/eNzUtc+KfhF7EpZRzaeBfouxKoXxKOu2VwFZVTE35bH9xTAV+O8ef+ALQAV6lnEsD/xJlXxuQz9W79jGp1xOk9vjdLknOb5Ts8WtJp1KOpYF/iZoK/Ll7/PYxqVNDlxd5cbuE0UiMoM+dvNAtkFy9THv8SjmVBv4lyi4Rzecirt6RCcoCnmQaB6au/gWmDQ7bA7ra41fKufIK/CJyvYjsF5FDInJHmv1/JyI7rdsBERlI2RdL2fdoIRu/nPk8LsqLvHn3+NMt/Wine4Ipgd+fTPVoj18pp8pZzikibuDrwLVAB/CqiDxqjNljH2OM+cOU438PuCDlJcaMMVsL12Rlqy7x5dfjH46knS/ITv2kBv6ADu4q5Xj59PgvAQ4ZYw4bYyLAA8BNWY6/Bbi/EI1T2dWU+OnJs8dfmy7wW9M7T0/1TK1XrJRypnwCfwPQnvK4w9o2i4g0AS3AMymbAyKyQ0ReEpGbM72JiNxmHbejp6cnj2apmhJfXnX8PSMTaSeKq0qmeqZy/1M5fu3xK+VUhR7c3Q48ZIxJjRpNxphW4GPA34vIWemeaIy51xjTaoxpra2tLXCznKmmxJ+znHN8MsbweDRtqqcmTaonmePPo8f/alsfLxzqnUuTlVKLQD6BvxNoTHm82tqWznZmpHmMMZ3Wfw8DP2d6/l+dguqgn8GxSSJZgnTImsEz7eBuyexUj135M5FHj/8rT+zjLx/fO6c2K6XOvHwC/6vAehFpEREfieA+qzpHRDYClcCLKdsqRcRv3a8BrgD2zHyump8aa+3dvizTM9szeKbr8VelqeqZS47/WN8oPXOYIVQptTjkDPzGmChwO/AUsBf4D2PM2yJyt4jcmHLoduABM326yE3ADhF5E3gW+EpqNZA6NVNr7yaC72QszpvtA9OOsffVpunx26me1B6/z+1CJHeOf3wyRs/wBKFwhFhcp3BWainJa3ZOY8zjwOMztn1pxuO/SPO8F4BzT6F9Kova0unz9XzzF0f46lP7eOGO91FfXjRtX7rBXfuLo9g3NbgrIgQ8uRdj6ehPzPETixv6wpG0XyxKqcVJr9xdwuzAHRqJYIzh4Tc6MAbe6Q4nj0k3T4+tsaqYT13RzPs21k3b7s9j+cX2vrHkfU33KLW0aOBfwuwB296RCfZ2DXPg5AgAbaGpwN8zPEGp35N2bn23S7jrV7fQVB2ctn0uPX4g67UE33/1GO/56jO6opdSi4gG/iUs6HPj97gIhSM8srMTj0vweVy09ab2+NNP15BNwOvKObjb3j/V4+8eGs943BvHBmjvG2NMrwtQatHQwL+EiQg1JX66h8Z59M3jXLmhlpbqIG2hqd54b4aLt7LJZ8H19r5RGioS4wjZevzHrbUAhsejc2qDUmrhaOBf4mpKfDy7v4euwXFu2rqKpupijoam5/jT5fez8XvdOS/gau8fZV1dCaV+T9Ycf9dA4peBBn6lFg8N/EtcTUniIq5in5trN6+gpSbI0b5R4laJZaLHP8fA73Hl0eMfo7GqiNpSf8bAb4zheDLwT86pDUqphaOBf4mzZ9i8bstKin0emqqDRKJxuobGiUTjDIxOzjnwB7zurDn+ofFJBscmaawspqbUT3eGwD80HiUcSXyBjExoj1+pxUID/xJnB/Wbtq4CoLkmsaD60d4wobBVw186xxy/x5V1yob2lMXba0v9yauDZ7J7+wAjmupRatHI6wIutXi9d2MdHf1jvHtdDQDNVmnmkVCY0oAXSF/Dn02uwd0Oq6KnsaqIulI/z2cI/F2DU4Ffc/xKLR4a+Je4i5uruLi5Kvl4ZVkAv8fF0dAoq6yrd+eX48+c6rF7/I1Wj394IspYJEaRb/q1Ap0DU2Wew5rqUWrR0FSPw7hcQlN1MW294WSZZbpFWLIJeN2MZ1lsvaN/jBK/h4pib/K10w3wdg2M4XElFnHXwV2lFg8N/A7UVB2kLRSemqdnrjl+r4uJHD3+1ZVFiEhyjp6ekdkXcXUNjrOyPECxz605fqUWEQ38DtRcXczRUGLK5GKfm2Lf3DJ6do8/0zQL7f2jNFYlBpHrSgNA+h5/58AYq8qLKA14NMev1CKigd+BmmuCTETjvN05NOf8PiRy/MZAJDa712+MSdTwVyYCv93jT1fS2TU4Rn1FgBK/R8s5lVpENPA7kF3Z82bHwJyna4DUdXdnB/6+cISxyRiNVYmB46qgD5fM7vHH44YTg+OsqiiiJOBlSHP8Si0aGvgdqKk60RufiMbn1+O3Av9EmgFee3I2u8fvdgnVJbOv3u0dmWAyZlhVHqAskLvHr1M7K3X6aOB3oFXlRfg8iY92rjNzQuICLiDtAG/y4i2rxw9Ql2baBntytlUVRYlUT5Yc/2tH+7n4L3/Kp/71FY6kzCyqlFoYGvgdyOUS1liDr/Pp8U+letL1+Kdq+G21aaZtsK/arc9jcPetjsRykS8f6eO6v3uev3lqX3KuIaVU4Wngd6hmK91TO48cv9/q8afL8bf3jVEV9E1boL02TarHDvyrKgKU+L1ZUz1toVGCPjc//+LVXHfOSr7+7Dv84lDvnNutlMpPXoFfRK4Xkf0ickhE7kiz/5Mi0iMiO63bZ1L23SoiB63brYVsvMrMHuA9lR5/uhx/R/8ojZVF07bVlvrpHZmY1ks/PjBOsc9NeZGXUivHn2lR9rZQmOaaIHVlAf5k29mA5vyVWkg5A7+IuIGvAzcAm4FbRGRzmkO/b4zZat2+aT23CrgLuBS4BLhLRCoL1nqVUVNNIvDPZxH0bFU9h3sSQTpVXamfaNwwMDZVudM1OEZ9eQARoTSQ+HUQjqTv9bf1Tr1meVFifqHBMa0CUmqh5NPjvwQ4ZIw5bIyJAA8AN+X5+tcBTxtj+owx/cDTwPXza6qai6s31HLt5hVsqi+b83MDXjvVM73HPzAaoXNgbNZr1loXcXUPT129e3xgjFXWCl124E+X55+MxWnvH6PF+oVSGvAgooFfqYWUT+BvANpTHndY22b6NRHZJSIPiUjjHJ+LiNwmIjtEZEdPT08ezVLZNFYV8/8+0TotF58vv8fq8c9I9ezpGgJg86zAP3u+nuOD48lJ4kr8iV58usqejv4xYnGTLEF1uYRSv4chDfxKLZhCDe7+GGg2xpxHolf/7bm+gDHmXmNMqzGmtba2tkDNUvMx1eOfnurZ2zUMkKbHPz3wT0Rj9AxPJHv8Jcke/+xgbi8M35KSPiov9mqPX6kFlE/g7wQaUx6vtrYlGWNCxhi7u/dN4KJ8n6sWn0yDu3uOD1Fb6p81bjBz2oaTg4n/1lckUkDJVE+ayh67bj913KC8SAO/Ugspn8D/KrBeRFpExAdsBx5NPUBE6lMe3gjste4/BWwTkUprUHebtU0tYgFP+sHdPV1Ds9I8ACV+D8U+d7LHf9xagMVO9ZRa6aZ0qZ62UJhSv4fq4FTZqQZ+pRZWzgSwMSYqIreTCNhu4D5jzNsicjewwxjzKPAFEbkRiAJ9wCet5/aJyJdJfHkA3G2M6VuA81AF5E8zuBuJxjnUPczVZ6dPw6Uuup5aww8kVwJLN7jbFhqluSaIiCS3lRd5OTk0UoAzUUqlk9fInzHmceDxGdu+lHL/TuDODM+9D7jvFNqoTjN/csqGqcB/qHuEyZjJWCVUW+LnWN8oO9sHeLUt8d1eXz49xz8ykT7Hf35jxbRt2uNXamHp0otqFhEh4HVNy8lnquix1VcU8eM3j3Pz1/8LgIaKouRSjEGfG5HZPf5INE5H/yg3WwvF28qswG+MmfZLQClVGBr4VVoXrqnkp3tP8j8+uBmXS9jbNUTA65pWfZPqjhs28r6NtZQFvJQXeacdJyKU+GfP19PeP0rcMOuCsD4sXu8AABWTSURBVPIiL5FonPHJ+Kx1fJVSp07n6lFp/cbFjbT3jfHCOyEgUdFz9soy3K70PfCGiiI+dMFqrtm0gtbmKqpnTBVRmibw26WcTdWzAz/oRVxKLRQN/Cqt67aspLzIywOvHsMYk7GiJ1+lAe+sHP+RNDX8oIFfqYWmgV+lFfC6+dAFDfzk7ZO8fXyIwbFJNteXzvv1StJMzdwWClMW8FBZ7J22XQO/UgtLA7/KaPsljURicf7q8cRlGZtXnUqPf/YqXG29o7TMKOUEDfxKLTQN/CqjjSvL2NpYwQvvhBCBs1fOP/CnW4XLno55Jg38Si0sDfwqq+0XJ2bcaKoqpmQeE77ZSgNehlIC/0Q0xvGBseS6Aak08Cu1sDTwq6x+5fxVBH1utjSUn9LrJFI9U4G8vS9RypmuPNS+0lcDv1ILQ+v4VVYlfg/f+53LqJ7HEo6pSv0exifjTMbieN0ujvQm1u5Nl+pxuxKLt+jUzEotDA38KqeZUyrMR3LahvEolUEfh7oTc/FkuiBMp21QauFoqkedFvb4gF3SefDkMCvLAsl8/kwa+JVaOBr41WmRnKHTyvMf6B5m/YqSjMdr4Fdq4WjgV6dF6rq78bjhUPcIG1ZkviBMA79SC0cDvzotSlNy/O39o4xPxtmgPX6lzggN/Oq0sHP8IxNRDpxMDOyuP4Uef+fA2LSFYpRS+dPAr06LqVW4JjlwMrFo+/q6LD3+Yntq5tnBPRKNc/3fPc89z72zMI1VyuE08KvTInXB9YMnh1lVHkh+GaST7erdw70jDE9EeePYwMI0VimH08CvTgu/x4XXLQyPJ1I92dI8MBX4B0ZnB/79JxK/GOxVwZRSc5NX4BeR60Vkv4gcEpE70uz/IxHZIyK7RORnItKUsi8mIjut26OFbLxaOuxVuAbHJnmnZyTrwC5k7/Hv7UoE/p7hCbqHxwvfWKUcLmfgFxE38HXgBmAzcIuIbJ5x2BtAqzHmPOAh4Ksp+8aMMVut240FardagkoCHvYcH2IiGs+7x58u8O87MYTHWgnM/hJQSuUvnx7/JcAhY8xhY0wEeAC4KfUAY8yzxphR6+FLwOrCNlM5Qanfy9vHBwGy1vBDjsDfNcyVG2qBxJKQSqm5ySfwNwDtKY87rG2ZfBp4IuVxQER2iMhLInLzPNqoHKIk4GEyZoDsFT2QOfAPjEY4MTTOpS1VNFQUsVfz/ErNWUEnaROR3wRagatSNjcZYzpFZC3wjIi8ZYyZVYcnIrcBtwGsWbOmkM1Si0SZVdnTUFFEMMfc/pmmZt5nDexurC9j86oyHeBVah7y6fF3Ao0pj1db26YRkfcDfw7caIyZsLcbYzqt/x4Gfg5ckO5NjDH3GmNajTGttbW1eZ+AWjrsi7hyDexC5qmZ91mBfuPKUjbXl3G4Z4SxiF7IpdRc5BP4XwXWi0iLiPiA7cC06hwRuQD4ZxJBvztle6WI+K37NcAVwJ5CNV4tLXYvPld+35bu6t39J4epLPZSV+pnU30ZcZPYppTKX87Ab4yJArcDTwF7gf8wxrwtIneLiF2l8zdACfDgjLLNTcAOEXkTeBb4ijFGA/8yZc/Jn6uix5Yu8O/tGmbjyjJEhC3W4u86wKvU3OSV4zfGPA48PmPbl1Luvz/D814Azj2VBirnmEuqB2YH/njccODkML/emsg8rq4sotTv0QFepeZIr9xVp80FjRWcv7p83qme9v5RRiMxNtUnni8ibNIBXqXmTAO/Om3eta6GR25/NwGvO6/jZwZ++2KtjSvLkts215ext2uIeNwUtrFKOZgGfrVozQz8+04MITJ9cHhzfRmjkRhH+0bTvYRSKg0N/GrRKiuaPjXzvq5hmquDFPmmfjFs1gFepeZMA79atGZevbv/5DAbV04fH1hXV4LHJezpGjzt7VNqqdLArxat1MD/ypE+2kLhafl9gIDXzYYVpezq0MCvVL408KtFyw78P3i9g9/6l5dZWxPklksbZx23dU0FO9sHdIBXqTxp4FeLlh34//m5w2xcWcqDv/su6koDs467oLGC4fEoh3tHTncTlVqSNPCrRauuzA/AFeuq+e7vXEZV0Jf2uAvWVABkXYrx5NA4feFI4Rup1BJU0Nk5lSqk+vIiHvu9d7NhRSk+T+Y+ytqaEkoDHt5oH+CjrVOpoMM9I3zv5WM8f7CHAydH2LiylCf/4MrT0XSlFjUN/GpRO6ehPOcxLpewtbGCnSk9fmMMn/n2DjoGxri0pYqm6iBP7zlJW2+Y5prgQjZZqUVPUz3KES5orGDfiSFGI1EA3uoc5HBvmC/ftIXvfPpS/vsHNwHwzL7ubC+j1LKggV85wtY1FcQNvGWVdT6y8zg+t4vrt9QD0FQdZF1diQZ+pdDArxxia2MlAG+0DxCLG3785nGuOruW8mJv8phrNtbx8pEQw+Oz1/FVajnRwK8coSroo6m6mJ3HBnj5cIju4Qlu2rpq2jHv21jHZMzwy4O9yW3fffkoH/t/LzER1VW81PKhgV85xgWNFbzR3s8jO48T9Lm5ZuOKafsvaqqkLODhZ1a6p71vlC8/tocX3gnxwCvtZ6LJSp0RWtWjHGNrYwU/2nmcR97s5APn1E+bzA3A43Zx9dl1PLuvm3jccPdje3CJcG5DOf/wzCE+2rqaYl9h/5fY2zXEw2900tk/RjgSZXQixkdaVycXk1HqTNDArxzjgjWJPP/4ZJwbZ6R5bNdsquPRN4/z9z89wNN7TnLHDRu5uLmSX/vGi3zrhTY+d/W6eb33G8f6+eKDb+JxuVi3ooQ1VcX88mAvb3UO4nO7WFNdTNDnpm80wl2PvM171tdQX14073NNZyIa42holOHxKBc0VuBySUFfXzmHBn7lGJvqy/B5XJT4PVyxribtMVdtqMUl8LVnDrGuroTfvqIFn8fFNRvruOfn7/DxS5uSU0Xk65l9J/n8d9+gusRH84ogb3UM8vhbXZy9opS7fnUzN29toNK66ri9b5T3/+1z/OV/7uUfP3bhKZ8zwCtH+rjzh7s40hvGnq7o1sub+IsbtyCiwV/NpoFfOYbP4+Jjl6xhdWURXnf64auKYh+tTVW80tbHl286J3lF8B9t28AHv/ZLvvazg9y8tYGTQ+OMTERpqCyiqbqYUr+Xl4+EeO5AD7s6BmmqLua8hnKiccP/emIfm+pL+ddPXkJtaWKaiUg0jtctswJvY1Uxn736LP7+pwf52KW9vOus9F9Q+ToaCnPbd3ZQXuTl9veu46y6El4/2s+3XzxKwOfmjus3zmrDwZPD/PWT+9i2ZeW8Uk5jkRjt/aMEPG4CXhelAe+stJpa3MSY3DMaisj1wP8F3MA3jTFfmbHfD/wbcBEQAn7DGNNm7bsT+DQQA75gjHkq1/u1traaHTt2zO1MlMrTy4dD7D85zCcub562/fbvvc5ju7qyPtfvcXFOQznH+kbpGZ4A4D3ra/jGb16UXEw+l/HJGO//2+cI+jw89oV30zsywU/3nGRwbJKzaks4q66Epupi/J7swXRofJIP/9ML9I5M8KPPXZG8ItkYw/94ZDf//tIx/uD96/nC+9bjcgnxuOFbL7TxlSf3EY8bonHDr7eu5u6bziHgdRONxdnVOUh4IkrQ76HE72FNVfG0pTKfO9DDnz60ixND49PaUhX00VBRxPq6Em44t54rN9Tg97g5Fhrlh2908NLhEF63iyKvm6DfQ02JjxVlAVaWB7ioqXJeaa8DJ4fxul20ZLkSOxY3hEYmCEdihCeilAW8rKkuzvl3PRYapaN/lJ6RCI2VRaxfUcqq8sCi/gUlIq8ZY1rzOjZX4BcRN3AAuBboAF4FbjHG7Ek55nPAecaY3xWR7cCHjDG/ISKbgfuBS4BVwE+BDcaYrLVzGvjVmRAameCpt09SbQWloM9Nx8AYx0KjhMIRWpsquaSlKhkITw6N0943yvmNFRl/YWTyk7dPcNt3XqOxqoj2vrG0x9SV+lldWURTdZANK0rZuLKUxqpiXAIGuPvHe/ivQ71859OXcvlZ1dOeG48b/uShXfzg9Q58HhdNVcV43C72dg1xzcY6/urD5/LvLx3lH545xOb6MlpqgvziYA9D49Fpr1Psc3PNphV84JyVPH+wh/tfaWddXQmfveosDIkvscGxSTr6x+gcGOOtjgH6RycpC3hoqQnyZscgInBuQzkuEcYnY4xMROkZnmAiGk++T0tNkMvWVrO6sojKYh9VQS8NFcWsqS6elnqLxQ0/23uSb/7yCK8c6QNgfV0J27asYOPKMkRAEI71jfLykRA72voZmZh+Tuc3VvBrFzZw3ZaVVAd9eNwuhscneeKtEzz0ekfydWcq9Xt436Y6bt7awLvX1/BW5yAP7mjnid0nqC8v4qoNtVy5vobBsUlebevnjfZ+akv83HDuSq7ZtIKyQGJFuZ6RCeJxQ22pP+/1p/NR6MB/OfAXxpjrrMd3Ahhj/lfKMU9Zx7woIh7gBFAL3JF6bOpx2d5TA79yOmMMX3xwF0d6R7h280qu3byCVRUBDveEeadnhCO9YTr7x+joH6MtFKZrcDzt63zlw+ey/ZI1affF4oZH3+xkX9cwh3vDdA+N8xsXr+GWSxqTPddn9p3kiw/uwusWrtpQy1Ub6qgr8zMyEWV4PMpLh0M8ufsEfeEIInDbe9byh9duyBiwJmNxfnmolx/vPM47vWG2bV7BzRc00FAxvUdvjGFoPEp73ygvHQ7x4jshXmnrY3jGFw8kpuf2e1zE4obxyRjhSIyGiiI+dUUzHpfwkz0neflIH7EZ6zGsqyvhkpYqNtWXUeJ3U+zzcCw0yg9e72DfieHkcUVeN7G4IRKLs7YmyI1bV3H2ilJWVxZTXeKjvW+Ug90jvNUxyJNvn2BwbBK/x8VENE6R1837N6+gZ3icHW39RK02+D0uzltdTnvfGCeGxvG5XZQGPIRmzBBb4vdQ7HMTjRsmY3Eqi308/9/em/Zvm0uhA/9HgOuNMZ+xHv8WcKkx5vaUY3Zbx3RYj98BLgX+AnjJGPPv1vZ/AZ4wxjyU5n1uA24DWLNmzUVHjx7Np/1KLQuDY5McODnM8YGpXwcrywJcurY6y7PyE4+bRE85QxojGovzypE+KoM+NtWXpT2mUMYnY/SPRgiNROjoH+NYX5hjfaPE4ga3S/C4XFzcXMV1W1bgSfmVNTg6SffwOHY0qwr6qCnxZ3yfPceHrKu4owyNTeJ2Cdefs5KtjRVZ0zmRaJyf7+/m5wd6OK+hnA+eV09pIPGLZHh8kh1t/VQUe9myqhyfx0U8bnijfYCn3j7B8PhkIr1VFkAEekci9AxPMD4Zw+MWvG4XZQEvf3jthnn97eYS+BfN4K4x5l7gXkj0+M9wc5RaVMqLvFzcXLUgr52r7NPjdvGuDFVShRbwuqkvL6K+vCivmVlt5cXeadNz5LJ5VRmbV839S8zncbFty0q2bVk5a19pwMt7N9ZN2+ZyCRc1VXJRU+Wc32sh5ZOY7ARSh/5XW9vSHmOlespJDPLm81yllFKnUT6B/1VgvYi0iIgP2A48OuOYR4FbrfsfAZ4xiRzSo8B2EfGLSAuwHnilME1XSik1HzlTPcaYqIjcDjxFopzzPmPM2yJyN7DDGPMo8C/Ad0TkENBH4ssB67j/APYAUeDzuSp6lFJKLay86vhPN63qUUqpuZnL4K7OzqmUUsuMBn6llFpmNPArpdQyo4FfKaWWmUU5uCsiPcB8L92tAXpzHuUsy/GcYXme93I8Z1ie5z3Xc24yxtTmc+CiDPynQkR25Duy7RTL8ZxheZ73cjxnWJ7nvZDnrKkepZRaZjTwK6XUMuPEwH/vmW7AGbAczxmW53kvx3OG5XneC3bOjsvxK6WUys6JPX6llFJZaOBXSqllxjGBX0SuF5H9InJIRO440+05FSLSKCLPisgeEXlbRH7f2l4lIk+LyEHrv5XWdhGRr1nnvktELkx5rVut4w+KyK2Z3nMxERG3iLwhIo9Zj1tE5GXr/L5vTQ+ONd33963tL4tIc8pr3Glt3y8i152ZM8mPiFSIyEMisk9E9orI5cvhsxaRP7T+fe8WkftFJODEz1pE7hORbmulQntbwT5fEblIRN6ynvM1kTxWhDfGLPkbiemi3wHWAj7gTWDzmW7XKZxPPXChdb+UxGL3m4GvAndY2+8A/tq6/wHgCUCAy4CXre1VwGHrv5XW/cozfX55nP8fAd8DHrMe/wew3bp/D/BZ6/7ngHus+9uB71v3N1v/BvxAi/Vvw32mzyvL+X4b+Ix13wdUOP2zBhqAI0BRymf8SSd+1sCVwIXA7pRtBft8Saxxcpn1nCeAG3K26Uz/UQr0h70ceCrl8Z3AnWe6XQU8v0eAa4H9QL21rR7Yb93/Z+CWlOP3W/tvAf45Zfu04xbjjcQqbT8D3gc8Zv1j7gU8Mz9rEmtEXG7d91jHyczPP/W4xXYjsVrdEaxCi5mfoVM/ayvwt1uBzGN91tc59bMGmmcE/oJ8vta+fSnbpx2X6eaUVI/9j8jWYW1b8qyftBcALwMrjDFd1q4TwArrfqbzX4p/l78H/hsQtx5XAwPGmKj1OPUckudn7R+0jl9K590C9AD/aqW3vikiQRz+WRtjOoH/DRwDukh8dq/h7M86VaE+3wbr/sztWTkl8DuSiJQAPwD+wBgzlLrPJL7eHVWLKyK/AnQbY1470205jTwk0gDfMMZcAIRJ/PRPcuhnXQncROKLbxUQBK4/o406Q87E5+uUwO+4Rd1FxEsi6H/XGPNDa/NJEam39tcD3db2TOe/1P4uVwA3ikgb8ACJdM//BSpExF4mNPUckudn7S8HQiyt8+4AOowxL1uPHyLxReD0z/r9wBFjTI8xZhL4IYnP38mfdapCfb6d1v2Z27NySuDPZ0H4JcMalf8XYK8x5m9TdqUuan8ridy/vf0TVkXAZcCg9TPyKWCbiFRaPaxt1rZFyRhzpzFmtTGmmcRn+Iwx5uPAs8BHrMNmnrf99/iIdbyxtm+3KkFagPUkBsAWHWPMCaBdRM62Nl1DYo1qR3/WJFI8l4lIsfXv3T5vx37WMxTk87X2DYnIZdbf8RMpr5XZmR70KODgyQdIVL+8A/z5mW7PKZ7Lu0n89NsF7LRuHyCR0/wZcBD4KVBlHS/A161zfwtoTXmt3wYOWbdPnelzm8Pf4GqmqnrWkvif+RDwIOC3tgesx4es/WtTnv/n1t9jP3lUOZzhc90K7LA+7x+RqNpw/GcN/E9gH7Ab+A6JyhzHfdbA/STGMSZJ/ML7dCE/X6DV+hu+A/wjMwoF0t10ygallFpmnJLqUUoplScN/Eoptcxo4FdKqWVGA79SSi0zGviVUmqZ0cCvlFLLjAZ+pZRaZv4/d6QNY2f3ih8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0z1O33KE0LA"
      },
      "source": [
        "16->8にすると学習が早くなった。逆に16->32にすると学習が遅くなった。最適な隠れそうのサイズがあることが分かった。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHlK5UZACDI1"
      },
      "source": [
        "## 重みをの初期化を変更"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjwjcM0VD0ti"
      },
      "source": [
        "## Xavier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hrhLz4jhCCUT",
        "outputId": "74f5e5f1-17a2-413e-bc7f-6b98470b840f"
      },
      "source": [
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "# W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "# W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "# W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.0775098281283704\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "2 + 84 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.0316589326882026\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "42 + 78 = 0\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.9412712253229278\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "3 + 114 = 254\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.9737459305490586\n",
            "Pred:[0 0 0 1 0 0 0 0]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "15 + 21 = 16\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.0679713770391772\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "36 + 74 = 0\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0485651239085925\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "42 + 108 = 255\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.9405741442424362\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "39 + 107 = 0\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0039264008065085\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "64 + 46 = 0\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.9562061690854\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "5 + 34 = 255\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.8462240530675252\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 1 1 0 0 0]\n",
            "4 + 20 = 0\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0090619257355378\n",
            "Pred:[1 1 0 0 1 0 0 1]\n",
            "True:[1 0 1 1 1 1 1 1]\n",
            "118 + 73 = 201\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.8053986900027124\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "78 + 54 = 0\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.0494010066554653\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "45 + 106 = 66\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.9591282512057344\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "64 + 42 = 190\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.907016230925323\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "11 + 83 = 255\n",
            "------------\n",
            "iters:1500\n",
            "Loss:1.0488773201729753\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "76 + 98 = 0\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.0344927666101882\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "83 + 73 = 255\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.9492313116039968\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 1 0 1]\n",
            "67 + 2 = 0\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.9750859132758206\n",
            "Pred:[1 0 1 1 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "86 + 24 = 188\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.0076204614909234\n",
            "Pred:[0 0 1 1 0 0 1 1]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "25 + 11 = 51\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.7997549596620954\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "73 + 86 = 255\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.9275025541969624\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "64 + 100 = 128\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.073887411083039\n",
            "Pred:[0 0 0 0 1 1 1 0]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "71 + 42 = 14\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.984591031937615\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[1 1 0 1 0 0 0 0]\n",
            "101 + 107 = 2\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.9890206400499564\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "69 + 27 = 2\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.9660927359082473\n",
            "Pred:[0 0 0 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "104 + 14 = 20\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.9114248628852418\n",
            "Pred:[1 0 1 1 1 0 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "80 + 93 = 185\n",
            "------------\n",
            "iters:2700\n",
            "Loss:1.1487434961961167\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[1 0 1 0 1 0 0 1]\n",
            "43 + 126 = 85\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.701139894362303\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "25 + 34 = 59\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.784787513660601\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "70 + 4 = 8\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.9628104763501439\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "46 + 104 = 212\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.5375216872816748\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[0 0 0 1 1 1 1 1]\n",
            "25 + 6 = 31\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.8472111684722166\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "22 + 95 = 127\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.8313807854754245\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "66 + 108 = 156\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.8571028587515997\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "71 + 95 = 158\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.7351081667967391\n",
            "Pred:[0 0 1 0 0 1 1 1]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "34 + 21 = 39\n",
            "------------\n",
            "iters:3600\n",
            "Loss:1.0294279303621896\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "55 + 27 = 108\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.7856391725185282\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "44 + 65 = 65\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.5274608307951102\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 1 0]\n",
            "66 + 4 = 4\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.6597846784618658\n",
            "Pred:[1 1 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "119 + 36 = 219\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.7397198734660739\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "63 + 39 = 94\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.5877855189339241\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "1 + 86 = 95\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.7534755227484522\n",
            "Pred:[1 1 1 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "93 + 57 = 246\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.8024630567112504\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "77 + 117 = 186\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.7283950310634004\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "96 + 63 = 159\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.4004966700765582\n",
            "Pred:[0 0 1 1 0 0 1 1]\n",
            "True:[0 0 1 0 0 0 1 1]\n",
            "27 + 8 = 51\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.3895108077106563\n",
            "Pred:[0 0 0 1 1 0 0 1]\n",
            "True:[0 0 0 1 1 0 1 1]\n",
            "22 + 5 = 25\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.28865646176884363\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "42 + 60 = 102\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.2102876404525458\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "63 + 54 = 117\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.5301428096500334\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "102 + 21 = 121\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.08135919373535594\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "72 + 12 = 84\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.31665968619771206\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "56 + 81 = 137\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.2796597983787943\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "8 + 105 = 113\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.1520930312954296\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "91 + 68 = 159\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.7853878668877572\n",
            "Pred:[1 1 0 1 1 0 0 0]\n",
            "True:[1 1 1 0 0 0 0 0]\n",
            "113 + 111 = 216\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.3293221253160274\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "115 + 13 = 128\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.1308680870889739\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "55 + 47 = 102\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.2385719403209926\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "31 + 111 = 142\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.11823493087769743\n",
            "Pred:[0 0 1 0 0 0 1 1]\n",
            "True:[0 0 1 0 0 0 1 1]\n",
            "9 + 26 = 35\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.056871744160296785\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "99 + 21 = 120\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.03419555403963004\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "64 + 53 = 117\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.045627379926345454\n",
            "Pred:[0 0 1 0 1 0 0 0]\n",
            "True:[0 0 1 0 1 0 0 0]\n",
            "5 + 35 = 40\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.0360070696767354\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "60 + 20 = 80\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.03800693051814838\n",
            "Pred:[0 0 1 0 0 0 1 1]\n",
            "True:[0 0 1 0 0 0 1 1]\n",
            "9 + 26 = 35\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.042742445220631406\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "80 + 87 = 167\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.04661795471070637\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "20 + 126 = 146\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.02303772806582821\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "59 + 108 = 167\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.025963661932824164\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "63 + 16 = 79\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.018167732592146428\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "89 + 45 = 134\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.01044750510209265\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "91 + 19 = 110\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.016655211774113877\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "24 + 13 = 37\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.021459982704549893\n",
            "Pred:[1 1 0 0 1 1 0 1]\n",
            "True:[1 1 0 0 1 1 0 1]\n",
            "94 + 111 = 205\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.006375356286372113\n",
            "Pred:[0 0 1 1 1 1 0 1]\n",
            "True:[0 0 1 1 1 1 0 1]\n",
            "7 + 54 = 61\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.006462669831716919\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "101 + 3 = 104\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.011759347615441876\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "127 + 52 = 179\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.009033655563185429\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "51 + 24 = 75\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.01124637519575763\n",
            "Pred:[1 1 1 0 0 1 0 0]\n",
            "True:[1 1 1 0 0 1 0 0]\n",
            "114 + 114 = 228\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.004652391157215714\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "49 + 125 = 174\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.009083024113749762\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "56 + 56 = 112\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.01024614721693875\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "42 + 45 = 87\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.0031616976304170456\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "107 + 105 = 212\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.005321834180664833\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "27 + 105 = 132\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.006462105953781336\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "54 + 72 = 126\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.006285221029954001\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "112 + 1 = 113\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.005877563677702812\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "101 + 63 = 164\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.004532051717490281\n",
            "Pred:[1 0 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "111 + 76 = 187\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.004690713588951749\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "68 + 56 = 124\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.001580901665769343\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "55 + 35 = 90\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.002430083506650728\n",
            "Pred:[1 1 1 1 0 0 0 1]\n",
            "True:[1 1 1 1 0 0 0 1]\n",
            "121 + 120 = 241\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.004114469432415777\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "2 + 119 = 121\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.003379137223224074\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "84 + 73 = 157\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.005023936473931626\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "104 + 26 = 130\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.0048872176003476875\n",
            "Pred:[1 1 0 0 0 0 0 1]\n",
            "True:[1 1 0 0 0 0 0 1]\n",
            "94 + 99 = 193\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.0036486639054631176\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "100 + 90 = 190\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.004196013551492404\n",
            "Pred:[1 0 1 1 1 1 0 0]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "114 + 74 = 188\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.003827468450214248\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "34 + 32 = 66\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0016298961481809805\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "35 + 64 = 99\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0020991856115969943\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 1 0 1 0 1 1 1]\n",
            "101 + 114 = 215\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.00339315608235309\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "116 + 3 = 119\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0006082360306611483\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "65 + 89 = 154\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUDeBmCdD-7Q"
      },
      "source": [
        "### He"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6LLjvIj3D6Hu",
        "outputId": "2bfa56c6-9852-45fd-c669-3c85056c0d1a"
      },
      "source": [
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "# W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "# W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "# W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:0.937150049726625\n",
            "Pred:[1 1 1 0 0 1 1 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "42 + 26 = 230\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.9562953909120671\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "90 + 117 = 222\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.9620722041826624\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 1 0 0 1 1 0]\n",
            "121 + 109 = 255\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.131230922320834\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "75 + 84 = 0\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.9340640448151754\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[1 1 0 0 1 0 1 1]\n",
            "99 + 104 = 239\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0100717274902997\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "110 + 4 = 0\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.33108485591091\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "19 + 113 = 255\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.9679264495979334\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "27 + 48 = 255\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.0480493464902554\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "95 + 114 = 4\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.9656918445552409\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "70 + 46 = 223\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.124172931009044\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "70 + 31 = 0\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.1613912981013361\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "117 + 19 = 255\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.0022590169428867\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "15 + 45 = 0\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.9081185065907574\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "20 + 42 = 126\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.0737900341673567\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "47 + 66 = 78\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.8975290427107843\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "63 + 44 = 127\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.8157545255712844\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 1 1 1]\n",
            "106 + 117 = 255\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.9874174147726932\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 0 1 0]\n",
            "15 + 43 = 127\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.066677718141579\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "120 + 43 = 83\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.0196961356719054\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[1 1 1 0 0 0 0 1]\n",
            "126 + 99 = 4\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.8565271528054006\n",
            "Pred:[0 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "79 + 76 = 24\n",
            "------------\n",
            "iters:2100\n",
            "Loss:1.1687345448101676\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "123 + 45 = 86\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.1801950212763703\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "79 + 97 = 255\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.96432962794225\n",
            "Pred:[0 0 1 1 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "24 + 42 = 48\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.8786231058663551\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "37 + 81 = 98\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.7774684157238025\n",
            "Pred:[0 0 0 0 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "45 + 2 = 15\n",
            "------------\n",
            "iters:2600\n",
            "Loss:1.1425711633861109\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "42 + 103 = 77\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.8602573294497075\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "89 + 74 = 145\n",
            "------------\n",
            "iters:2800\n",
            "Loss:1.023075468947094\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "106 + 16 = 0\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.7648953205763254\n",
            "Pred:[0 1 0 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "99 + 1 = 70\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.5068479070592763\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "2 + 98 = 4\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.8058760875389633\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "102 + 49 = 215\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.6332947398782738\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "29 + 82 = 111\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.9121200831293721\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "38 + 127 = 221\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.5334075383170355\n",
            "Pred:[0 0 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "65 + 6 = 7\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.1408457361265332\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "37 + 37 = 74\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.5918034398455219\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "41 + 63 = 108\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.510729727074273\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "77 + 24 = 101\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.6707023307387048\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "5 + 74 = 85\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.380724094552062\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "41 + 82 = 123\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.5768695685652968\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "71 + 126 = 181\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.723010350051663\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "119 + 81 = 172\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.285756735113822\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "43 + 76 = 119\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.2310707308867477\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "84 + 57 = 141\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.23792994646563226\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "53 + 126 = 179\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.1529480860871931\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "56 + 4 = 60\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.15287397313987258\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "31 + 84 = 115\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.0844716551509245\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "37 + 80 = 117\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.07575051811052333\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "15 + 93 = 108\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.16182846272893908\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "31 + 46 = 77\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.08142209568680354\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "76 + 79 = 155\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.016899239809980645\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "97 + 101 = 198\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.0674769126216084\n",
            "Pred:[1 0 1 1 0 0 0 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "51 + 126 = 177\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.01451740598419192\n",
            "Pred:[1 1 0 1 0 0 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "105 + 105 = 210\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.11249847809409848\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "37 + 25 = 62\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.044614939134343876\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "49 + 54 = 103\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.032156730189452996\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "7 + 92 = 99\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.04341901462055265\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "15 + 108 = 123\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.02105332002057785\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "72 + 92 = 164\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.010546335521438483\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "36 + 81 = 117\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.012314992250290355\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "106 + 39 = 145\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.008110544906397756\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "64 + 25 = 89\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.018053098946149256\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "95 + 20 = 115\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.011433814724738704\n",
            "Pred:[1 1 1 0 0 0 0 1]\n",
            "True:[1 1 1 0 0 0 0 1]\n",
            "100 + 125 = 225\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.024985964710995\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "25 + 126 = 151\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.029598462125395925\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "62 + 6 = 68\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.011862017550034722\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "6 + 76 = 82\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.006177558910529211\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "95 + 29 = 124\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.007326175314771375\n",
            "Pred:[1 0 1 0 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "72 + 103 = 175\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.008712580258324836\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "59 + 85 = 144\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.01037275331938011\n",
            "Pred:[1 1 0 0 1 0 0 1]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "127 + 74 = 201\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.0044839999884831805\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "6 + 47 = 53\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.008002626264759326\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[1 1 0 1 1 1 0 1]\n",
            "106 + 115 = 221\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.0021992454297473517\n",
            "Pred:[1 1 0 0 1 1 0 0]\n",
            "True:[1 1 0 0 1 1 0 0]\n",
            "107 + 97 = 204\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.0050300135336808875\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "64 + 90 = 154\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.005040926241003555\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "16 + 92 = 108\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.0036877434039037675\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "50 + 123 = 173\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.00478333977257708\n",
            "Pred:[1 0 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "60 + 127 = 187\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.005427697753224339\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "111 + 26 = 137\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.003357986836424916\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "114 + 31 = 145\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.005081144227996096\n",
            "Pred:[1 1 1 0 0 1 1 1]\n",
            "True:[1 1 1 0 0 1 1 1]\n",
            "107 + 124 = 231\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.003467595344777634\n",
            "Pred:[0 0 0 1 0 0 0 1]\n",
            "True:[0 0 0 1 0 0 0 1]\n",
            "11 + 6 = 17\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.00406295669766845\n",
            "Pred:[1 1 1 0 0 0 1 1]\n",
            "True:[1 1 1 0 0 0 1 1]\n",
            "103 + 124 = 227\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0035837480142541425\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "16 + 84 = 100\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.0025908581818565877\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "55 + 125 = 180\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.0025831731723792734\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[0 1 0 0 0 1 0 1]\n",
            "3 + 66 = 69\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.0028417674230216947\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "29 + 76 = 105\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.002399392600576611\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "78 + 87 = 165\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.0026889966015651748\n",
            "Pred:[1 1 1 0 1 1 1 0]\n",
            "True:[1 1 1 0 1 1 1 0]\n",
            "114 + 124 = 238\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.0048480460956719105\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "18 + 94 = 112\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.002241037243309926\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "71 + 42 = 113\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.0018591098863750596\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "32 + 71 = 103\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.0024491686225888913\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "61 + 67 = 128\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.0014223313005337936\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "83 + 85 = 168\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0018578746636099595\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "55 + 98 = 153\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.002313119360044917\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "56 + 104 = 160\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0018604379273680347\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "59 + 70 = 129\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0022726299051796977\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "68 + 46 = 114\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.001693042747517032\n",
            "Pred:[1 0 1 1 0 0 0 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "109 + 68 = 177\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0010015063010543998\n",
            "Pred:[1 1 0 0 0 0 0 1]\n",
            "True:[1 1 0 0 0 0 0 1]\n",
            "80 + 113 = 193\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJPcHdGtFjWd"
      },
      "source": [
        "XavierよりHeのほうが効果がありそう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtED2LWrCHoL"
      },
      "source": [
        "## 中間層の活性化関数を変更"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXMS_Xq-EV-L"
      },
      "source": [
        "### ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V83Kwz7bCLkq",
        "outputId": "f56dbafc-c111-49c6-a608-b5e8a5fe3222"
      },
      "source": [
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "        # z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        # delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.7448611337858302\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "0 + 106 = 255\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.1701748505857548\n",
            "Pred:[0 0 0 0 1 0 0 1]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "90 + 10 = 9\n",
            "------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/rabbit_challenge/DNN_code/common/functions.py:6: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:200\n",
            "Loss:0.9578471510431101\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "34 + 15 = 0\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.9057284161382679\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "20 + 112 = 0\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.8997170253003454\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "62 + 33 = 222\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.044460373980318\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "84 + 61 = 64\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.9953365117420453\n",
            "Pred:[0 0 1 0 1 1 0 0]\n",
            "True:[0 0 0 1 1 1 1 1]\n",
            "13 + 18 = 44\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0839272828297206\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "104 + 25 = 98\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.9300482133448557\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "85 + 28 = 64\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.0202843733730549\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 1 1 0 0 1 1 0]\n",
            "115 + 115 = 141\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.985188253065205\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "45 + 73 = 183\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.9802578497708478\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "94 + 58 = 68\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.8276342859226998\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "90 + 36 = 94\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.0956137467549631\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "26 + 37 = 0\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.048332709361525\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "39 + 37 = 1\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.955928039209146\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "22 + 69 = 3\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.0231894822782206\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "53 + 11 = 5\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.9452831438117842\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "77 + 96 = 135\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.0636436478848998\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "93 + 38 = 255\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.114999873045983\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "9 + 27 = 255\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.9795497078563599\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "33 + 57 = 255\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.9094361534121366\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "92 + 67 = 255\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.9660436508368256\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[1 1 1 0 0 1 0 0]\n",
            "106 + 122 = 250\n",
            "------------\n",
            "iters:2300\n",
            "Loss:1.079162168004541\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 0 1 0 0 0 0]\n",
            "3 + 13 = 255\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.9720215584164714\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "25 + 61 = 255\n",
            "------------\n",
            "iters:2500\n",
            "Loss:1.0103943678593776\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "43 + 25 = 223\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.848496440186994\n",
            "Pred:[1 0 0 0 1 0 0 0]\n",
            "True:[1 1 0 0 1 1 0 0]\n",
            "118 + 86 = 136\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.9580106391140983\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "87 + 58 = 43\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.8827369756843363\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "70 + 54 = 184\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.9823060229810924\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "4 + 91 = 251\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.9958606352412182\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "95 + 21 = 160\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.9414773630467003\n",
            "Pred:[1 1 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "37 + 120 = 219\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.913765677850887\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "86 + 12 = 190\n",
            "------------\n",
            "iters:3300\n",
            "Loss:1.0131795069305862\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "103 + 13 = 255\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.8774416960644599\n",
            "Pred:[1 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "40 + 86 = 246\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.937488839447348\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "84 + 93 = 168\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.9620603352116208\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 1 0 0 0 0 0 1]\n",
            "120 + 73 = 149\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.9083102326821721\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "61 + 40 = 123\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.9104079234486813\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "110 + 74 = 148\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.839362536715131\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 1 1 0 1 1 1 0]\n",
            "114 + 124 = 142\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.9621674790814049\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "75 + 65 = 128\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.9738919805994325\n",
            "Pred:[1 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "23 + 89 = 232\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.7619652099663892\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "72 + 108 = 182\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.9870829687325038\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "105 + 58 = 255\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.8686905249477448\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "89 + 62 = 255\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.9019446971351791\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 1 1 0 0 0 1 1]\n",
            "107 + 120 = 151\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.8375939734869284\n",
            "Pred:[1 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "18 + 92 = 238\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.9479652877916743\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "69 + 67 = 190\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.8856897454947386\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 1 0 1 0 1 1 1]\n",
            "103 + 112 = 129\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.9049771465337348\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "72 + 4 = 150\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.8987529284194495\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 1 1 0 1 1 0 0]\n",
            "122 + 114 = 132\n",
            "------------\n",
            "iters:5100\n",
            "Loss:1.0118627319331996\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "61 + 31 = 0\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.8572315626673166\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "102 + 38 = 72\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.9889567166110338\n",
            "Pred:[1 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "13 + 83 = 242\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.8654341817482627\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 1 0]\n",
            "35 + 35 = 68\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.9024209096729158\n",
            "Pred:[1 0 1 0 1 0 0 1]\n",
            "True:[0 0 1 0 1 1 0 1]\n",
            "16 + 29 = 169\n",
            "------------\n",
            "iters:5600\n",
            "Loss:1.0056190013412132\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "92 + 35 = 1\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.8473703094987803\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "81 + 118 = 191\n",
            "------------\n",
            "iters:5800\n",
            "Loss:1.0680768888820569\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 0 1 0 0 0 0]\n",
            "13 + 3 = 255\n",
            "------------\n",
            "iters:5900\n",
            "Loss:1.0312633255207708\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "11 + 67 = 215\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.91402286874117\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "46 + 80 = 134\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.9489185803906933\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "90 + 23 = 183\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.9036881247551892\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "91 + 60 = 33\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.9706751392601012\n",
            "Pred:[0 0 0 1 0 0 1 0]\n",
            "True:[0 0 1 0 0 1 1 0]\n",
            "13 + 25 = 18\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.9395875746865554\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "84 + 62 = 254\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.97253965324603\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "94 + 17 = 33\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.9841139864166704\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "91 + 21 = 34\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.9168433846839118\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "105 + 81 = 162\n",
            "------------\n",
            "iters:6800\n",
            "Loss:1.0181443764797353\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "96 + 104 = 182\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.7583744826302885\n",
            "Pred:[0 0 1 1 0 1 1 0]\n",
            "True:[0 0 0 1 1 1 0 0]\n",
            "4 + 24 = 54\n",
            "------------\n",
            "iters:7000\n",
            "Loss:1.1019747104636914\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "127 + 59 = 118\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.9202878563450534\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "100 + 79 = 223\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.9913296570821423\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "119 + 62 = 127\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.9047246170015051\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "109 + 42 = 127\n",
            "------------\n",
            "iters:7400\n",
            "Loss:1.0120138997748283\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "96 + 21 = 41\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.8163528513724776\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "58 + 75 = 181\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.8463123467894081\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "88 + 34 = 88\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.8867439130399335\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "34 + 23 = 41\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.9107368738645987\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "51 + 124 = 129\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.8593008361687855\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 0 0 1 1 1 0 0]\n",
            "8 + 20 = 36\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.885748443482858\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "105 + 28 = 1\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.8404801442651957\n",
            "Pred:[1 0 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "5 + 92 = 161\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.8668775808542577\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "37 + 59 = 69\n",
            "------------\n",
            "iters:8300\n",
            "Loss:1.0174095617373655\n",
            "Pred:[0 0 1 0 0 0 1 1]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "125 + 25 = 35\n",
            "------------\n",
            "iters:8400\n",
            "Loss:1.2250670988144599\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 0 1 0 1 0 0 0]\n",
            "0 + 40 = 84\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.9873287192454328\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "94 + 34 = 4\n",
            "------------\n",
            "iters:8600\n",
            "Loss:1.0129203839059011\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "127 + 60 = 65\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.8126606221263536\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[0 0 0 1 0 0 1 1]\n",
            "3 + 16 = 5\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.9088493649982983\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "22 + 42 = 84\n",
            "------------\n",
            "iters:8900\n",
            "Loss:1.0289685980776064\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "25 + 119 = 171\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.8553607691796019\n",
            "Pred:[0 0 0 1 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 1 0]\n",
            "58 + 12 = 20\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.810237271913414\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "36 + 62 = 72\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.7142374724175147\n",
            "Pred:[0 0 0 1 0 0 0 1]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "9 + 40 = 17\n",
            "------------\n",
            "iters:9300\n",
            "Loss:1.0087679373672722\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "126 + 16 = 164\n",
            "------------\n",
            "iters:9400\n",
            "Loss:1.0402794604385859\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "84 + 19 = 135\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.9595325459532176\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "117 + 25 = 59\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.9545755720388924\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "96 + 74 = 0\n",
            "------------\n",
            "iters:9700\n",
            "Loss:1.0620223074435808\n",
            "Pred:[0 0 0 1 0 1 0 1]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "63 + 63 = 21\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.9993632880855177\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "126 + 88 = 36\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.6729980896270465\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "68 + 58 = 124\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sg9HnK3vEMrD",
        "outputId": "b2a7afd8-b5d3-4f2c-dbba-d60fd016f9bd"
      },
      "source": [
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "#         z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "        z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.1766273667371108\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "54 + 47 = 98\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.8947178602424243\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "28 + 74 = 94\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.8699539553704607\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "43 + 90 = 156\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.7517101529090635\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "76 + 47 = 119\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.920197723481959\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[1 1 1 0 1 1 0 0]\n",
            "116 + 120 = 116\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0493860634785899\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "37 + 118 = 181\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.8994983631124552\n",
            "Pred:[1 1 1 1 0 0 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "18 + 125 = 243\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.7892588761428341\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "22 + 17 = 31\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.18484969338955\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "122 + 15 = 103\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.7445926937934866\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "69 + 103 = 148\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.9650970101491105\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "63 + 52 = 41\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.424324099618096\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "41 + 72 = 141\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.6660044160307229\n",
            "Pred:[0 0 0 0 0 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "83 + 11 = 6\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.8596498476219702\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "90 + 23 = 91\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.7825432709174098\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "41 + 12 = 5\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.8497399300037969\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 1 1 0 0 0 1]\n",
            "116 + 125 = 255\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.7223905270562503\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "10 + 37 = 103\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.1919243421030739\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "37 + 85 = 252\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.0611464208360268\n",
            "Pred:[0 0 0 1 1 0 0 1]\n",
            "True:[0 0 1 0 0 0 0 1]\n",
            "5 + 28 = 25\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.9583770035501837\n",
            "Pred:[0 0 1 0 0 0 1 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "73 + 44 = 35\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.8778735460022139\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "75 + 109 = 138\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.75254372323249\n",
            "Pred:[0 0 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "84 + 2 = 18\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.834663520597561\n",
            "Pred:[0 0 0 1 0 1 0 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "16 + 31 = 21\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.8632482713017046\n",
            "Pred:[1 1 0 0 0 1 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "118 + 26 = 196\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.9056087631012212\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "125 + 61 = 160\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.9256819543220581\n",
            "Pred:[0 0 1 1 0 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "58 + 96 = 50\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.7152838642636331\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "52 + 97 = 247\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.4306124372440052\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "61 + 22 = 67\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.978584476683731\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "8 + 60 = 124\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.6484939690604494\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "100 + 63 = 129\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.6449248722846695\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "97 + 10 = 239\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.28998198057172375\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 1 1 1]\n",
            "127 + 96 = 223\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.7107953034515951\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "36 + 81 = 123\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.42800570448752445\n",
            "Pred:[1 0 1 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "101 + 45 = 178\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.1827377340750855\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "117 + 85 = 202\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.5661664392576585\n",
            "Pred:[0 0 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "80 + 37 = 57\n",
            "------------\n",
            "iters:3600\n",
            "Loss:1.0896775003691421\n",
            "Pred:[1 0 1 1 1 0 0 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "103 + 72 = 185\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.9734155379994172\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "36 + 41 = 83\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.6547775112193686\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "90 + 72 = 146\n",
            "------------\n",
            "iters:3900\n",
            "Loss:1.0454683335004034\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "70 + 127 = 131\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.7781793057047799\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "34 + 106 = 164\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.7037245281484521\n",
            "Pred:[0 0 0 0 1 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "0 + 68 = 12\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.9011845043125828\n",
            "Pred:[1 0 1 1 0 0 0 1]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "89 + 112 = 177\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.4412457463194775\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "112 + 74 = 186\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.5828599342737826\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "15 + 120 = 151\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.728311671551123\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "35 + 36 = 3\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.8914375745085119\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 0 0 1 1 0 1 1]\n",
            "27 + 0 = 115\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.8535687417946155\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "77 + 81 = 166\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.7407249756417171\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "1 + 38 = 115\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.5909407841083556\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "109 + 14 = 117\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.5686160387215384\n",
            "Pred:[1 1 1 1 0 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "59 + 123 = 246\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.42308995625099244\n",
            "Pred:[0 0 1 1 0 1 1 1]\n",
            "True:[0 0 1 1 0 0 1 1]\n",
            "35 + 16 = 55\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.8581891948596279\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "88 + 5 = 5\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.49760803260786535\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "4 + 49 = 63\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.5193762528026085\n",
            "Pred:[1 1 0 1 0 1 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "100 + 109 = 213\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.2627953389801669\n",
            "Pred:[0 0 1 1 0 0 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "7 + 45 = 48\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.3682129392471333\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "35 + 101 = 152\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.07037931314928163\n",
            "Pred:[0 0 0 1 1 0 0 1]\n",
            "True:[0 0 0 1 1 0 0 1]\n",
            "8 + 17 = 25\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.3890042729623135\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "61 + 18 = 71\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.13715586632380156\n",
            "Pred:[0 0 1 0 1 1 0 0]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "10 + 34 = 44\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.8409320559672869\n",
            "Pred:[1 0 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "113 + 8 = 185\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.8756326920353543\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "44 + 122 = 250\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.6939597431227674\n",
            "Pred:[0 0 1 1 0 0 0 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "57 + 26 = 49\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.999296315149544\n",
            "Pred:[1 1 0 0 1 0 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "106 + 11 = 201\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.813738593475406\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "66 + 67 = 131\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.8344933517543489\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "18 + 88 = 250\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.45971929569360714\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "64 + 40 = 104\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.8497680829388436\n",
            "Pred:[1 1 1 0 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "36 + 114 = 230\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.661989657383427\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 0 0 1 0 1 1 0]\n",
            "20 + 2 = 82\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.8115151330762358\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "112 + 2 = 146\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.7214940857164619\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "51 + 24 = 3\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.9134743212319123\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "115 + 27 = 76\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.4707461899439922\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "107 + 51 = 142\n",
            "------------\n",
            "iters:7300\n",
            "Loss:1.0075151734620336\n",
            "Pred:[1 1 1 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "31 + 25 = 224\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.6632280719283185\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 0 1 1 0 0 1 1]\n",
            "9 + 42 = 91\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.28460754803092647\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 0 0 1 1 1 1 1]\n",
            "20 + 11 = 29\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.7563526135806495\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "84 + 86 = 166\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.7545626610407119\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "64 + 58 = 154\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.3017090509231251\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "22 + 34 = 56\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.5510356476606842\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "95 + 14 = 101\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.20756854069387454\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "66 + 67 = 133\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.41543688709816307\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "27 + 26 = 37\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.6717325930646404\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "93 + 15 = 120\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.6069893098430346\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "91 + 28 = 99\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.4993504110034875\n",
            "Pred:[1 1 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "76 + 90 = 230\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.47463986222069565\n",
            "Pred:[1 1 1 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "81 + 91 = 236\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.30913003808222395\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "120 + 67 = 251\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.18758150461902148\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "36 + 47 = 83\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.4787626177724162\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "28 + 59 = 103\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.5784582038931638\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "22 + 80 = 166\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.7967013190220738\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "111 + 55 = 222\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.11131024048468001\n",
            "Pred:[0 0 1 0 1 1 1 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "43 + 3 = 46\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.6653073213592156\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "40 + 61 = 71\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.4337020206086244\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "79 + 3 = 86\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.4699011397265796\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "107 + 8 = 119\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.5151923969828346\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "88 + 90 = 162\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.9635507413978336\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "34 + 88 = 162\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.8873946926790195\n",
            "Pred:[1 1 1 1 0 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "120 + 36 = 244\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.9666744306475177\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "121 + 67 = 2\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.9235027979673824\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "41 + 7 = 254\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}