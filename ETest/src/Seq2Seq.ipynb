{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPz7qsSGe7pNPJ6Q0TlE2dG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcms2ll/AI-Study/blob/main/ETest/src/Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HgrbnY0N-f5",
        "outputId": "e3ae298e-6e37-4cae-b1ca-eb4346fd34bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX0UQIYKOzqH",
        "outputId": "1c9712ae-0016-40c1-db21-3ffae7a0e55c"
      },
      "source": [
        "!pip3 install wheel==0.34.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wheel==0.34.1 in /usr/local/lib/python3.7/dist-packages (0.34.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6H3aUbrTOYl"
      },
      "source": [
        "# Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL4BHnakOP-4",
        "outputId": "036fe6a3-473f-405c-9b0f-b7188d5aa406"
      },
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 69.4 MB 1.2 MB/s \n",
            "\u001b[?25h1.0.0\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPTRCOd6O2CW",
        "outputId": "bd1db214-99a3-4756-e3c7-84cd26ac85a6"
      },
      "source": [
        "! wget https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n",
        "! mkdir images data\n",
        "\n",
        "# data取得\n",
        "! wget https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en -P data/\n",
        "! wget https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja -P data/\n",
        "! wget https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en -P data/\n",
        "! wget https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja -P data/\n",
        "! wget https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en -P data/\n",
        "! wget https://www.dropbox.com/s/ak53qirssci6f1j/train.ja -P data/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-07 10:11:40--  https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/9narw5x4uizmehh/utils.py [following]\n",
            "--2021-12-07 10:11:41--  https://www.dropbox.com/s/raw/9narw5x4uizmehh/utils.py\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3b051dc37ddad923a1110f8ecd.dl.dropboxusercontent.com/cd/0/inline/BbaHms3BU_DK0YAKy-oGJ6BS2OC3daPpXgImHCMM38q7zPWIlRwOcIR-e4Ow61HeX-IVARugmy1VtR5mcAcuL_aFwLrGUEofBMn7TF3IN48XkbOArLV_yy4OdkPuJdhpj0FkHKJ-h7zft20Bq0Qty2lu/file# [following]\n",
            "--2021-12-07 10:11:41--  https://uc3b051dc37ddad923a1110f8ecd.dl.dropboxusercontent.com/cd/0/inline/BbaHms3BU_DK0YAKy-oGJ6BS2OC3daPpXgImHCMM38q7zPWIlRwOcIR-e4Ow61HeX-IVARugmy1VtR5mcAcuL_aFwLrGUEofBMn7TF3IN48XkbOArLV_yy4OdkPuJdhpj0FkHKJ-h7zft20Bq0Qty2lu/file\n",
            "Resolving uc3b051dc37ddad923a1110f8ecd.dl.dropboxusercontent.com (uc3b051dc37ddad923a1110f8ecd.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc3b051dc37ddad923a1110f8ecd.dl.dropboxusercontent.com (uc3b051dc37ddad923a1110f8ecd.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 949 [text/plain]\n",
            "Saving to: ‘utils.py.2’\n",
            "\n",
            "utils.py.2          100%[===================>]     949  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-07 10:11:41 (106 MB/s) - ‘utils.py.2’ saved [949/949]\n",
            "\n",
            "mkdir: cannot create directory ‘images’: File exists\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2021-12-07 10:11:41--  https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/o4kyc52a8we25wy/dev.en [following]\n",
            "--2021-12-07 10:11:42--  https://www.dropbox.com/s/raw/o4kyc52a8we25wy/dev.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucbef611035bb76a37ff38d3ed94.dl.dropboxusercontent.com/cd/0/inline/BbYaYeTi1kP5HJij-42U205tB1834gxnLWOFyrOZKYL37q0U4du7EqGf6QRsN9tjKzORmvQl1obrf16xupQteGqJAB1xpf4XaZauv8ySDTHvUEnV6zi-9_x_NVv5YOROisk8AetbSAr66M6xs5JHaf10/file# [following]\n",
            "--2021-12-07 10:11:42--  https://ucbef611035bb76a37ff38d3ed94.dl.dropboxusercontent.com/cd/0/inline/BbYaYeTi1kP5HJij-42U205tB1834gxnLWOFyrOZKYL37q0U4du7EqGf6QRsN9tjKzORmvQl1obrf16xupQteGqJAB1xpf4XaZauv8ySDTHvUEnV6zi-9_x_NVv5YOROisk8AetbSAr66M6xs5JHaf10/file\n",
            "Resolving ucbef611035bb76a37ff38d3ed94.dl.dropboxusercontent.com (ucbef611035bb76a37ff38d3ed94.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucbef611035bb76a37ff38d3ed94.dl.dropboxusercontent.com (ucbef611035bb76a37ff38d3ed94.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17054 (17K) [text/plain]\n",
            "Saving to: ‘data/dev.en.2’\n",
            "\n",
            "dev.en.2            100%[===================>]  16.65K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-12-07 10:11:43 (3.03 MB/s) - ‘data/dev.en.2’ saved [17054/17054]\n",
            "\n",
            "--2021-12-07 10:11:43--  https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/kdgskm5hzg6znuc/dev.ja [following]\n",
            "--2021-12-07 10:11:43--  https://www.dropbox.com/s/raw/kdgskm5hzg6znuc/dev.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc6a1640e4bf275808275c14273d.dl.dropboxusercontent.com/cd/0/inline/BbY-WzCjtWNyuMfV6Cu5iXVAp6bEcOyp_wsAHey6bjyQKkHdhiFxLa40YX7n39L6wQfNhd2Y3evI2JW82KqEGA92S8CICQk2jF7quldxn_FmC1sT28iXx49A3ktuB0RIqmAkjnsOxkq25Rd3UqeIvo3T/file# [following]\n",
            "--2021-12-07 10:11:43--  https://uc6a1640e4bf275808275c14273d.dl.dropboxusercontent.com/cd/0/inline/BbY-WzCjtWNyuMfV6Cu5iXVAp6bEcOyp_wsAHey6bjyQKkHdhiFxLa40YX7n39L6wQfNhd2Y3evI2JW82KqEGA92S8CICQk2jF7quldxn_FmC1sT28iXx49A3ktuB0RIqmAkjnsOxkq25Rd3UqeIvo3T/file\n",
            "Resolving uc6a1640e4bf275808275c14273d.dl.dropboxusercontent.com (uc6a1640e4bf275808275c14273d.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc6a1640e4bf275808275c14273d.dl.dropboxusercontent.com (uc6a1640e4bf275808275c14273d.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27781 (27K) [text/plain]\n",
            "Saving to: ‘data/dev.ja.2’\n",
            "\n",
            "dev.ja.2            100%[===================>]  27.13K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-12-07 10:11:44 (820 KB/s) - ‘data/dev.ja.2’ saved [27781/27781]\n",
            "\n",
            "--2021-12-07 10:11:44--  https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/gyyx4gohv9v65uh/test.en [following]\n",
            "--2021-12-07 10:11:44--  https://www.dropbox.com/s/raw/gyyx4gohv9v65uh/test.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc70a28f2c14853113997d280861.dl.dropboxusercontent.com/cd/0/inline/BbZgPAzWgxhXvjRnw34Rcqp2XzsCXoqnZ9Fc6U9aZnZW7a0zQD6Zr4ZarybnEypdcopAPC4awuyZTf8oTtH1lUYpZb4JLVIxQmPBjXszzfAMw4haZAynWWT17pRZOfQIPOpoFSwNIAwkvTgZR7TYwsmj/file# [following]\n",
            "--2021-12-07 10:11:44--  https://uc70a28f2c14853113997d280861.dl.dropboxusercontent.com/cd/0/inline/BbZgPAzWgxhXvjRnw34Rcqp2XzsCXoqnZ9Fc6U9aZnZW7a0zQD6Zr4ZarybnEypdcopAPC4awuyZTf8oTtH1lUYpZb4JLVIxQmPBjXszzfAMw4haZAynWWT17pRZOfQIPOpoFSwNIAwkvTgZR7TYwsmj/file\n",
            "Resolving uc70a28f2c14853113997d280861.dl.dropboxusercontent.com (uc70a28f2c14853113997d280861.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc70a28f2c14853113997d280861.dl.dropboxusercontent.com (uc70a28f2c14853113997d280861.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17301 (17K) [text/plain]\n",
            "Saving to: ‘data/test.en.2’\n",
            "\n",
            "test.en.2           100%[===================>]  16.90K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2021-12-07 10:11:44 (4.38 MB/s) - ‘data/test.en.2’ saved [17301/17301]\n",
            "\n",
            "--2021-12-07 10:11:44--  https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/hotxwbgoe2n013k/test.ja [following]\n",
            "--2021-12-07 10:11:45--  https://www.dropbox.com/s/raw/hotxwbgoe2n013k/test.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc72abcd9f2425690a0fbd02e79c.dl.dropboxusercontent.com/cd/0/inline/BbZwo7MbqD4xweJcXs_RX_lUIuavOvABmmRsqRkkVHNyOtDxg5dQVs06nXOf7SmuYCm-sbF-TKAC7MEl7ibx2twz7cf-XDPxYokxcljl8m4SCofg8hflfuAuAvSq0nvDNwrEy6jCh--xMyjS722qxyPJ/file# [following]\n",
            "--2021-12-07 10:11:45--  https://uc72abcd9f2425690a0fbd02e79c.dl.dropboxusercontent.com/cd/0/inline/BbZwo7MbqD4xweJcXs_RX_lUIuavOvABmmRsqRkkVHNyOtDxg5dQVs06nXOf7SmuYCm-sbF-TKAC7MEl7ibx2twz7cf-XDPxYokxcljl8m4SCofg8hflfuAuAvSq0nvDNwrEy6jCh--xMyjS722qxyPJ/file\n",
            "Resolving uc72abcd9f2425690a0fbd02e79c.dl.dropboxusercontent.com (uc72abcd9f2425690a0fbd02e79c.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc72abcd9f2425690a0fbd02e79c.dl.dropboxusercontent.com (uc72abcd9f2425690a0fbd02e79c.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27793 (27K) [text/plain]\n",
            "Saving to: ‘data/test.ja.2’\n",
            "\n",
            "test.ja.2           100%[===================>]  27.14K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-12-07 10:11:45 (810 KB/s) - ‘data/test.ja.2’ saved [27793/27793]\n",
            "\n",
            "--2021-12-07 10:11:45--  https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/5lsftkmb20ay9e1/train.en [following]\n",
            "--2021-12-07 10:11:45--  https://www.dropbox.com/s/raw/5lsftkmb20ay9e1/train.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc12930eac49273888917685af32.dl.dropboxusercontent.com/cd/0/inline/BbYHrUvEfLtCcYes1bgOMRGsqAIiaa5xaQ29_N3GXEti0tfGYwD7Qh2mymJu0jnDN4ZUTOu2usXSqiesA_BYgtloZ61Rp8BE3xb4EXYRALi1OntDFa0wQAjJzIRlo4MQgzVDux79FBve7G9lzFFjbO-f/file# [following]\n",
            "--2021-12-07 10:11:46--  https://uc12930eac49273888917685af32.dl.dropboxusercontent.com/cd/0/inline/BbYHrUvEfLtCcYes1bgOMRGsqAIiaa5xaQ29_N3GXEti0tfGYwD7Qh2mymJu0jnDN4ZUTOu2usXSqiesA_BYgtloZ61Rp8BE3xb4EXYRALi1OntDFa0wQAjJzIRlo4MQgzVDux79FBve7G9lzFFjbO-f/file\n",
            "Resolving uc12930eac49273888917685af32.dl.dropboxusercontent.com (uc12930eac49273888917685af32.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc12930eac49273888917685af32.dl.dropboxusercontent.com (uc12930eac49273888917685af32.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1701356 (1.6M) [text/plain]\n",
            "Saving to: ‘data/train.en.2’\n",
            "\n",
            "train.en.2          100%[===================>]   1.62M  10.2MB/s    in 0.2s    \n",
            "\n",
            "2021-12-07 10:11:46 (10.2 MB/s) - ‘data/train.en.2’ saved [1701356/1701356]\n",
            "\n",
            "--2021-12-07 10:11:46--  https://www.dropbox.com/s/ak53qirssci6f1j/train.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ak53qirssci6f1j/train.ja [following]\n",
            "--2021-12-07 10:11:46--  https://www.dropbox.com/s/raw/ak53qirssci6f1j/train.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc022914949a3f6bb9834dc64798.dl.dropboxusercontent.com/cd/0/inline/BbYcC7TbthW7HaPXM6cFyGCWaMrzXuN5RvsUEs2iNWshFFiKnU0DcGOKUqT6zatmcBBunVN3vxfR0luCGZLAEFgPh-hxNk4nf1Mr6uWCoGBIQEBaDGCPIdvbRSJUHGnqkWSdrEYFExEYjkBp7rcPdB5w/file# [following]\n",
            "--2021-12-07 10:11:47--  https://uc022914949a3f6bb9834dc64798.dl.dropboxusercontent.com/cd/0/inline/BbYcC7TbthW7HaPXM6cFyGCWaMrzXuN5RvsUEs2iNWshFFiKnU0DcGOKUqT6zatmcBBunVN3vxfR0luCGZLAEFgPh-hxNk4nf1Mr6uWCoGBIQEBaDGCPIdvbRSJUHGnqkWSdrEYFExEYjkBp7rcPdB5w/file\n",
            "Resolving uc022914949a3f6bb9834dc64798.dl.dropboxusercontent.com (uc022914949a3f6bb9834dc64798.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc022914949a3f6bb9834dc64798.dl.dropboxusercontent.com (uc022914949a3f6bb9834dc64798.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2784447 (2.7M) [text/plain]\n",
            "Saving to: ‘data/train.ja.2’\n",
            "\n",
            "train.ja.2          100%[===================>]   2.66M  15.0MB/s    in 0.2s    \n",
            "\n",
            "2021-12-07 10:11:47 (15.0 MB/s) - ‘data/train.ja.2’ saved [2784447/2784447]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su4U_zSsRIez",
        "outputId": "69532bc2-edb2-4328-daee-11e7339092af"
      },
      "source": [
        "! ls data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.en\t  dev.ja    test.en    test.ja\t  train.en    train.ja\n",
            "dev.en.1  dev.ja.1  test.en.1  test.ja.1  train.en.1  train.ja.1\n",
            "dev.en.2  dev.ja.2  test.en.2  test.ja.2  train.en.2  train.ja.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp40pFQVRIh0",
        "outputId": "297f4ba0-9675-4c08-f18f-28343a829190"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from nltk import bleu_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "from utils import Vocab\n",
        "\n",
        "# デバイスの設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random_state = 42\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DafmvX2vTKJg"
      },
      "source": [
        "## データセットの準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNI8Q6gMRIkc",
        "outputId": "2c9ce41a-ebd4-40c4-97e5-40f088e8da90"
      },
      "source": [
        "! head -10 data/train.en"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i can 't tell who will arrive first .\n",
            "many animals have been destroyed by men .\n",
            "i 'm in the tennis club .\n",
            "emi looks happy .\n",
            "please bear this fact in mind .\n",
            "she takes care of my children .\n",
            "we want to be international .\n",
            "you ought not to break your promise .\n",
            "when you cross the street , watch out for cars .\n",
            "i have nothing to live for .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA7HAjxPRIoB",
        "outputId": "ca7e85e9-c414-4e16-d382-300a9cd958da"
      },
      "source": [
        "! head -10 ./data/train.ja"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\n",
            "多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\n",
            "私 は テニス 部員 で す 。\n",
            "エミ は 幸せ そう に 見え ま す 。\n",
            "この 事実 を 心 に 留め て お い て 下さ い 。\n",
            "彼女 は 私 たち の 世話 を し て くれ る 。\n",
            "私 達 は 国際 人 に な り た い と 思 い ま す 。\n",
            "約束 を 破 る べ き で は あ り ま せ ん 。\n",
            "道路 を 横切 る とき は 車 に 注意 し なさ い 。\n",
            "私 に は 生き 甲斐 が な い 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaTGuE9nTa2Y"
      },
      "source": [
        "### データの読み込みと単語の分割\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlrYrs3jUtqk"
      },
      "source": [
        "def load_data(file_path):\n",
        "    # テキストファイルからデータを読み込むメソッド\n",
        "    data = []\n",
        "    for line in open(file_path, encoding='utf-8'):\n",
        "        words = line.strip().split()  # スペースで単語を分割\n",
        "        data.append(words)\n",
        "    return data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se6Ul6KNTYMn"
      },
      "source": [
        "train_X = load_data('./data/train.en')\n",
        "train_Y = load_data('./data/train.ja')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbUwCoicRIrC"
      },
      "source": [
        "# 訓練データと検証データに分割\n",
        "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=random_state)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bwDNDiEUzEB",
        "outputId": "1864ff42-1eaf-4057-9c3d-3b1010ab276e"
      },
      "source": [
        "print('train data', train_X[0])\n",
        "print('valid data', valid_X[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data ['where', 'shall', 'we', 'eat', 'tonight', '?']\n",
            "valid data ['you', 'may', 'extend', 'your', 'stay', 'in', 'tokyo', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAy9bBV1U35r"
      },
      "source": [
        "\n",
        "### 単語辞書の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwWe3LZbU1Oq"
      },
      "source": [
        "# まず特殊トークンを定義しておく\n",
        "PAD_TOKEN = '<PAD>'  # バッチ処理の際に、短い系列の末尾を埋めるために使う （Padding）\n",
        "BOS_TOKEN = '<S>'  # 系列の始まりを表す （Beggining of sentence）\n",
        "EOS_TOKEN = '</S>'  # 系列の終わりを表す （End of sentence）\n",
        "UNK_TOKEN = '<UNK>'  # 語彙に存在しない単語を表す （Unknown）\n",
        "PAD = 0\n",
        "BOS = 1\n",
        "EOS = 2\n",
        "UNK = 3"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiKlWfxeU7Wa"
      },
      "source": [
        "MIN_COUNT = 2  # 語彙に含める単語の最低出現回数 再提出現回数に満たない単語はUNKに置き換えられる\n",
        "\n",
        "# 単語をIDに変換する辞書の初期値を設定\n",
        "word2id = {\n",
        "    PAD_TOKEN: PAD,\n",
        "    BOS_TOKEN: BOS,\n",
        "    EOS_TOKEN: EOS,\n",
        "    UNK_TOKEN: UNK,\n",
        "    }\n",
        "\n",
        "# 単語辞書を作成\n",
        "vocab_X = Vocab(word2id=word2id)\n",
        "vocab_Y = Vocab(word2id=word2id)\n",
        "vocab_X.build_vocab(train_X, min_count=MIN_COUNT)\n",
        "vocab_Y.build_vocab(train_Y, min_count=MIN_COUNT)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwPObcijU882",
        "outputId": "681bb184-7cd1-441b-a271-979f875e799f"
      },
      "source": [
        "vocab_size_X = len(vocab_X.id2word)\n",
        "vocab_size_Y = len(vocab_Y.id2word)\n",
        "print('入力言語の語彙数：', vocab_size_X)\n",
        "print('出力言語の語彙数：', vocab_size_Y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力言語の語彙数： 3725\n",
            "出力言語の語彙数： 4405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew1q3D4mVDvK"
      },
      "source": [
        "## テンソルへの変換"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IH9qCxPVb1D"
      },
      "source": [
        "### IDへの変換\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eATZ5EeoU-pG"
      },
      "source": [
        "def sentence_to_ids(vocab, sentence):\n",
        "    # 単語(str)のリストをID(int)のリストに変換する関数\n",
        "    ids = [vocab.word2id.get(word, UNK) for word in sentence]\n",
        "    ids += [EOS]  # EOSを加える\n",
        "    return ids"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeMdCpNQVQkE"
      },
      "source": [
        "train_X = [sentence_to_ids(vocab_X, sentence) for sentence in train_X]\n",
        "train_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in train_Y]\n",
        "valid_X = [sentence_to_ids(vocab_X, sentence) for sentence in valid_X]\n",
        "valid_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in valid_Y]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m1_372uVdoJ"
      },
      "source": [
        "### DataLoaderの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grZ75durVSBc"
      },
      "source": [
        "def pad_seq(seq, max_length):\n",
        "    # 系列(seq)が指定の文長(max_length)になるように末尾をパディングする\n",
        "    res = seq + [PAD for i in range(max_length - len(seq))]\n",
        "    return res    \n",
        "\n",
        "\n",
        "class DataLoader(object):\n",
        "\n",
        "    def __init__(self, X, Y, batch_size, shuffle=False):\n",
        "        \"\"\"\n",
        "        :param X: list, 入力言語の文章（単語IDのリスト）のリスト\n",
        "        :param Y: list, 出力言語の文章（単語IDのリスト）のリスト\n",
        "        :param batch_size: int, バッチサイズ\n",
        "        :param shuffle: bool, サンプルの順番をシャッフルするか否か\n",
        "        \"\"\"\n",
        "        self.data = list(zip(X, Y))\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.start_index = 0\n",
        "        \n",
        "        self.reset()\n",
        "    \n",
        "    def reset(self):\n",
        "        if self.shuffle:  # サンプルの順番をシャッフルする\n",
        "            self.data = shuffle(self.data, random_state=random_state)\n",
        "        self.start_index = 0  # ポインタの位置を初期化する\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        # ポインタが最後まで到達したら初期化する\n",
        "        if self.start_index >= len(self.data):\n",
        "            self.reset()\n",
        "            raise StopIteration()\n",
        "\n",
        "        # バッチを取得\n",
        "        seqs_X, seqs_Y = zip(*self.data[self.start_index:self.start_index+self.batch_size])\n",
        "        # 入力系列seqs_Xの文章の長さ順（降順）に系列ペアをソートする\n",
        "        seq_pairs = sorted(zip(seqs_X, seqs_Y), key=lambda p: len(p[0]), reverse=True)\n",
        "        seqs_X, seqs_Y = zip(*seq_pairs)\n",
        "        # 短い系列の末尾をパディングする\n",
        "        lengths_X = [len(s) for s in seqs_X]  # 後述のEncoderのpack_padded_sequenceでも用いる\n",
        "        lengths_Y = [len(s) for s in seqs_Y]\n",
        "        max_length_X = max(lengths_X)\n",
        "        max_length_Y = max(lengths_Y)\n",
        "        padded_X = [pad_seq(s, max_length_X) for s in seqs_X]\n",
        "        padded_Y = [pad_seq(s, max_length_Y) for s in seqs_Y]\n",
        "        # tensorに変換し、転置する\n",
        "        batch_X = torch.tensor(padded_X, dtype=torch.long, device=device).transpose(0, 1)\n",
        "        batch_Y = torch.tensor(padded_Y, dtype=torch.long, device=device).transpose(0, 1)\n",
        "\n",
        "        # ポインタを更新する\n",
        "        self.start_index += self.batch_size\n",
        "\n",
        "        return batch_X, batch_Y, lengths_X"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb0jMsm0Vqa-"
      },
      "source": [
        "## モデルの構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFJK6uFGVoLL",
        "outputId": "206276f5-dad9-4dcb-956d-6822a04032f2"
      },
      "source": [
        "# 系列長がそれぞれ4,3,2の3つのサンプルからなるバッチを作成\n",
        "batch = [[1,2,3,4], [5,6,7], [8,9]]\n",
        "lengths = [len(sample) for sample in batch]\n",
        "print('各サンプルの系列長:', lengths)\n",
        "print()\n",
        "\n",
        "# 最大系列長に合うように各サンプルをpadding\n",
        "_max_length = max(lengths)\n",
        "padded = torch.tensor([pad_seq(sample, _max_length) for sample in batch])\n",
        "print('paddingされたテンソル:\\n', padded)\n",
        "padded = padded.transpose(0,1) # (max_length, batch_size)に転置\n",
        "print('padding & 転置されたテンソル:\\n', padded)\n",
        "print('padding & 転置されたテンソルのサイズ:\\n', padded.size())\n",
        "print()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "各サンプルの系列長: [4, 3, 2]\n",
            "\n",
            "paddingされたテンソル:\n",
            " tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 0],\n",
            "        [8, 9, 0, 0]])\n",
            "padding & 転置されたテンソル:\n",
            " tensor([[1, 5, 8],\n",
            "        [2, 6, 9],\n",
            "        [3, 7, 0],\n",
            "        [4, 0, 0]])\n",
            "padding & 転置されたテンソルのサイズ:\n",
            " torch.Size([4, 3])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnQ5uDm7Vx4x",
        "outputId": "97f7f61b-de53-4044-f595-459880b64195"
      },
      "source": [
        "# PackedSequenceに変換（テンソルをRNNに入力する前に適用する）\n",
        "packed = pack_padded_sequence(padded, lengths=lengths) # 各サンプルの系列長も与える\n",
        "print('PackedSequenceのインスタンス:\\n', packed) # テンソルのPAD以外の値(data)と各時刻で計算が必要な(=PADに到達していない)バッチの数(batch_sizes)を有するインスタンス\n",
        "print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PackedSequenceのインスタンス:\n",
            " PackedSequence(data=tensor([1, 5, 8, 2, 6, 9, 3, 7, 4]), batch_sizes=tensor([3, 3, 2, 1]))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_F3tGyEV0tt",
        "outputId": "1e73d77f-aba1-4c71-bd1d-f88fb36c16c8"
      },
      "source": [
        "# PackedSequenceのインスタンスをRNNに入力する（ここでは省略）\n",
        "output = packed\n",
        "\n",
        "# テンソルに戻す(RNNの出力に対して適用する)\n",
        "output, _length = pad_packed_sequence(output)  # PADを含む元のテンソルと各サンプルの系列長を返す\n",
        "print('PADを含む元のテンソル:\\n', output)\n",
        "print('各サンプルの系列長:', _length)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PADを含む元のテンソル:\n",
            " tensor([[1, 5, 8],\n",
            "        [2, 6, 9],\n",
            "        [3, 7, 0],\n",
            "        [4, 0, 0]])\n",
            "各サンプルの系列長: tensor([4, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEg8wJwxV7d3"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNJ1ztOmV2t7"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        \"\"\"\n",
        "        :param input_size: int, 入力言語の語彙数\n",
        "        :param hidden_size: int, 隠れ層のユニット数\n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=PAD)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, seqs, input_lengths, hidden=None):\n",
        "        \"\"\"\n",
        "        :param seqs: tensor, 入力のバッチ, size=(max_length, batch_size)\n",
        "        :param input_lengths: 入力のバッチの各サンプルの文長\n",
        "        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
        "        :return output: tensor, Encoderの出力, size=(max_length, batch_size, hidden_size)\n",
        "        :return hidden: tensor, Encoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        emb = self.embedding(seqs) # seqsはパディング済み\n",
        "        packed = pack_padded_sequence(emb, input_lengths) # PackedSequenceオブジェクトに変換\n",
        "        output, hidden = self.gru(packed, hidden)\n",
        "        output, _ = pad_packed_sequence(output)\n",
        "        return output, hidden"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWo_6kR9V_gL"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fp-zekAV-lN"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        \"\"\"\n",
        "        :param hidden_size: int, 隠れ層のユニット数\n",
        "        :param output_size: int, 出力言語の語彙数\n",
        "        :param dropout: float, ドロップアウト率\n",
        "        \"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, seqs, hidden):\n",
        "        \"\"\"\n",
        "        :param seqs: tensor, 入力のバッチ, size=(1, batch_size)\n",
        "        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
        "        :return output: tensor, Decoderの出力, size=(1, batch_size, output_size)\n",
        "        :return hidden: tensor, Decoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        emb = self.embedding(seqs)\n",
        "        output, hidden = self.gru(emb, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxMRL46iWKJF"
      },
      "source": [
        "## EncoderDecoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf44wZ0PWFpn"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"EncoderとDecoderの処理をまとめる\"\"\"\n",
        "    def __init__(self, input_size, output_size, hidden_size):\n",
        "        \"\"\"\n",
        "        :param input_size: int, 入力言語の語彙数\n",
        "        :param output_size: int, 出力言語の語彙数\n",
        "        :param hidden_size: int, 隠れ層のユニット数\n",
        "        \"\"\"\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = Encoder(input_size, hidden_size)\n",
        "        self.decoder = Decoder(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, batch_X, lengths_X, max_length, batch_Y=None, use_teacher_forcing=False):\n",
        "        \"\"\"\n",
        "        :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n",
        "        :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n",
        "        :param max_length: int, Decoderの最大文長\n",
        "        :param batch_Y: tensor, Decoderで用いるターゲット系列\n",
        "        :param use_teacher_forcing: Decoderでターゲット系列を入力とするフラグ\n",
        "        :return decoder_outputs: tensor, Decoderの出力, \n",
        "            size=(max_length, batch_size, self.decoder.output_size)\n",
        "        \"\"\"\n",
        "        # encoderに系列を入力（複数時刻をまとめて処理）\n",
        "        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n",
        "        \n",
        "        _batch_size = batch_X.size(1)\n",
        "\n",
        "        # decoderの入力と隠れ層の初期状態を定義\n",
        "        decoder_input = torch.tensor([BOS] * _batch_size, dtype=torch.long, device=device) # 最初の入力にはBOSを使用する\n",
        "        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
        "        decoder_hidden = encoder_hidden  # Encoderの最終隠れ状態を取得\n",
        "\n",
        "        # decoderの出力のホルダーを定義\n",
        "        decoder_outputs = torch.zeros(max_length, _batch_size, self.decoder.output_size, device=device) # max_length分の固定長\n",
        "\n",
        "        # 各時刻ごとに処理\n",
        "        for t in range(max_length):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            decoder_outputs[t] = decoder_output\n",
        "            # 次の時刻のdecoderの入力を決定\n",
        "            if use_teacher_forcing and batch_Y is not None:  # teacher forceの場合、ターゲット系列を用いる\n",
        "                decoder_input = batch_Y[t].unsqueeze(0)\n",
        "            else:  # teacher forceでない場合、自身の出力を用いる\n",
        "                decoder_input = decoder_output.max(-1)[1]\n",
        "                \n",
        "        return decoder_outputs"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM9tgK4kWQhv"
      },
      "source": [
        "## 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdUZ1uLCWOF_",
        "outputId": "442ee7fa-482c-427a-d1e2-b2b55ad6be40"
      },
      "source": [
        "mce = nn.CrossEntropyLoss(size_average=False, ignore_index=PAD) # PADを無視する\n",
        "def masked_cross_entropy(logits, target):\n",
        "    logits_flat = logits.view(-1, logits.size(-1)) # (max_seq_len * batch_size, output_size)\n",
        "    target_flat = target.view(-1) # (a * batch_size, 1)\n",
        "    return mce(logits_flat, target_flat)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxdNqSF5WXLn"
      },
      "source": [
        "### 学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdQKeOcYWUoX"
      },
      "source": [
        "# ハイパーパラメータの設定\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "lr = 1e-3  # 学習率\n",
        "teacher_forcing_rate = 0.2  # Teacher Forcingを行う確率\n",
        "ckpt_path = 'model.pth'  # 学習済みのモデルを保存するパス\n",
        "\n",
        "model_args = {\n",
        "    'input_size': vocab_size_X,\n",
        "    'output_size': vocab_size_Y,\n",
        "    'hidden_size': 256,\n",
        "}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyTqI7QnWb3T"
      },
      "source": [
        "# データローダを定義\n",
        "train_dataloader = DataLoader(train_X, train_Y, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_X, valid_Y, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# モデルとOptimizerを定義\n",
        "model = EncoderDecoder(**model_args).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6nA_FLjWlt2"
      },
      "source": [
        "def compute_loss(batch_X, batch_Y, lengths_X, model, optimizer=None, is_train=True):\n",
        "    # 損失を計算する関数\n",
        "    model.train(is_train)  # train/evalモードの切替え\n",
        "    \n",
        "    # 一定確率でTeacher Forcingを行う\n",
        "    use_teacher_forcing = is_train and (random.random() < teacher_forcing_rate)\n",
        "    max_length = batch_Y.size(0)\n",
        "    # 推論\n",
        "    pred_Y = model(batch_X, lengths_X, max_length, batch_Y, use_teacher_forcing)\n",
        "    \n",
        "    # 損失関数を計算\n",
        "    loss = masked_cross_entropy(pred_Y.contiguous(), batch_Y.contiguous())\n",
        "    \n",
        "    if is_train:  # 訓練時はパラメータを更新\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    batch_Y = batch_Y.transpose(0, 1).contiguous().data.cpu().tolist()\n",
        "    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().T.tolist()\n",
        "\n",
        "    return loss.item(), batch_Y, pred"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uijPCRzJWoSh"
      },
      "source": [
        "def calc_bleu(refs, hyps):\n",
        "    \"\"\"\n",
        "    BLEUスコアを計算する関数\n",
        "    :param refs: list, 参照訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
        "    :param hyps: list, モデルの生成した訳。単語のリストのリスト (例： ['I', 'have', 'a', 'pen'])\n",
        "    :return: float, BLEUスコア(0~100)\n",
        "    \"\"\"\n",
        "    refs = [[ref[:ref.index(EOS)]] for ref in refs] # EOSは評価しないで良いので切り捨てる, refsのほうは複数なのでlistが一個多くかかっている\n",
        "    hyps = [hyp[:hyp.index(EOS)] if EOS in hyp else hyp for hyp in hyps]\n",
        "    return 100 * bleu_score.corpus_bleu(refs, hyps)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qi5V8VrWrNv",
        "outputId": "69df7349-661a-4554-e44e-a7465c0d4244"
      },
      "source": [
        "# 訓練\n",
        "best_valid_bleu = 0.\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    train_loss = 0.\n",
        "    train_refs = []\n",
        "    train_hyps = []\n",
        "    valid_loss = 0.\n",
        "    valid_refs = []\n",
        "    valid_hyps = []\n",
        "    # train\n",
        "    for batch in train_dataloader:\n",
        "        batch_X, batch_Y, lengths_X = batch\n",
        "        loss, gold, pred = compute_loss(\n",
        "            batch_X, batch_Y, lengths_X, model, optimizer, \n",
        "            is_train=True\n",
        "            )\n",
        "        train_loss += loss\n",
        "        train_refs += gold\n",
        "        train_hyps += pred\n",
        "    # valid\n",
        "    for batch in valid_dataloader:\n",
        "        batch_X, batch_Y, lengths_X = batch\n",
        "        loss, gold, pred = compute_loss(\n",
        "            batch_X, batch_Y, lengths_X, model, \n",
        "            is_train=False\n",
        "            )\n",
        "        valid_loss += loss\n",
        "        valid_refs += gold\n",
        "        valid_hyps += pred\n",
        "    # 損失をサンプル数で割って正規化\n",
        "    train_loss = np.sum(train_loss) / len(train_dataloader.data)\n",
        "    valid_loss = np.sum(valid_loss) / len(valid_dataloader.data)\n",
        "    # BLEUを計算\n",
        "    train_bleu = calc_bleu(train_refs, train_hyps)\n",
        "    valid_bleu = calc_bleu(valid_refs, valid_hyps)\n",
        "\n",
        "    # validationデータでBLEUが改善した場合にはモデルを保存\n",
        "    if valid_bleu > best_valid_bleu:\n",
        "        ckpt = model.state_dict()\n",
        "        torch.save(ckpt, ckpt_path)\n",
        "        best_valid_bleu = valid_bleu\n",
        "\n",
        "    print('Epoch {}: train_loss: {:5.2f}  train_bleu: {:2.2f}  valid_loss: {:5.2f}  valid_bleu: {:2.2f}'.format(\n",
        "            epoch, train_loss, train_bleu, valid_loss, valid_bleu))\n",
        "        \n",
        "    print('-'*80)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss: 52.58  train_bleu: 3.28  valid_loss: 48.89  valid_bleu: 4.48\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2: train_loss: 44.79  train_bleu: 7.28  valid_loss: 44.65  valid_bleu: 7.94\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3: train_loss: 40.18  train_bleu: 11.34  valid_loss: 42.28  valid_bleu: 10.52\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4: train_loss: 37.49  train_bleu: 13.57  valid_loss: 41.77  valid_bleu: 14.45\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5: train_loss: 35.21  train_bleu: 16.22  valid_loss: 40.40  valid_bleu: 14.01\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6: train_loss: 33.25  train_bleu: 18.52  valid_loss: 40.12  valid_bleu: 15.45\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7: train_loss: 31.77  train_bleu: 20.44  valid_loss: 40.50  valid_bleu: 17.03\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8: train_loss: 30.56  train_bleu: 22.28  valid_loss: 39.90  valid_bleu: 16.05\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9: train_loss: 29.19  train_bleu: 24.21  valid_loss: 40.12  valid_bleu: 15.75\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10: train_loss: 27.99  train_bleu: 26.36  valid_loss: 40.45  valid_bleu: 17.36\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN05e7AiYSPJ"
      },
      "source": [
        "## 評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgKgslWLWwkp"
      },
      "source": [
        "# 学習済みモデルの読み込み\n",
        "ckpt = torch.load(ckpt_path) # cpuで処理する場合はmap_locationで指定する必要があります。\n",
        "model.load_state_dict(ckpt)\n",
        "model.eval()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl3W0mELYY39"
      },
      "source": [
        "def ids_to_sentence(vocab, ids):\n",
        "    # IDのリストを単語のリストに変換する\n",
        "    return [vocab.id2word[_id] for _id in ids]\n",
        "\n",
        "def trim_eos(ids):\n",
        "    # IDのリストからEOS以降の単語を除外する\n",
        "    if EOS in ids:\n",
        "        return ids[:ids.index(EOS)]\n",
        "    else:\n",
        "        return ids"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnsNyTTAYY7A"
      },
      "source": [
        "# テストデータの読み込み\n",
        "test_X = load_data('./data/dev.en')\n",
        "test_Y = load_data('./data/dev.ja')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAOqUxtfYY9N"
      },
      "source": [
        "test_X = [sentence_to_ids(vocab_X, sentence) for sentence in test_X]\n",
        "test_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in test_Y]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ4xcKaMYZDY"
      },
      "source": [
        "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N2rEiC1YZOW",
        "outputId": "6ae69823-0ed3-4774-ad45-171283d8d8e9"
      },
      "source": [
        "# 生成\n",
        "batch_X, batch_Y, lengths_X = next(test_dataloader)\n",
        "sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n",
        "sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n",
        "print('src: {}'.format(sentence_X))\n",
        "print('tgt: {}'.format(sentence_Y))\n",
        "\n",
        "output = model(batch_X, lengths_X, max_length=20)\n",
        "output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
        "output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n",
        "output_sentence_without_trim = ' '.join(ids_to_sentence(vocab_Y, output))\n",
        "print('out: {}'.format(output_sentence))\n",
        "print('without trim: {}'.format(output_sentence_without_trim))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src: show your own business .\n",
            "tgt: 自分 の 事 を しろ 。\n",
            "out: 自分 の 仕事 を や っ なさ い 。\n",
            "without trim: 自分 の 仕事 を や っ なさ い 。 </S> </S> </S> </S> </S> </S> </S> </S> </S> </S> </S>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yX3895YYZRZ",
        "outputId": "1a863b7c-767f-47d6-c741-f6a0937824d2"
      },
      "source": [
        "# BLEUの計算\n",
        "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)\n",
        "refs_list = []\n",
        "hyp_list = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch_X, batch_Y, lengths_X = batch\n",
        "    pred_Y = model(batch_X, lengths_X, max_length=20)\n",
        "    pred = pred_Y.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
        "    refs = batch_Y.view(-1).data.cpu().tolist()\n",
        "    refs_list.append(refs)\n",
        "    hyp_list.append(pred)\n",
        "bleu = calc_bleu(refs_list, hyp_list)\n",
        "print(bleu)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.194397546904117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTvi9EpKYvyQ"
      },
      "source": [
        "### Beam Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmbnvHMcYwNo"
      },
      "source": [
        "class BeamEncoderDecoder(EncoderDecoder):\n",
        "    \"\"\"\n",
        "    Beam Searchでdecodeを行うためのクラス\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_size, hidden_size, beam_size=4):\n",
        "        \"\"\"\n",
        "        :param input_size: int, 入力言語の語彙数\n",
        "        :param output_size: int, 出力言語の語彙数\n",
        "        :param hidden_size: int, 隠れ層のユニット数\n",
        "        :param beam_size: int, ビーム数\n",
        "        \"\"\"\n",
        "        super(BeamEncoderDecoder, self).__init__(input_size, output_size, hidden_size)\n",
        "        self.beam_size = beam_size\n",
        "\n",
        "    def forward(self, batch_X, lengths_X, max_length):\n",
        "        \"\"\"\n",
        "        :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n",
        "        :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n",
        "        :param max_length: int, Decoderの最大文長\n",
        "        :return decoder_outputs: list, 各ビームのDecoderの出力\n",
        "        :return finished_scores: list of float, 各ビームのスコア\n",
        "        \"\"\"\n",
        "        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n",
        "\n",
        "        # decoderの入力と隠れ層の初期状態を定義\n",
        "        decoder_input = torch.tensor([BOS] * self.beam_size, dtype=torch.long, device=device)\n",
        "        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # beam_sizeの数だけrepeatする\n",
        "        decoder_input = decoder_input.expand(1, beam_size)\n",
        "        decoder_hidden = decoder_hidden.expand(1, beam_size, -1).contiguous()\n",
        "\n",
        "        k = beam_size\n",
        "        finished_beams = []\n",
        "        finished_scores = []\n",
        "        prev_probs = torch.zeros(beam_size, 1, dtype=torch.float, device=device)  # 前の時刻の各ビームの対数尤度を保持しておく\n",
        "        output_size = self.decoder.output_size\n",
        "\n",
        "        # 各時刻ごとに処理\n",
        "        for t in range(max_length):\n",
        "            # decoder_input: (1, k)\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input[-1:], decoder_hidden)\n",
        "            # decoder_output: (1, k, output_size)\n",
        "            # decoder_hidden: (1, k, hidden_size)\n",
        "            decoder_output_t = decoder_output[-1]  # (k, output_size)\n",
        "            log_probs = prev_probs + F.log_softmax(decoder_output_t, dim=-1)  # (k, output_size)\n",
        "            scores = log_probs  # 対数尤度をスコアとする\n",
        "\n",
        "            # スコアの高いビームとその単語を取得\n",
        "            flat_scores = scores.view(-1)  # (k*output_size,)\n",
        "            if t == 0:\n",
        "                flat_scores = flat_scores[:output_size]  # t=0のときは後半の同じ値の繰り返しを除外\n",
        "            top_vs, top_is = flat_scores.data.topk(k)\n",
        "            beam_indices = top_is / output_size  # (k,)\n",
        "            word_indices = top_is % output_size  # (k,)\n",
        "            \n",
        "            # ビームを更新する\n",
        "            _next_beam_indices = []\n",
        "            _next_word_indices = []\n",
        "            for b, w in zip(beam_indices, word_indices):\n",
        "                if w.item() == EOS:  # EOSに到達した場合はそのビームは更新して終了\n",
        "                    k -= 1\n",
        "                    beam = torch.cat([decoder_input.t()[b], w.view(1,)])  # (t+2,)\n",
        "                    score = scores[b, w].item()\n",
        "                    finished_beams.append(beam)\n",
        "                    finished_scores.append(score)\n",
        "                else:   # それ以外の場合はビームを更新\n",
        "                    _next_beam_indices.append(b)\n",
        "                    _next_word_indices.append(w)\n",
        "            if k == 0:\n",
        "                break\n",
        "\n",
        "            # tensorｎに変換\n",
        "            next_beam_indices = torch.tensor(_next_beam_indices, device=device)\n",
        "            next_word_indices = torch.tensor(_next_word_indices, device=device)\n",
        "\n",
        "            # 次の時刻のDecoderの入力を更新\n",
        "            decoder_input = torch.index_select(\n",
        "                decoder_input, dim=-1, index=next_beam_indices)\n",
        "            decoder_input = torch.cat(\n",
        "                [decoder_input, next_word_indices.unsqueeze(0)], dim=0)\n",
        "    \n",
        "            # 次の時刻のDecoderの隠れ層を更新\n",
        "            decoder_hidden = torch.index_select(\n",
        "                decoder_hidden, dim=1, index=next_beam_indices)\n",
        "\n",
        "            # 各ビームの対数尤度を更新\n",
        "            flat_probs = log_probs.view(-1)  # (k*output_size,)\n",
        "            next_indices = (next_beam_indices + 1) * next_word_indices\n",
        "            prev_probs = torch.index_select(\n",
        "                flat_probs, dim=0, index=next_indices).unsqueeze(1)  # (k, 1)\n",
        "\n",
        "        # すべてのビームが完了したらデータを整形\n",
        "        decoder_outputs = [[idx.item() for idx in beam[1:-1]] for beam in finished_beams]\n",
        "        \n",
        "        return decoder_outputs, finished_scores"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B-rhHQ7Y5n0",
        "outputId": "d468055d-a575-4517-b788-80919ae7ca0d"
      },
      "source": [
        "# 学習済みモデルの読み込み\n",
        "beam_size = 3\n",
        "beam_model = BeamEncoderDecoder(**model_args, beam_size=beam_size).to(device)\n",
        "beam_model.load_state_dict(ckpt)\n",
        "beam_model.eval()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BeamEncoderDecoder(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(3725, 256, padding_idx=0)\n",
              "    (gru): GRU(256, 256)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(4405, 256, padding_idx=0)\n",
              "    (gru): GRU(256, 256)\n",
              "    (out): Linear(in_features=256, out_features=4405, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46g-08qCZBDn"
      },
      "source": [
        "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y-AR5UOZBAr",
        "outputId": "a8cd4566-7dd6-45d0-81dd-b16c09304d33"
      },
      "source": [
        "# 生成\n",
        "batch_X, batch_Y, lengths_X = next(test_dataloader)\n",
        "sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n",
        "sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n",
        "print('src: {}'.format(sentence_X))\n",
        "print('tgt: {}'.format(sentence_Y))\n",
        "\n",
        "# 普通のdecode\n",
        "output = model(batch_X, lengths_X, max_length=20)\n",
        "output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
        "output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n",
        "print('out: {}'.format(output_sentence))\n",
        "\n",
        "# beam decode\n",
        "outputs, scores = beam_model(batch_X, lengths_X, max_length=20)\n",
        "# scoreの良い順にソート\n",
        "outputs, scores = zip(*sorted(zip(outputs, scores), key=lambda x: -x[1]))\n",
        "for o, output in enumerate(outputs):\n",
        "    output_sentence = ' '.join(ids_to_sentence(vocab_Y, output))\n",
        "    print('out{}: {}'.format(o+1, output_sentence))    "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src: show your own business .\n",
            "tgt: 自分 の 事 を しろ 。\n",
            "out: 自分 の 仕事 を や っ なさ い 。\n",
            "out1: 自分 の 仕事 を や っ なさ い 。\n",
            "out2: 自分 の 仕事 を や っ なさ い\n",
            "out3: 自分 の 仕事 を や っ なさ い い 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnKdaAaVZA9_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}