{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMG5VACZ2XWDzuezaGyqXiv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcms2ll/AI-Study/blob/main/ETest/src/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFojLwhYNWJJ",
        "outputId": "b8382c30-7574-4d2d-a734-e237ed41d183"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwd34pz-NmiI"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/rabbit_challenge/DNN_code')\n",
        "\n",
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fcyzzPpZP_d",
        "outputId": "2e084951-a333-4631-eaa8-27bf65d99ee2"
      },
      "source": [
        "! wget https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n",
        "! mkdir images data\n",
        "\n",
        "# data取得\n",
        "! wget https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en -P data/\n",
        "! wget https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja -P data/\n",
        "! wget https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en -P data/\n",
        "! wget https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja -P data/\n",
        "! wget https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en -P data/\n",
        "! wget https://www.dropbox.com/s/ak53qirssci6f1j/train.ja -P data/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-07 11:54:46--  https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/9narw5x4uizmehh/utils.py [following]\n",
            "--2021-12-07 11:54:46--  https://www.dropbox.com/s/raw/9narw5x4uizmehh/utils.py\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc78b44be196efe735e5d85bf369.dl.dropboxusercontent.com/cd/0/inline/BbY-fa5vIn92ZvyHQw4gIhj7WNxDiPeUchK7sBaDyDVGoJeMcLx8-xjZQuCFqkOUO7yIBu3eZQaxWKXQNJb1AyMrWxVfXCEpsqh7joz_Cc8491oj4hahg_TdKK5_RvBF6o0WBtBCv3E2QlOrQVUP5S3m/file# [following]\n",
            "--2021-12-07 11:54:46--  https://uc78b44be196efe735e5d85bf369.dl.dropboxusercontent.com/cd/0/inline/BbY-fa5vIn92ZvyHQw4gIhj7WNxDiPeUchK7sBaDyDVGoJeMcLx8-xjZQuCFqkOUO7yIBu3eZQaxWKXQNJb1AyMrWxVfXCEpsqh7joz_Cc8491oj4hahg_TdKK5_RvBF6o0WBtBCv3E2QlOrQVUP5S3m/file\n",
            "Resolving uc78b44be196efe735e5d85bf369.dl.dropboxusercontent.com (uc78b44be196efe735e5d85bf369.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc78b44be196efe735e5d85bf369.dl.dropboxusercontent.com (uc78b44be196efe735e5d85bf369.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 949 [text/plain]\n",
            "Saving to: ‘utils.py.1’\n",
            "\n",
            "utils.py.1          100%[===================>]     949  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-07 11:54:47 (124 MB/s) - ‘utils.py.1’ saved [949/949]\n",
            "\n",
            "mkdir: cannot create directory ‘images’: File exists\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2021-12-07 11:54:47--  https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/o4kyc52a8we25wy/dev.en [following]\n",
            "--2021-12-07 11:54:48--  https://www.dropbox.com/s/raw/o4kyc52a8we25wy/dev.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc4a89521d9372deddcf1b7b4143.dl.dropboxusercontent.com/cd/0/inline/BbZjUxhMTVWh1WZ4SE7KWDcfpX-fhMxL0AvCOHFekKtZwCFN-jk0SRRf7glag3ttoh8OCkrHDQHCWxRPPzIgwc_3EXw0rLZhkSe5aL47j67UuIGwi8BfFq5vTfdGTFtS2SuyMuNdIpDsJ8pUDX_VtADq/file# [following]\n",
            "--2021-12-07 11:54:48--  https://uc4a89521d9372deddcf1b7b4143.dl.dropboxusercontent.com/cd/0/inline/BbZjUxhMTVWh1WZ4SE7KWDcfpX-fhMxL0AvCOHFekKtZwCFN-jk0SRRf7glag3ttoh8OCkrHDQHCWxRPPzIgwc_3EXw0rLZhkSe5aL47j67UuIGwi8BfFq5vTfdGTFtS2SuyMuNdIpDsJ8pUDX_VtADq/file\n",
            "Resolving uc4a89521d9372deddcf1b7b4143.dl.dropboxusercontent.com (uc4a89521d9372deddcf1b7b4143.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc4a89521d9372deddcf1b7b4143.dl.dropboxusercontent.com (uc4a89521d9372deddcf1b7b4143.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17054 (17K) [text/plain]\n",
            "Saving to: ‘data/dev.en.1’\n",
            "\n",
            "dev.en.1            100%[===================>]  16.65K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-12-07 11:54:49 (881 KB/s) - ‘data/dev.en.1’ saved [17054/17054]\n",
            "\n",
            "--2021-12-07 11:54:49--  https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/kdgskm5hzg6znuc/dev.ja [following]\n",
            "--2021-12-07 11:54:49--  https://www.dropbox.com/s/raw/kdgskm5hzg6znuc/dev.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc566a1c062432105623ad6f91cb.dl.dropboxusercontent.com/cd/0/inline/BbbU61i99HQUt7YB-8SaZbxp-CU8HGsBYGWLf8RGEW2Zn-CLXd3JGok3VZZHvoNfExPRoZ8fSb8wCT8Qa9ZI0EdGCXghVVetSzNCMwD5ETsrLtG8LqO_iXP63RL1IOY_FbYlw09JkYUqyoDAu-O1ixaJ/file# [following]\n",
            "--2021-12-07 11:54:50--  https://uc566a1c062432105623ad6f91cb.dl.dropboxusercontent.com/cd/0/inline/BbbU61i99HQUt7YB-8SaZbxp-CU8HGsBYGWLf8RGEW2Zn-CLXd3JGok3VZZHvoNfExPRoZ8fSb8wCT8Qa9ZI0EdGCXghVVetSzNCMwD5ETsrLtG8LqO_iXP63RL1IOY_FbYlw09JkYUqyoDAu-O1ixaJ/file\n",
            "Resolving uc566a1c062432105623ad6f91cb.dl.dropboxusercontent.com (uc566a1c062432105623ad6f91cb.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc566a1c062432105623ad6f91cb.dl.dropboxusercontent.com (uc566a1c062432105623ad6f91cb.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27781 (27K) [text/plain]\n",
            "Saving to: ‘data/dev.ja.1’\n",
            "\n",
            "dev.ja.1            100%[===================>]  27.13K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-12-07 11:54:50 (599 KB/s) - ‘data/dev.ja.1’ saved [27781/27781]\n",
            "\n",
            "--2021-12-07 11:54:50--  https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/gyyx4gohv9v65uh/test.en [following]\n",
            "--2021-12-07 11:54:51--  https://www.dropbox.com/s/raw/gyyx4gohv9v65uh/test.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc2c0c690c40f984a01b99eb8633.dl.dropboxusercontent.com/cd/0/inline/BbaoUWrZ-3JT9H71z0pbQTtHeShRtYH72f-wSOj58xaDowi1zcNWraiVXclCgyfjstbzl-n4Ewi9i1-WrJ7CsBkhVA4EpaCmNEfoppMIeJ9SY5_LedY7KHhw2-yektvdqV5dO1BxrOZ1lDWprGueQRgS/file# [following]\n",
            "--2021-12-07 11:54:51--  https://uc2c0c690c40f984a01b99eb8633.dl.dropboxusercontent.com/cd/0/inline/BbaoUWrZ-3JT9H71z0pbQTtHeShRtYH72f-wSOj58xaDowi1zcNWraiVXclCgyfjstbzl-n4Ewi9i1-WrJ7CsBkhVA4EpaCmNEfoppMIeJ9SY5_LedY7KHhw2-yektvdqV5dO1BxrOZ1lDWprGueQRgS/file\n",
            "Resolving uc2c0c690c40f984a01b99eb8633.dl.dropboxusercontent.com (uc2c0c690c40f984a01b99eb8633.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6030:15::a27d:500f\n",
            "Connecting to uc2c0c690c40f984a01b99eb8633.dl.dropboxusercontent.com (uc2c0c690c40f984a01b99eb8633.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17301 (17K) [text/plain]\n",
            "Saving to: ‘data/test.en.1’\n",
            "\n",
            "test.en.1           100%[===================>]  16.90K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-12-07 11:54:52 (5.96 MB/s) - ‘data/test.en.1’ saved [17301/17301]\n",
            "\n",
            "--2021-12-07 11:54:52--  https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/hotxwbgoe2n013k/test.ja [following]\n",
            "--2021-12-07 11:54:52--  https://www.dropbox.com/s/raw/hotxwbgoe2n013k/test.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucaff6d6363d107f3a029b681649.dl.dropboxusercontent.com/cd/0/inline/Bbabco8Qg3LQKt3Lq27Aaj1_1htolLjGbhqGFuFm7ShX8V-d9w-eKS92EDyCRmpn_5Ko80a8ADaqb3mnRWaGhmHKoYF08zqx_sOlPARttUpFzU2B9IWm74aUqAOJReZmR9LgbV_QbxjKGHCuJ7CvECHH/file# [following]\n",
            "--2021-12-07 11:54:53--  https://ucaff6d6363d107f3a029b681649.dl.dropboxusercontent.com/cd/0/inline/Bbabco8Qg3LQKt3Lq27Aaj1_1htolLjGbhqGFuFm7ShX8V-d9w-eKS92EDyCRmpn_5Ko80a8ADaqb3mnRWaGhmHKoYF08zqx_sOlPARttUpFzU2B9IWm74aUqAOJReZmR9LgbV_QbxjKGHCuJ7CvECHH/file\n",
            "Resolving ucaff6d6363d107f3a029b681649.dl.dropboxusercontent.com (ucaff6d6363d107f3a029b681649.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to ucaff6d6363d107f3a029b681649.dl.dropboxusercontent.com (ucaff6d6363d107f3a029b681649.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27793 (27K) [text/plain]\n",
            "Saving to: ‘data/test.ja.1’\n",
            "\n",
            "test.ja.1           100%[===================>]  27.14K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-12-07 11:54:53 (574 KB/s) - ‘data/test.ja.1’ saved [27793/27793]\n",
            "\n",
            "--2021-12-07 11:54:53--  https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/5lsftkmb20ay9e1/train.en [following]\n",
            "--2021-12-07 11:54:54--  https://www.dropbox.com/s/raw/5lsftkmb20ay9e1/train.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca6153bd1988e4fdce7d905878f.dl.dropboxusercontent.com/cd/0/inline/BbbTQOucRk13LfyPVYLXaZmnhhEH5tMDdYOpOHCtDt-j4CspVPu0RvhsaRn4Iv-bhk8XyyomNNZDrcHnjy9cnUV2CNOsg9PzlxOjZu6-MC_LSqp5eA4xKy5QKGxDadZoyp_QO9CnVoCxIWT7o4rFul8K/file# [following]\n",
            "--2021-12-07 11:54:54--  https://uca6153bd1988e4fdce7d905878f.dl.dropboxusercontent.com/cd/0/inline/BbbTQOucRk13LfyPVYLXaZmnhhEH5tMDdYOpOHCtDt-j4CspVPu0RvhsaRn4Iv-bhk8XyyomNNZDrcHnjy9cnUV2CNOsg9PzlxOjZu6-MC_LSqp5eA4xKy5QKGxDadZoyp_QO9CnVoCxIWT7o4rFul8K/file\n",
            "Resolving uca6153bd1988e4fdce7d905878f.dl.dropboxusercontent.com (uca6153bd1988e4fdce7d905878f.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uca6153bd1988e4fdce7d905878f.dl.dropboxusercontent.com (uca6153bd1988e4fdce7d905878f.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1701356 (1.6M) [text/plain]\n",
            "Saving to: ‘data/train.en.1’\n",
            "\n",
            "train.en.1          100%[===================>]   1.62M  3.64MB/s    in 0.4s    \n",
            "\n",
            "2021-12-07 11:54:55 (3.64 MB/s) - ‘data/train.en.1’ saved [1701356/1701356]\n",
            "\n",
            "--2021-12-07 11:54:55--  https://www.dropbox.com/s/ak53qirssci6f1j/train.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ak53qirssci6f1j/train.ja [following]\n",
            "--2021-12-07 11:54:56--  https://www.dropbox.com/s/raw/ak53qirssci6f1j/train.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc286417a64b0bc9b15b3beb8581.dl.dropboxusercontent.com/cd/0/inline/BbYDntelUuRu_UFSaeZZR7XUi_9k9NdV4o0VanBE44qKXv2oZBcdbShJZo_RcDU2RzpFobGbcCzyK-BviYd017PNsMekfKy4C2aA4hH8NkPSke34H_Pg-WNfGASPkT0E_j8Fs07oPWu_o4dqPBAvqCGl/file# [following]\n",
            "--2021-12-07 11:54:56--  https://uc286417a64b0bc9b15b3beb8581.dl.dropboxusercontent.com/cd/0/inline/BbYDntelUuRu_UFSaeZZR7XUi_9k9NdV4o0VanBE44qKXv2oZBcdbShJZo_RcDU2RzpFobGbcCzyK-BviYd017PNsMekfKy4C2aA4hH8NkPSke34H_Pg-WNfGASPkT0E_j8Fs07oPWu_o4dqPBAvqCGl/file\n",
            "Resolving uc286417a64b0bc9b15b3beb8581.dl.dropboxusercontent.com (uc286417a64b0bc9b15b3beb8581.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc286417a64b0bc9b15b3beb8581.dl.dropboxusercontent.com (uc286417a64b0bc9b15b3beb8581.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2784447 (2.7M) [text/plain]\n",
            "Saving to: ‘data/train.ja.1’\n",
            "\n",
            "train.ja.1          100%[===================>]   2.66M  4.43MB/s    in 0.6s    \n",
            "\n",
            "2021-12-07 11:54:57 (4.43 MB/s) - ‘data/train.ja.1’ saved [2784447/2784447]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M6DNm0IZQCK"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from nltk import bleu_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from utils import Vocab\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random_state = 42"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1QoljtMZT0R",
        "outputId": "8f57da15-3548-4cc3-cb28-7ed3c73a73d2"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7-wisf_ZT3T"
      },
      "source": [
        "PAD = 0\n",
        "UNK = 1\n",
        "BOS = 2\n",
        "EOS = 3\n",
        "\n",
        "PAD_TOKEN = '<PAD>'\n",
        "UNK_TOKEN = '<UNK>'\n",
        "BOS_TOKEN = '<S>'\n",
        "EOS_TOKEN = '</S>'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0TMDCPVOCyn"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7upbTQewZZKS"
      },
      "source": [
        "## データセット"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6vQ3vwDNxT4"
      },
      "source": [
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    テキストファイルからデータを読み込む\n",
        "    :param file_path: str, テキストファイルのパス\n",
        "    :return data: list, 文章（単語のリスト）のリスト\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for line in open(file_path, encoding='utf-8'):\n",
        "        words = line.strip().split()  # スペースで単語を分割\n",
        "        data.append(words)\n",
        "    return data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qAdEkQFZeYU"
      },
      "source": [
        "train_X = load_data('./data/train.en')\n",
        "train_Y = load_data('./data/train.ja')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHwNPrziZeaC"
      },
      "source": [
        "# 訓練データと検証データに分割\n",
        "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=random_state)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRr62jyqZebZ",
        "outputId": "31a0b382-b2e9-42fb-db83-092570496b9d"
      },
      "source": [
        "# データセットの中身を確認\n",
        "print('train_X:', train_X[:5])\n",
        "print('train_Y:', train_Y[:5])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_X: [['where', 'shall', 'we', 'eat', 'tonight', '?'], ['i', 'made', 'a', 'big', 'mistake', 'in', 'choosing', 'my', 'wife', '.'], ['i', \"'ll\", 'have', 'to', 'think', 'about', 'it', '.'], ['it', 'is', 'called', 'a', 'lily', '.'], ['could', 'you', 'lend', 'me', 'some', 'money', 'until', 'this', 'weekend', '?']]\n",
            "train_Y: [['今夜', 'は', 'どこ', 'で', '食事', 'を', 'し', 'よ', 'う', 'か', '。'], ['僕', 'は', '妻', 'を', '選', 'ぶ', 'の', 'に', '大変', 'な', '間違い', 'を', 'し', 'た', '。'], ['考え', 'と', 'く', 'よ', '。'], ['ｌｉｌｙ', 'と', '呼', 'ば', 'れ', 'て', 'い', 'ま', 'す', '。'], ['今週末', 'まで', 'いくら', 'か', '金', 'を', '貸', 'し', 'て', 'くれ', 'ま', 'せ', 'ん', 'か', '。']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xTlpTb5Zedq"
      },
      "source": [
        "MIN_COUNT = 2  # 語彙に含める単語の最低出現回数\n",
        "\n",
        "word2id = {\n",
        "    PAD_TOKEN: PAD,\n",
        "    BOS_TOKEN: BOS,\n",
        "    EOS_TOKEN: EOS,\n",
        "    UNK_TOKEN: UNK,\n",
        "    }\n",
        "\n",
        "vocab_X = Vocab(word2id=word2id)\n",
        "vocab_Y = Vocab(word2id=word2id)\n",
        "vocab_X.build_vocab(train_X, min_count=MIN_COUNT)\n",
        "vocab_Y.build_vocab(train_Y, min_count=MIN_COUNT)\n",
        "\n",
        "vocab_size_X = len(vocab_X.id2word)\n",
        "vocab_size_Y = len(vocab_Y.id2word)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7wwXObTZegL"
      },
      "source": [
        "def sentence_to_ids(vocab, sentence):\n",
        "    \"\"\"\n",
        "    単語のリストをインデックスのリストに変換する\n",
        "    :param vocab: Vocabのインスタンス\n",
        "    :param sentence: list of str\n",
        "    :return indices: list of int\n",
        "    \"\"\"\n",
        "    ids = [vocab.word2id.get(word, UNK) for word in sentence]\n",
        "    ids = [BOS] + ids + [EOS]  # EOSを末尾に加える\n",
        "    return ids"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czzq3jD_ZeiH"
      },
      "source": [
        "train_X = [sentence_to_ids(vocab_X, sentence) for sentence in train_X]\n",
        "train_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in train_Y]\n",
        "valid_X = [sentence_to_ids(vocab_X, sentence) for sentence in valid_X]\n",
        "valid_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in valid_Y]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAng0OFkZekv"
      },
      "source": [
        "class DataLoader(object):\n",
        "    def __init__(self, src_insts, tgt_insts, batch_size, shuffle=True):\n",
        "        \"\"\"\n",
        "        :param src_insts: list, 入力言語の文章（単語IDのリスト）のリスト\n",
        "        :param tgt_insts: list, 出力言語の文章（単語IDのリスト）のリスト\n",
        "        :param batch_size: int, バッチサイズ\n",
        "        :param shuffle: bool, サンプルの順番をシャッフルするか否か\n",
        "        \"\"\"\n",
        "        self.data = list(zip(src_insts, tgt_insts))\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.start_index = 0\n",
        "        \n",
        "        self.reset()\n",
        "    \n",
        "    def reset(self):\n",
        "        if self.shuffle:\n",
        "            self.data = shuffle(self.data, random_state=random_state)\n",
        "        self.start_index = 0\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "\n",
        "        def preprocess_seqs(seqs):\n",
        "            # パディング\n",
        "            max_length = max([len(s) for s in seqs])\n",
        "            data = [s + [PAD] * (max_length - len(s)) for s in seqs]\n",
        "            # 単語の位置を表現するベクトルを作成\n",
        "            positions = [[pos+1 if w != PAD else 0 for pos, w in enumerate(seq)] for seq in data]\n",
        "            # テンソルに変換\n",
        "            data_tensor = torch.tensor(data, dtype=torch.long, device=device)\n",
        "            position_tensor = torch.tensor(positions, dtype=torch.long, device=device)\n",
        "            return data_tensor, position_tensor            \n",
        "\n",
        "        # ポインタが最後まで到達したら初期化する\n",
        "        if self.start_index >= len(self.data):\n",
        "            self.reset()\n",
        "            raise StopIteration()\n",
        "\n",
        "        # バッチを取得して前処理\n",
        "        src_seqs, tgt_seqs = zip(*self.data[self.start_index:self.start_index+self.batch_size])\n",
        "        src_data, src_pos = preprocess_seqs(src_seqs)\n",
        "        tgt_data, tgt_pos = preprocess_seqs(tgt_seqs)\n",
        "\n",
        "        # ポインタを更新する\n",
        "        self.start_index += self.batch_size\n",
        "\n",
        "        return (src_data, src_pos), (tgt_data, tgt_pos)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkRAGKfMZvG2"
      },
      "source": [
        "### Position Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPFzmhObZent"
      },
      "source": [
        "def position_encoding_init(n_position, d_pos_vec):\n",
        "    \"\"\"\n",
        "    Positional Encodingのための行列の初期化を行う\n",
        "    :param n_position: int, 系列長\n",
        "    :param d_pos_vec: int, 隠れ層の次元数\n",
        "    :return torch.tensor, size=(n_position, d_pos_vec)\n",
        "    \"\"\"\n",
        "    # PADがある単語の位置はpos=0にしておき、position_encも0にする\n",
        "    position_enc = np.array([\n",
        "        [pos / np.power(10000, 2 * (j // 2) / d_pos_vec) for j in range(d_pos_vec)]\n",
        "        if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
        "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2])  # dim 2i\n",
        "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2])  # dim 2i+1\n",
        "    return torch.tensor(position_enc, dtype=torch.float)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osO9lnMUZ2mu"
      },
      "source": [
        "### Scaled Dot-Product Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yBvwd9VvfkF"
      },
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, attn_dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param d_model: int, 隠れ層の次元数\n",
        "        :param attn_dropout: float, ドロップアウト率\n",
        "        \"\"\"\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "        self.temper = np.power(d_model, 0.5)  # スケーリング因子\n",
        "        self.dropout = nn.Dropout(attn_dropout)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, q, k, v, attn_mask):\n",
        "        \"\"\"\n",
        "        :param q: torch.tensor, queryベクトル, \n",
        "            size=(n_head*batch_size, len_q, d_model/n_head)\n",
        "        :param k: torch.tensor, key, \n",
        "            size=(n_head*batch_size, len_k, d_model/n_head)\n",
        "        :param v: torch.tensor, valueベクトル, \n",
        "            size=(n_head*batch_size, len_v, d_model/n_head)\n",
        "        :param attn_mask: torch.tensor, Attentionに適用するマスク, \n",
        "            size=(n_head*batch_size, len_q, len_k)\n",
        "        :return output: 出力ベクトル, \n",
        "            size=(n_head*batch_size, len_q, d_model/n_head)\n",
        "        :return attn: Attention\n",
        "            size=(n_head*batch_size, len_q, len_k)\n",
        "        \"\"\"\n",
        "        # QとKの内積でAttentionの重みを求め、スケーリングする\n",
        "        attn = torch.bmm(q, k.transpose(1, 2)) / self.temper  # (n_head*batch_size, len_q, len_k)\n",
        "        # Attentionをかけたくない部分がある場合は、その部分を負の無限大に飛ばしてSoftmaxの値が0になるようにする\n",
        "        attn.data.masked_fill_(attn_mask, -float('inf'))\n",
        "        \n",
        "        attn = self.softmax(attn)\n",
        "        attn = self.dropout(attn)\n",
        "        output = torch.bmm(attn, v)\n",
        "\n",
        "        return output, attn"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhBLF0NHvmU3"
      },
      "source": [
        "### Multihead Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvd4DxIyZeqt"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param n_head: int, ヘッド数\n",
        "        :param d_model: int, 隠れ層の次元数\n",
        "        :param d_k: int, keyベクトルの次元数\n",
        "        :param d_v: int, valueベクトルの次元数\n",
        "        :param dropout: float, ドロップアウト率\n",
        "        \"\"\"\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.n_head = n_head\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "\n",
        "        # 各ヘッドごとに異なる重みで線形変換を行うための重み\n",
        "        # nn.Parameterを使うことで、Moduleのパラメータとして登録できる. TFでは更新が必要な変数はtf.Variableでラップするのでわかりやすい\n",
        "        self.w_qs = nn.Parameter(torch.empty([n_head, d_model, d_k], dtype=torch.float))\n",
        "        self.w_ks = nn.Parameter(torch.empty([n_head, d_model, d_k], dtype=torch.float))\n",
        "        self.w_vs = nn.Parameter(torch.empty([n_head, d_model, d_v], dtype=torch.float))\n",
        "        # nn.init.xavier_normal_で重みの値を初期化\n",
        "        nn.init.xavier_normal_(self.w_qs)\n",
        "        nn.init.xavier_normal_(self.w_ks)\n",
        "        nn.init.xavier_normal_(self.w_vs)\n",
        "\n",
        "        self.attention = ScaledDotProductAttention(d_model)\n",
        "        self.layer_norm = nn.LayerNorm(d_model) # 各層においてバイアスを除く活性化関数への入力を平均０、分散１に正則化\n",
        "        self.proj = nn.Linear(n_head*d_v, d_model)  # 複数ヘッド分のAttentionの結果を元のサイズに写像するための線形層\n",
        "        # nn.init.xavier_normal_で重みの値を初期化\n",
        "        nn.init.xavier_normal_(self.proj.weight)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, q, k, v, attn_mask=None):\n",
        "        \"\"\"\n",
        "        :param q: torch.tensor, queryベクトル, \n",
        "            size=(batch_size, len_q, d_model)\n",
        "        :param k: torch.tensor, key, \n",
        "            size=(batch_size, len_k, d_model)\n",
        "        :param v: torch.tensor, valueベクトル, \n",
        "            size=(batch_size, len_v, d_model)\n",
        "        :param attn_mask: torch.tensor, Attentionに適用するマスク, \n",
        "            size=(batch_size, len_q, len_k)\n",
        "        :return outputs: 出力ベクトル, \n",
        "            size=(batch_size, len_q, d_model)\n",
        "        :return attns: Attention\n",
        "            size=(n_head*batch_size, len_q, len_k)\n",
        "            \n",
        "        \"\"\"\n",
        "        d_k, d_v = self.d_k, self.d_v\n",
        "        n_head = self.n_head\n",
        "\n",
        "        # residual connectionのための入力 出力に入力をそのまま加算する\n",
        "        residual = q\n",
        "\n",
        "        batch_size, len_q, d_model = q.size()\n",
        "        batch_size, len_k, d_model = k.size()\n",
        "        batch_size, len_v, d_model = v.size()\n",
        "\n",
        "        # 複数ヘッド化\n",
        "        # torch.repeat または .repeatで指定したdimに沿って同じテンソルを作成\n",
        "        q_s = q.repeat(n_head, 1, 1) # (n_head*batch_size, len_q, d_model)\n",
        "        k_s = k.repeat(n_head, 1, 1) # (n_head*batch_size, len_k, d_model)\n",
        "        v_s = v.repeat(n_head, 1, 1) # (n_head*batch_size, len_v, d_model)\n",
        "        # ヘッドごとに並列計算させるために、n_headをdim=0に、batch_sizeをdim=1に寄せる\n",
        "        q_s = q_s.view(n_head, -1, d_model) # (n_head, batch_size*len_q, d_model)\n",
        "        k_s = k_s.view(n_head, -1, d_model) # (n_head, batch_size*len_k, d_model)\n",
        "        v_s = v_s.view(n_head, -1, d_model) # (n_head, batch_size*len_v, d_model)\n",
        "\n",
        "        # 各ヘッドで線形変換を並列計算(p16左側`Linear`)\n",
        "        q_s = torch.bmm(q_s, self.w_qs)  # (n_head, batch_size*len_q, d_k)\n",
        "        k_s = torch.bmm(k_s, self.w_ks)  # (n_head, batch_size*len_k, d_k)\n",
        "        v_s = torch.bmm(v_s, self.w_vs)  # (n_head, batch_size*len_v, d_v)\n",
        "        # Attentionは各バッチ各ヘッドごとに計算させるためにbatch_sizeをdim=0に寄せる\n",
        "        q_s = q_s.view(-1, len_q, d_k)   # (n_head*batch_size, len_q, d_k)\n",
        "        k_s = k_s.view(-1, len_k, d_k)   # (n_head*batch_size, len_k, d_k)\n",
        "        v_s = v_s.view(-1, len_v, d_v)   # (n_head*batch_size, len_v, d_v)\n",
        "\n",
        "        # Attentionを計算(p16.左側`Scaled Dot-Product Attention * h`)\n",
        "        outputs, attns = self.attention(q_s, k_s, v_s, attn_mask=attn_mask.repeat(n_head, 1, 1))\n",
        "\n",
        "        # 各ヘッドの結果を連結(p16左側`Concat`)\n",
        "        # torch.splitでbatch_sizeごとのn_head個のテンソルに分割\n",
        "        outputs = torch.split(outputs, batch_size, dim=0)  # (batch_size, len_q, d_model) * n_head\n",
        "        # dim=-1で連結\n",
        "        outputs = torch.cat(outputs, dim=-1)  # (batch_size, len_q, d_model*n_head)\n",
        "\n",
        "        # residual connectionのために元の大きさに写像(p16左側`Linear`)\n",
        "        outputs = self.proj(outputs)  # (batch_size, len_q, d_model)\n",
        "        outputs = self.dropout(outputs)\n",
        "        outputs = self.layer_norm(outputs + residual)\n",
        "\n",
        "        return outputs, attns"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX59DiWwZ75H"
      },
      "source": [
        "### Position-Wise Feed Forward Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBhEII-3Zeto"
      },
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    :param d_hid: int, 隠れ層1層目の次元数\n",
        "    :param d_inner_hid: int, 隠れ層2層目の次元数\n",
        "    :param dropout: float, ドロップアウト率\n",
        "    \"\"\"\n",
        "    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        # window size 1のconv層を定義することでPosition wiseな全結合層を実現する.\n",
        "        self.w_1 = nn.Conv1d(d_hid, d_inner_hid, 1)\n",
        "        self.w_2 = nn.Conv1d(d_inner_hid, d_hid, 1)\n",
        "        self.layer_norm = nn.LayerNorm(d_hid)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: torch.tensor,\n",
        "            size=(batch_size, max_length, d_hid)\n",
        "        :return: torch.tensor,\n",
        "            size=(batch_size, max_length, d_hid) \n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        output = self.relu(self.w_1(x.transpose(1, 2)))\n",
        "        output = self.w_2(output).transpose(2, 1)\n",
        "        output = self.dropout(output)\n",
        "        return self.layer_norm(output + residual)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rGKBNDcZ93u"
      },
      "source": [
        "### Masking\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcGiGjgmZ-ic"
      },
      "source": [
        "def get_attn_padding_mask(seq_q, seq_k):\n",
        "    \"\"\"\n",
        "    keyのPADに対するattentionを0にするためのマスクを作成する\n",
        "    :param seq_q: tensor, queryの系列, size=(batch_size, len_q)\n",
        "    :param seq_k: tensor, keyの系列, size=(batch_size, len_k)\n",
        "    :return pad_attn_mask: tensor, size=(batch_size, len_q, len_k)\n",
        "    \"\"\"\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(PAD).unsqueeze(1)   # (N, 1, len_k) PAD以外のidを全て0にする\n",
        "    pad_attn_mask = pad_attn_mask.expand(batch_size, len_q, len_k) # (N, len_q, len_k)\n",
        "    return pad_attn_mask"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn1nqo55acRr",
        "outputId": "e1361694-7e24-4e6e-f229-56d1fa606344"
      },
      "source": [
        "_seq_q = torch.tensor([[1, 2, 3]])\n",
        "_seq_k = torch.tensor([[4, 5, 6, 7, PAD]])\n",
        "_mask = get_attn_padding_mask(_seq_q, _seq_k)  # 行がquery、列がkeyに対応し、key側がPAD(=0)の時刻だけ1で他が0の行列ができる\n",
        "print('query:\\n', _seq_q)\n",
        "print('key:\\n', _seq_k)\n",
        "print('mask:\\n', _mask)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query:\n",
            " tensor([[1, 2, 3]])\n",
            "key:\n",
            " tensor([[4, 5, 6, 7, 0]])\n",
            "mask:\n",
            " tensor([[[False, False, False, False,  True],\n",
            "         [False, False, False, False,  True],\n",
            "         [False, False, False, False,  True]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l43oXeqacLl"
      },
      "source": [
        "def get_attn_subsequent_mask(seq):\n",
        "    \"\"\"\n",
        "    未来の情報に対するattentionを0にするためのマスクを作成する\n",
        "    :param seq: tensor, size=(batch_size, length)\n",
        "    :return subsequent_mask: tensor, size=(batch_size, length, length)\n",
        "    \"\"\"\n",
        "    attn_shape = (seq.size(1), seq.size(1))\n",
        "    # 上三角行列(diagonal=1: 対角線より上が1で下が0)\n",
        "    subsequent_mask = torch.triu(torch.ones(attn_shape, dtype=torch.uint8, device=device), diagonal=1)\n",
        "    subsequent_mask = subsequent_mask.repeat(seq.size(0), 1, 1)\n",
        "    return subsequent_mask"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jevr5R9GacI0",
        "outputId": "9f318a63-0915-4a32-f20c-bb10c147072c"
      },
      "source": [
        "_seq = torch.tensor([[1,2,3,4]])\n",
        "_mask = get_attn_subsequent_mask(_seq)  # 行がquery、列がkeyに対応し、queryより未来のkeyの値が1で他は0の行列ができいる\n",
        "print('seq:\\n', _seq)\n",
        "print('mask:\\n', _mask)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seq:\n",
            " tensor([[1, 2, 3, 4]])\n",
            "mask:\n",
            " tensor([[[0, 1, 1, 1],\n",
            "         [0, 0, 1, 1],\n",
            "         [0, 0, 0, 1],\n",
            "         [0, 0, 0, 0]]], dtype=torch.uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CFxFs-VaitC"
      },
      "source": [
        "## モデルの定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAQE74ZEaluT"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bplWEDkacGA"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"Encoderのブロックのクラス\"\"\"\n",
        "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param d_model: int, 隠れ層の次元数\n",
        "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
        "        :param n_head: int,　ヘッド数\n",
        "        :param d_k: int, keyベクトルの次元数\n",
        "        :param d_v: int, valueベクトルの次元数\n",
        "        :param dropout: float, ドロップアウト率\n",
        "        \"\"\"\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        # Encoder内のSelf-Attention\n",
        "        self.slf_attn = MultiHeadAttention(\n",
        "            n_head, d_model, d_k, d_v, dropout=dropout)\n",
        "        # Postionwise FFN\n",
        "        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
        "\n",
        "    def forward(self, enc_input, slf_attn_mask=None):\n",
        "        \"\"\"\n",
        "        :param enc_input: tensor, Encoderの入力, \n",
        "            size=(batch_size, max_length, d_model)\n",
        "        :param slf_attn_mask: tensor, Self Attentionの行列にかけるマスク, \n",
        "            size=(batch_size, len_q, len_k)\n",
        "        :return enc_output: tensor, Encoderの出力, \n",
        "            size=(batch_size, max_length, d_model)\n",
        "        :return enc_slf_attn: tensor, EncoderのSelf Attentionの行列, \n",
        "            size=(n_head*batch_size, len_q, len_k)\n",
        "        \"\"\"\n",
        "        # Self-Attentionのquery, key, valueにはすべてEncoderの入力（enc_input）が入る\n",
        "        enc_output, enc_slf_attn = self.slf_attn(\n",
        "            enc_input, enc_input, enc_input, attn_mask=slf_attn_mask)\n",
        "        enc_output = self.pos_ffn(enc_output)\n",
        "        return enc_output, enc_slf_attn"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXZcZ7RxacC2"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"EncoderLayerブロックからなるEncoderのクラス\"\"\"\n",
        "    def __init__(\n",
        "            self, n_src_vocab, max_length, n_layers=6, n_head=8, d_k=64, d_v=64,\n",
        "            d_word_vec=512, d_model=512, d_inner_hid=1024, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param n_src_vocab: int, 入力言語の語彙数\n",
        "        :param max_length: int, 最大系列長\n",
        "        :param n_layers: int, レイヤー数\n",
        "        :param n_head: int,　ヘッド数\n",
        "        :param d_k: int, keyベクトルの次元数\n",
        "        :param d_v: int, valueベクトルの次元数\n",
        "        :param d_word_vec: int, 単語の埋め込みの次元数\n",
        "        :param d_model: int, 隠れ層の次元数\n",
        "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
        "        :param dropout: float, ドロップアウト率        \n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        n_position = max_length + 1\n",
        "        self.max_length = max_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Positional Encodingを用いたEmbedding\n",
        "        self.position_enc = nn.Embedding(n_position, d_word_vec, padding_idx=PAD)\n",
        "        self.position_enc.weight.data = position_encoding_init(n_position, d_word_vec)\n",
        "\n",
        "        # 一般的なEmbedding\n",
        "        self.src_word_emb = nn.Embedding(n_src_vocab, d_word_vec, padding_idx=PAD)\n",
        "\n",
        "        # EncoderLayerをn_layers個積み重ねる\n",
        "        self.layer_stack = nn.ModuleList([\n",
        "            EncoderLayer(d_model, d_inner_hid, n_head, d_k, d_v, dropout=dropout)\n",
        "            for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, src_seq, src_pos):\n",
        "        \"\"\"\n",
        "        :param src_seq: tensor, 入力系列, \n",
        "            size=(batch_size, max_length)\n",
        "        :param src_pos: tensor, 入力系列の各単語の位置情報,\n",
        "            size=(batch_size, max_length)\n",
        "        :return enc_output: tensor, Encoderの最終出力, \n",
        "            size=(batch_size, max_length, d_model)\n",
        "        :return enc_slf_attns: list, EncoderのSelf Attentionの行列のリスト\n",
        "        \"\"\"\n",
        "        # 一般的な単語のEmbeddingを行う\n",
        "        enc_input = self.src_word_emb(src_seq)\n",
        "        # Positional EncodingのEmbeddingを加算する\n",
        "        enc_input += self.position_enc(src_pos)\n",
        "\n",
        "        enc_slf_attns = []\n",
        "        enc_output = enc_input\n",
        "        # key(=enc_input)のPADに対応する部分のみ1のマスクを作成\n",
        "        enc_slf_attn_mask = get_attn_padding_mask(src_seq, src_seq)\n",
        "\n",
        "        # n_layers個のEncoderLayerに入力を通す\n",
        "        for enc_layer in self.layer_stack:\n",
        "            enc_output, enc_slf_attn = enc_layer(\n",
        "                enc_output, slf_attn_mask=enc_slf_attn_mask)\n",
        "            enc_slf_attns += [enc_slf_attn]\n",
        "\n",
        "        return enc_output, enc_slf_attns"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWgKr_y9ax7i"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5hwYn7mab6H"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"Decoderのブロックのクラス\"\"\"\n",
        "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param d_model: int, 隠れ層の次元数\n",
        "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
        "        :param n_head: int,　ヘッド数\n",
        "        :param d_k: int, keyベクトルの次元数\n",
        "        :param d_v: int, valueベクトルの次元数\n",
        "        :param dropout: float, ドロップアウト率\n",
        "        \"\"\"\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        # Decoder内のSelf-Attention\n",
        "        self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
        "        # Encoder-Decoder間のSource-Target Attention\n",
        "        self.enc_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
        "        # Positionwise FFN\n",
        "        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
        "\n",
        "    def forward(self, dec_input, enc_output, slf_attn_mask=None, dec_enc_attn_mask=None):\n",
        "        \"\"\"\n",
        "        :param dec_input: tensor, Decoderの入力, \n",
        "            size=(batch_size, max_length, d_model)\n",
        "        :param enc_output: tensor, Encoderの出力, \n",
        "            size=(batch_size, max_length, d_model)\n",
        "        :param slf_attn_mask: tensor, Self Attentionの行列にかけるマスク, \n",
        "            size=(batch_size, len_q, len_k)\n",
        "        :param dec_enc_attn_mask: tensor, Soutce-Target Attentionの行列にかけるマスク, \n",
        "            size=(batch_size, len_q, len_k)\n",
        "        :return dec_output: tensor, Decoderの出力, \n",
        "            size=(batch_size, max_length, d_model)\n",
        "        :return dec_slf_attn: tensor, DecoderのSelf Attentionの行列, \n",
        "            size=(n_head*batch_size, len_q, len_k)\n",
        "        :return dec_enc_attn: tensor, DecoderのSoutce-Target Attentionの行列, \n",
        "            size=(n_head*batch_size, len_q, len_k)\n",
        "        \"\"\"\n",
        "        # Self-Attentionのquery, key, valueにはすべてDecoderの入力（dec_input）が入る\n",
        "        dec_output, dec_slf_attn = self.slf_attn(\n",
        "            dec_input, dec_input, dec_input, attn_mask=slf_attn_mask)\n",
        "        # Source-Target-AttentionのqueryにはDecoderの出力(dec_output), key, valueにはEncoderの出力（enc_output）が入る\n",
        "        dec_output, dec_enc_attn = self.enc_attn(\n",
        "            dec_output, enc_output, enc_output, attn_mask=dec_enc_attn_mask)\n",
        "        dec_output = self.pos_ffn(dec_output)\n",
        "\n",
        "        return dec_output, dec_slf_attn, dec_enc_attn"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KF89BGMab3W"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"DecoderLayerブロックからなるDecoderのクラス\"\"\"\n",
        "    def __init__(\n",
        "            self, n_tgt_vocab, max_length, n_layers=6, n_head=8, d_k=64, d_v=64,\n",
        "            d_word_vec=512, d_model=512, d_inner_hid=1024, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param n_tgt_vocab: int, 出力言語の語彙数\n",
        "        :param max_length: int, 最大系列長\n",
        "        :param n_layers: int, レイヤー数\n",
        "        :param n_head: int,　ヘッド数\n",
        "        :param d_k: int, keyベクトルの次元数\n",
        "        :param d_v: int, valueベクトルの次元数\n",
        "        :param d_word_vec: int, 単語の埋め込みの次元数\n",
        "        :param d_model: int, 隠れ層の次元数\n",
        "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
        "        :param dropout: float, ドロップアウト率        \n",
        "        \"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        n_position = max_length + 1\n",
        "        self.max_length = max_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Positional Encodingを用いたEmbedding\n",
        "        self.position_enc = nn.Embedding(\n",
        "            n_position, d_word_vec, padding_idx=PAD)\n",
        "        self.position_enc.weight.data = position_encoding_init(n_position, d_word_vec)\n",
        "\n",
        "        # 一般的なEmbedding\n",
        "        self.tgt_word_emb = nn.Embedding(\n",
        "            n_tgt_vocab, d_word_vec, padding_idx=PAD)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # DecoderLayerをn_layers個積み重ねる\n",
        "        self.layer_stack = nn.ModuleList([\n",
        "            DecoderLayer(d_model, d_inner_hid, n_head, d_k, d_v, dropout=dropout)\n",
        "            for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, tgt_seq, tgt_pos, src_seq, enc_output):\n",
        "        \"\"\"\n",
        "        :param tgt_seq: tensor, 出力系列, \n",
        "            size=(batch_size, max_length)\n",
        "        :param tgt_pos: tensor, 出力系列の各単語の位置情報,\n",
        "            size=(batch_size, max_length)\n",
        "        :param src_seq: tensor, 入力系列, \n",
        "            size=(batch_size, n_src_vocab)\n",
        "        :param enc_output: tensor, Encoderの出力, \n",
        "            size=(batch_size, max_length, d_model)\n",
        "        :return dec_output: tensor, Decoderの最終出力, \n",
        "            size=(batch_size, max_length, d_model)\n",
        "        :return dec_slf_attns: list, DecoderのSelf Attentionの行列のリスト \n",
        "        :return dec_slf_attns: list, DecoderのSelf Attentionの行列のリスト\n",
        "        \"\"\"\n",
        "        # 一般的な単語のEmbeddingを行う\n",
        "        dec_input = self.tgt_word_emb(tgt_seq)\n",
        "        # Positional EncodingのEmbeddingを加算する\n",
        "        dec_input += self.position_enc(tgt_pos)\n",
        "\n",
        "        # Self-Attention用のマスクを作成\n",
        "        # key(=dec_input)のPADに対応する部分が1のマスクと、queryから見たkeyの未来の情報に対応する部分が1のマスクのORをとる\n",
        "        dec_slf_attn_pad_mask = get_attn_padding_mask(tgt_seq, tgt_seq)  # (N, max_length, max_length)\n",
        "        dec_slf_attn_sub_mask = get_attn_subsequent_mask(tgt_seq)  # (N, max_length, max_length)\n",
        "        dec_slf_attn_mask = torch.gt(dec_slf_attn_pad_mask + dec_slf_attn_sub_mask, 0)  # ORをとる\n",
        "\n",
        "        # key(=dec_input)のPADに対応する部分のみ1のマスクを作成\n",
        "        dec_enc_attn_pad_mask = get_attn_padding_mask(tgt_seq, src_seq)  # (N, max_length, max_length)\n",
        "\n",
        "        dec_slf_attns, dec_enc_attns = [], []\n",
        "\n",
        "        dec_output = dec_input\n",
        "        # n_layers個のDecoderLayerに入力を通す\n",
        "        for dec_layer in self.layer_stack:\n",
        "            dec_output, dec_slf_attn, dec_enc_attn = dec_layer(\n",
        "                dec_output, enc_output,\n",
        "                slf_attn_mask=dec_slf_attn_mask,\n",
        "                dec_enc_attn_mask=dec_enc_attn_pad_mask)\n",
        "\n",
        "            dec_slf_attns += [dec_slf_attn]\n",
        "            dec_enc_attns += [dec_enc_attn]\n",
        "\n",
        "        return dec_output, dec_slf_attns, dec_enc_attns"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsfCx-HpbAf-"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"Transformerのモデル全体のクラス\"\"\"\n",
        "    def __init__(\n",
        "            self, n_src_vocab, n_tgt_vocab, max_length, n_layers=6, n_head=8,\n",
        "            d_word_vec=512, d_model=512, d_inner_hid=1024, d_k=64, d_v=64,\n",
        "            dropout=0.1, proj_share_weight=True):\n",
        "        \"\"\"\n",
        "        :param n_src_vocab: int, 入力言語の語彙数\n",
        "        :param n_tgt_vocab: int, 出力言語の語彙数\n",
        "        :param max_length: int, 最大系列長\n",
        "        :param n_layers: int, レイヤー数\n",
        "        :param n_head: int,　ヘッド数\n",
        "        :param d_k: int, keyベクトルの次元数\n",
        "        :param d_v: int, valueベクトルの次元数\n",
        "        :param d_word_vec: int, 単語の埋め込みの次元数\n",
        "        :param d_model: int, 隠れ層の次元数\n",
        "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
        "        :param dropout: float, ドロップアウト率        \n",
        "        :param proj_share_weight: bool, 出力言語の単語のEmbeddingと出力の写像で重みを共有する        \n",
        "        \"\"\"\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(\n",
        "            n_src_vocab, max_length, n_layers=n_layers, n_head=n_head,\n",
        "            d_word_vec=d_word_vec, d_model=d_model,\n",
        "            d_inner_hid=d_inner_hid, dropout=dropout)\n",
        "        self.decoder = Decoder(\n",
        "            n_tgt_vocab, max_length, n_layers=n_layers, n_head=n_head,\n",
        "            d_word_vec=d_word_vec, d_model=d_model,\n",
        "            d_inner_hid=d_inner_hid, dropout=dropout)\n",
        "        self.tgt_word_proj = nn.Linear(d_model, n_tgt_vocab, bias=False)\n",
        "        nn.init.xavier_normal_(self.tgt_word_proj.weight)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        assert d_model == d_word_vec  # 各モジュールの出力のサイズは揃える\n",
        "\n",
        "        if proj_share_weight:\n",
        "            # 出力言語の単語のEmbeddingと出力の写像で重みを共有する\n",
        "            assert d_model == d_word_vec\n",
        "            self.tgt_word_proj.weight = self.decoder.tgt_word_emb.weight\n",
        "\n",
        "    def get_trainable_parameters(self):\n",
        "        # Positional Encoding以外のパラメータを更新する\n",
        "        enc_freezed_param_ids = set(map(id, self.encoder.position_enc.parameters()))\n",
        "        dec_freezed_param_ids = set(map(id, self.decoder.position_enc.parameters()))\n",
        "        freezed_param_ids = enc_freezed_param_ids | dec_freezed_param_ids\n",
        "        return (p for p in self.parameters() if id(p) not in freezed_param_ids)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_seq, src_pos = src\n",
        "        tgt_seq, tgt_pos = tgt\n",
        "\n",
        "        src_seq = src_seq[:, 1:]\n",
        "        src_pos = src_pos[:, 1:]\n",
        "        tgt_seq = tgt_seq[:, :-1]\n",
        "        tgt_pos = tgt_pos[:, :-1]\n",
        "\n",
        "        enc_output, *_ = self.encoder(src_seq, src_pos)\n",
        "        dec_output, *_ = self.decoder(tgt_seq, tgt_pos, src_seq, enc_output)\n",
        "        seq_logit = self.tgt_word_proj(dec_output)\n",
        "\n",
        "        return seq_logit"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3tUKT0HbHFb"
      },
      "source": [
        "## 学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5hTNN9zbAcY"
      },
      "source": [
        "def compute_loss(batch_X, batch_Y, model, criterion, optimizer=None, is_train=True):\n",
        "    # バッチの損失を計算\n",
        "    model.train(is_train)\n",
        "    \n",
        "    pred_Y = model(batch_X, batch_Y)\n",
        "    gold = batch_Y[0][:, 1:].contiguous()\n",
        "#     gold = batch_Y[0].contiguous()\n",
        "    loss = criterion(pred_Y.view(-1, pred_Y.size(2)), gold.view(-1))\n",
        "\n",
        "    if is_train:  # 訓練時はパラメータを更新\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    gold = gold.data.cpu().numpy().tolist()\n",
        "    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().tolist()\n",
        "\n",
        "    return loss.item(), gold, pred"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5-hyliubAZO"
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "batch_size = 64\n",
        "num_epochs = 15\n",
        "lr = 0.001\n",
        "ckpt_path = 'transformer.pth'\n",
        "max_length = MAX_LENGTH + 2"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScfhZhZdbAW5"
      },
      "source": [
        "model_args = {\n",
        "    'n_src_vocab': vocab_size_X,\n",
        "    'n_tgt_vocab': vocab_size_Y,\n",
        "    'max_length': max_length,\n",
        "    'proj_share_weight': True,\n",
        "    'd_k': 32,\n",
        "    'd_v': 32,\n",
        "    'd_model': 128,\n",
        "    'd_word_vec': 128,\n",
        "    'd_inner_hid': 256,\n",
        "    'n_layers': 3,\n",
        "    'n_head': 6,\n",
        "    'dropout': 0.1,\n",
        "}"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdkDWkEYbAUa",
        "outputId": "6c83fff8-57c8-45bc-96ee-335133509e18"
      },
      "source": [
        "# DataLoaderやモデルを定義\n",
        "train_dataloader = DataLoader(\n",
        "    train_X, train_Y, batch_size\n",
        "    )\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_X, valid_Y, batch_size, \n",
        "    shuffle=False\n",
        "    )\n",
        "\n",
        "model = Transformer(**model_args).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.get_trainable_parameters(), lr=lr)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD, size_average=False).to(device)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "236SY2Y2bAR_"
      },
      "source": [
        "def calc_bleu(refs, hyps):\n",
        "    \"\"\"\n",
        "    BLEUスコアを計算する関数\n",
        "    :param refs: list, 参照訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
        "    :param hyps: list, モデルの生成した訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
        "    :return: float, BLEUスコア(0~100)\n",
        "    \"\"\"\n",
        "    refs = [[ref[:ref.index(EOS)]] for ref in refs]\n",
        "    hyps = [hyp[:hyp.index(EOS)] if EOS in hyp else hyp for hyp in hyps]\n",
        "    return 100 * bleu_score.corpus_bleu(refs, hyps)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFsBOTKLbAPJ",
        "outputId": "7021a115-a46c-43bd-c92d-d6a7ae3d8fb9"
      },
      "source": [
        "# 訓練\n",
        "best_valid_bleu = 0.\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    start = time.time()\n",
        "    train_loss = 0.\n",
        "    train_refs = []\n",
        "    train_hyps = []\n",
        "    valid_loss = 0.\n",
        "    valid_refs = []\n",
        "    valid_hyps = []\n",
        "    # train\n",
        "    for batch in train_dataloader:\n",
        "        batch_X, batch_Y = batch\n",
        "        loss, gold, pred = compute_loss(\n",
        "            batch_X, batch_Y, model, criterion, optimizer, is_train=True\n",
        "            )\n",
        "        train_loss += loss\n",
        "        train_refs += gold\n",
        "        train_hyps += pred\n",
        "    # valid\n",
        "    for batch in valid_dataloader:\n",
        "        batch_X, batch_Y = batch\n",
        "        loss, gold, pred = compute_loss(\n",
        "            batch_X, batch_Y, model, criterion, is_train=False\n",
        "            )\n",
        "        valid_loss += loss\n",
        "        valid_refs += gold\n",
        "        valid_hyps += pred\n",
        "    # 損失をサンプル数で割って正規化\n",
        "    train_loss /= len(train_dataloader.data) \n",
        "    valid_loss /= len(valid_dataloader.data) \n",
        "    # BLEUを計算\n",
        "    train_bleu = calc_bleu(train_refs, train_hyps)\n",
        "    valid_bleu = calc_bleu(valid_refs, valid_hyps)\n",
        "\n",
        "    # validationデータでBLEUが改善した場合にはモデルを保存\n",
        "    if valid_bleu > best_valid_bleu:\n",
        "        ckpt = model.state_dict()\n",
        "        torch.save(ckpt, ckpt_path)\n",
        "        best_valid_bleu = valid_bleu\n",
        "\n",
        "    elapsed_time = (time.time()-start) / 60\n",
        "    print('Epoch {} [{:.1f}min]: train_loss: {:5.2f}  train_bleu: {:2.2f}  valid_loss: {:5.2f}  valid_bleu: {:2.2f}'.format(\n",
        "            epoch, elapsed_time, train_loss, train_bleu, valid_loss, valid_bleu))\n",
        "    print('-'*80)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 [6.6min]: train_loss: 77.15  train_bleu: 4.79  valid_loss: 41.32  valid_bleu: 11.45\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2 [6.5min]: train_loss: 39.12  train_bleu: 12.41  valid_loss: 32.14  valid_bleu: 17.63\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3 [6.5min]: train_loss: 31.78  train_bleu: 18.21  valid_loss: 28.05  valid_bleu: 22.17\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4 [6.4min]: train_loss: 28.16  train_bleu: 21.86  valid_loss: 25.66  valid_bleu: 24.91\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5 [6.4min]: train_loss: 25.71  train_bleu: 24.63  valid_loss: 24.12  valid_bleu: 27.43\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6 [6.4min]: train_loss: 23.87  train_bleu: 27.02  valid_loss: 23.00  valid_bleu: 29.02\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7 [6.4min]: train_loss: 22.44  train_bleu: 28.76  valid_loss: 22.10  valid_bleu: 29.98\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8 [6.4min]: train_loss: 21.27  train_bleu: 30.19  valid_loss: 21.57  valid_bleu: 30.73\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9 [6.4min]: train_loss: 20.25  train_bleu: 31.68  valid_loss: 20.89  valid_bleu: 32.12\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10 [6.4min]: train_loss: 19.33  train_bleu: 33.01  valid_loss: 20.46  valid_bleu: 32.94\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 11 [6.4min]: train_loss: 18.54  train_bleu: 34.22  valid_loss: 19.98  valid_bleu: 33.57\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 12 [6.4min]: train_loss: 17.83  train_bleu: 35.22  valid_loss: 19.75  valid_bleu: 33.91\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 13 [6.4min]: train_loss: 17.23  train_bleu: 36.19  valid_loss: 19.25  valid_bleu: 34.77\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 14 [6.4min]: train_loss: 16.62  train_bleu: 37.14  valid_loss: 19.08  valid_bleu: 35.62\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 15 [6.4min]: train_loss: 16.11  train_bleu: 37.89  valid_loss: 19.15  valid_bleu: 35.69\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_uG1Mbfbl_S"
      },
      "source": [
        "## 評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjn-cr4RbAJd"
      },
      "source": [
        "def test(model, src, max_length=20):\n",
        "    # 学習済みモデルで系列を生成する\n",
        "    model.eval()\n",
        "    \n",
        "    src_seq, src_pos = src\n",
        "    batch_size = src_seq.size(0)\n",
        "    enc_output, enc_slf_attns = model.encoder(src_seq, src_pos)\n",
        "        \n",
        "    tgt_seq = torch.full([batch_size, 1], BOS, dtype=torch.long, device=device)\n",
        "    tgt_pos = torch.arange(1, dtype=torch.long, device=device)\n",
        "    tgt_pos = tgt_pos.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "    # 時刻ごとに処理\n",
        "    for t in range(1, max_length+1):\n",
        "        dec_output, dec_slf_attns, dec_enc_attns = model.decoder(\n",
        "            tgt_seq, tgt_pos, src_seq, enc_output)\n",
        "        dec_output = model.tgt_word_proj(dec_output)\n",
        "        out = dec_output[:, -1, :].max(dim=-1)[1].unsqueeze(1)\n",
        "        # 自身の出力を次の時刻の入力にする\n",
        "        tgt_seq = torch.cat([tgt_seq, out], dim=-1)\n",
        "        tgt_pos = torch.arange(t+1, dtype=torch.long, device=device)\n",
        "        tgt_pos = tgt_pos.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "    return tgt_seq[:, 1:], enc_slf_attns, dec_slf_attns, dec_enc_attns"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoghAQrUbp7a"
      },
      "source": [
        "def ids_to_sentence(vocab, ids):\n",
        "    # IDのリストを単語のリストに変換する\n",
        "    return [vocab.id2word[_id] for _id in ids]\n",
        "\n",
        "def trim_eos(ids):\n",
        "    # IDのリストからEOS以降の単語を除外する\n",
        "    if EOS in ids:\n",
        "        return ids[:ids.index(EOS)]\n",
        "    else:\n",
        "        return ids"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwY6_FpBbp5n",
        "outputId": "dd479839-226a-4e23-b453-1b2315987425"
      },
      "source": [
        "# 学習済みモデルの読み込み\n",
        "model = Transformer(**model_args).to(device)\n",
        "ckpt = torch.load(ckpt_path)\n",
        "model.load_state_dict(ckpt)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMbeaPQcbp4J"
      },
      "source": [
        "# テストデータの読み込み\n",
        "test_X = load_data('./data/dev.en')\n",
        "test_Y = load_data('./data/dev.ja')\n",
        "test_X = [sentence_to_ids(vocab_X, sentence) for sentence in test_X]\n",
        "test_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in test_Y]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwFT5I3Nb6J_"
      },
      "source": [
        "### 生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYycQd9Vbp1m"
      },
      "source": [
        "test_dataloader = DataLoader(\n",
        "    test_X, test_Y, 1,\n",
        "    shuffle=False\n",
        "    )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASbUp6p6bp0Q",
        "outputId": "e1dceae6-eb17-4529-ae09-51e707809cf0"
      },
      "source": [
        "src, tgt = next(test_dataloader)\n",
        "\n",
        "src_ids = src[0][0].cpu().numpy()\n",
        "tgt_ids = tgt[0][0].cpu().numpy()\n",
        "\n",
        "print('src: {}'.format(' '.join(ids_to_sentence(vocab_X, src_ids[1:-1]))))\n",
        "print('tgt: {}'.format(' '.join(ids_to_sentence(vocab_Y, tgt_ids[1:-1]))))\n",
        "\n",
        "preds, enc_slf_attns, dec_slf_attns, dec_enc_attns = test(model, src)\n",
        "pred_ids = preds[0].data.cpu().numpy().tolist()\n",
        "print('out: {}'.format(' '.join(ids_to_sentence(vocab_Y, trim_eos(pred_ids)))))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src: show your own business .\n",
            "tgt: 自分 の 事 を しろ 。\n",
            "out: 自分 の 仕事 の こと を <UNK> し て い た 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxQ1buJacIVs"
      },
      "source": [
        "## BLUE評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVWfR2DAbpvk",
        "outputId": "f4933ff9-6b9e-44da-b002-b8af3bd3bca4"
      },
      "source": [
        "# BLEUの評価\n",
        "test_dataloader = DataLoader(\n",
        "    test_X, test_Y, 128,\n",
        "    shuffle=False\n",
        "    )\n",
        "refs_list = []\n",
        "hyp_list = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch_X, batch_Y = batch\n",
        "    preds, *_ = test(model, batch_X)\n",
        "    preds = preds.data.cpu().numpy().tolist()\n",
        "    refs = batch_Y[0].data.cpu().numpy()[:, 1:].tolist()\n",
        "    refs_list += refs\n",
        "    hyp_list += preds\n",
        "bleu = calc_bleu(refs_list, hyp_list)\n",
        "print(bleu)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.68704832794868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcLnACnAbpqu"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}