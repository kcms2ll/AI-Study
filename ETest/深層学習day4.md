# 【ラビットチャレンジ】　深層学習day4

以下は、JDLA E資格の認定プログラム「ラビットチャレンジ」における深層学習day4のレポートである。  
深層学習モデルについてレポートにまとめた。
* 強化学習
    * Alpha Go
* 軽量化・高速化技術
* 応用技術
* 物体検知・セグメント
* Transformer

***

## 強化学習
長期的に報酬を最大化できるように環境の中で行動を選択できるエージェントを作ることを目標とする機械学習分野（他に教師あり、なし学習がある）の1つ  
→行動の結果として得られる利益（報酬）をもとに行動を決定する原理を改善していく仕組み

* 教師学習とほかの機械学習の差  
教師あり、なし学習はデータに含まれるパターンを見つけ出す、およびそのデータから予測することが目的であり、強化学習は、優れた方策を見つけ出すことが目的となっている

### 強化学習の構造
* 価値関数  
    * 状態関数：ある状態における価値に注目
    * 状態価値関数：ある状態と価値の組み合わせた価値に注目

* 方策関数  
ある状態でどのような行動をとるのかという確率を与える関数

以上の2つの構造を持つ。

### 強化学習の学習
* 方策反復法：方策をモデル化し最適化する手法  
方策勾配法→ <img src="https://latex.codecogs.com/png.latex?{\color{White}&space;\theta&space;^{t&plus;1}&space;=&space;\theta&space;^{t}&space;&plus;&space;\varepsilon&space;\nabla&space;J(\theta&space;)}" title="{\color{White} \theta ^{t+1} = \theta ^{t} + \varepsilon \nabla J(\theta )}" />  
※Jは方策の良さ（定義する必要がある）

    * 平均報酬
    * 割引報酬和  
    の2種類が存在する。方策関数をNNでつくったとするとNN同様に重みに対し学習が行える。

## Alpha go
Alpha　Goには"Lee"と"Zero"の2つがある。

### Alpha Go Lee
方策関数の働きをするPolicy Netと価値関数のはたらきをするValue Netで構成されている。どちらもCNNで作られている。  

* 学習方法
1. 教師あり学習による、Poricy NetとValue Netの学習
1. 強化学習によるPolicy Netの学習
1. 強化学習によるValue Netの学習  
1については、教師あり学習なので過去に対局した人間vs人間の情報を使う。教師が着手した手を1とし、残りを0とした19×19次元の配列を教師データとして、それを分類として学習した。この方法で作成されたPolicy Netは、精度57%ほどだった。  
2は、現状のPolicy NetとPolicy Poolからランダムに選択されたPlicy Netと来局シミュレーションを行い、その結果を用いて方策勾配法で学習する。Policy Net同士で学習させないのは、対局に幅をもたせ過学習を防ぐ目的がある。3も、2の学習がある程度進んだ段階で、同様に学習する。

### Alpha Go Zero
* Zeeとの違い
1. 教師学習を一切行わない
1. 特徴入力からヒューリスティックな要素（人間の主観で選んだもの）を排除し、石の配置のみを特徴とした
1. Plicy NetとValue Nerを1つのネットワーク統合した
1. 畳み込み層に、Residual Netを導入した
1. モンテカルロ木探索からRolloutシミュレーションをなくした  
Residual Net（処理を1ブロック分スキップするような構造）を導入したことにより、ネットワークの深さを抑える働きをもつようになった。その結果、勾配爆発や勾配消失問題を抑制する効果が得られた。

## 学習の高速化技術
### 分散深層学習
深層学習では、多くのデータを使用したり、パラメータ調整のため多くの時間を使用したりするため、高速な計算が求めれれる。そこで、スク数の計算資源（ワーカー）を使用し、並列的にニューラルネットワークを構成することで効率の良い学習を行う。

1. データ並列化  
親モデルを各ワーカーに子モデルとしてコピーする。そして、データを分割し各ワーカーごとに計算する。この計算結果の扱い方の違いで、2つの方法に別れる。
    * 同期型  
    各ワーカーが計算を終えるのを待ち、全ワーカーの勾配が出たところで勾配の平均を算出する。そして、その平均値から親モデルのパラメータを更新する。  
    * 非同期型  
    各ワーカーはお互いの計算を待たずに、各モデルごとにパタメータの更新を行う。学習が終わった段階で、パラメータサーバーへパラメータをpushし、新しく学習を始める際に、パラメータサーバーからpopし、学習を行っていく。
    
    非同期型の方が学習速度は早いが、最新モデルのパラメータを利用できないので、学習が不安定になりやすい。（現在は、精度のいい同期型が主流）

1. モデル並列化  
親モデルを各ワーカーに分割し、それぞれのモデルを学習させる。全てのデータで学習が終わったあとで、ひとつのモデルに復元する。モデルのパラメータ数が多いほどスピードアップ効率が向上する。

1. GPUによる高速化  
    * CUDA  
    GPGPU乗で並列コンピューティングを行うためのプラットフォームで、NVIDIA製のGPUのみで使用が可能。deep larning用に提供されているため使いやすい。

    * OpenCL  
    オープンな並列コンピューティングのプラットフォーム。NVIDIA製以外のGPUにも使用可能。deep learning用に特化しているわけではない。

### モデルの軽量化
モデルの精度を維持しつつ、パラメータや演算回数を低減する手法の総称。モデルやIoT機器において有効な手段で、性能があまり良くないデバイスでもDeep laerningが可能。

1. 量子化  
ネットワークが大きくなると大量のパラメータが必要となる、学習や推論に多くのメモリが必要なので、通常のパラメータである64bit浮動小数点を32bitなどの下位の精度に落とすことでメモリ演算処理の削減を行う。16bit半精度浮動小数点数、32bitを単精度浮動小数点数、64bitを倍精度浮動小数点という。実際に倍精度から単精度に落としたとしても、予測結果はほとんど変わらない。重みの精度を下げることにより、計算の高速化と省メモリ化を行う。

1. 蒸留  
予測精度の高い学習済みモデルの知識を軽量なモデルへ継承させる。教師モデルと生徒モデルの2つで構成されており、同じデータから教師モデルと生徒モデルの出力をだし、その出力の差から、生徒モデルの重みのみを更新して学習していく。効率陽区学習を行う技術。

1. プルーニング  
ネットワークが大きくなると大量のパラメータが全てのニューロンの計算が精度に寄与しているわけではない。このことから、モデルの精度に寄与していないニューロンを削減することで、モデルを高速化と省メモリ化する。

## 応用技術
### Mobile Net
画像技術は、2017年頃までにほとんど完成されている。（精度の大幅な向上は見られない）現在は、モデルを軽量化する研究等が進んでおり、Mobile Netでは、畳み込み層を工夫することで、軽量化・高速化を実現している。  
* Depthwise Convolution  
カーネルのフィルタ数を1にすることで、出力マップのチェンネル数が入力マップのチャンネル数と同じになる。
* PointWise Convolution  
カーネルのサイズを1×1にし、ポイントごとに畳み込みを実施する。

上記2つの方法を組み合わせることで、空間方向とチャンネル方向に同時に計算を行っていたものを別々に計算するようになり、計算量が抑えられる。

### Dense Net
画像認識のネットワークで、層が深くなるほど学習が難しくなるという問題を解消するようなネットワーク。
* Dense Block  
出力には、前のブロックで計算した出力を足し合わせる。入力特徴マップのチャンネル数がI×kだった場合、出力は、(I+1)×kとなる。  
※kはハイパーパラメータでgrowth rate(成長率)という
* Transitoin Layer  
Dense Bolockで増幅された層にTransition Layerをつなぐことで、ダウンサンプリングを行う。

### Normalization
正規化を行う方法の3種類。
* Batch Norm  
レイヤー間を流れるデータ分布をミニバッチ単位で、平均が0分散が1になるよう正規化。学習時間の短縮や初期値への依存低減、また過学習の抑制などの効果がある。  
    * 問題点  
    batch sizeが小さい条件下では、学習が収束しないことがある。代わりにLayer NOrmalizationなどの正規化手法が使われることが多い。

* Layer Norm  
それぞれのsampleの全てのpixelsが同一分布に従うように正規化。つまり、1つの画像のすべてのチャンネルを正規化する。

* Instance Norm
各sampleごとの各チャンネルごとに正規化する。つまり1つの画像で、それぞれのチャンネルごとに正規化を行う。コントラストの正規化に寄与、画像のすらいるやテクスチャ合成タスクなどで利用する。

### Wave Net
生の音声波形を生成する深層学習モデル。時系列データに対し、畳み込みを適用する。層が深くなるにつれて畳み込むリンクを離す。これにより、受容野を簡単に増やす（より過去のデータを持つ）ことができる。深層学習を用いて結合確率を学習する際に、効率的に学習が行えるアーキテクチャとなっている。

## 物体検知
物体検知のタスクには、
* 分類→（出力）クラスラベル
* 物体検知→（出力）Bounding box
* 意味領域分割→（出力）各ピクセルに対する、クラスラベル
* 固体領域分割→（出力）各ピクセルに対する、クラスラベル

の4つのタスクがあり、下のタスクほど難易度が上がっていく。
データセットがいくつか存在し、どんなアプリケーションを作るのが目的なのかによって利用するデータセットを変更する必要がある。

### 物体検知の閾値変更
物体検知において、閾値を変更するということは、Bounding Boxの数が増減するということになる。
また、Bounding Boxの評価も行うためにIOUという評価指標を利用する。真のBBと予測のBBの合計と重なった部分の割合で算出する。

* Average Precision  
閾値を0.05から0.05刻みで大きくして行った時に、precisionが変化していくので、その値の平均を算出した結果をaverage precisionという。定義は下記。  
<a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;{\color{White}&space;AP=&space;\int_{0}^{1}&space;P(R)dR}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;AP=&space;\int_{0}^{1}&space;P(R)dR}" title="{\color{White} AP= \int_{0}^{1} P(R)dR}" /></a>

### 物体検知のマイルストーン
物体検知には、現在大きく2種類に分かれている。それが、一段階検知と二段階検知である。二段階検知は一段階検知に比べ、精度が高いが処理速度が遅い。

* SSD  
single shot detecterの略で、one stage detecterの1つである。
ランダムに生成されたDefal Boxを用意し、そのBBを変形して確信度を算出する。出力は、それぞれのクラスラベルに対する確信度と、BBの4つの値となっている。ベースのネットワークは、VGG16である。  
処理途中の特徴マップから物体検出をそれぞれで行い、段階的に段階的に物体検知を行う。その過程で生じる、Defalt Boxを多く用意することによる弊害も、Non-Maximun Suppression（1つの物体に対し、いくつかのBBが重なっている場合確信度が一番高いものを残す）とHard Negative Mining（非背景と背景の比率が1:3になるように、BBの数を削減する）により、解消した。

## BERT
BERTの構成要素として、Encoder-DecoderModelとTransformerの2つがある。
### Seq2Seq
系列(Sequence)を入力として、系列を出力するもの。Encoder-Decoderモデルとも呼ばれる。入力系列がEncode(内部状態に変換)されて、内部状態からDecode(系列に変換)する。実用上も入力出力ともに系列情報なものは多い。  
Seq2Seqの構成要素としては、RNNと言語モデルとなっている。

* RNN  
系列を読み込むために再起的に動作するNN。

* 言語モデル  
単語の並びに確率を与えるもの。単語の並びに対し、尤度(それがどれだけ起こり得るか)、すなわち文章として自然かを確率で評価する。  
言語モデルでは、時刻tの事後確率を求めることが最終目標となる。

### Transformer  
EncoderDecoderモデルの翻訳の弱点である、翻訳の内容を一つのベクトルで表現するため、翻訳元の文章が長くなると表現力が足りなくなるというものを解消したものである。  
この機構をAttention(注意機構)という。翻訳先の各単語を選択する際に、翻訳元の文中の各単語の隠れ状態を利用する。つまり、Attentionが辞書オブジェクトのような働きをする。RNNを全く使わないということも特徴に挙げられる。

Attensionには2種類存在する。  
* Self Attention  
入力を同じにして、学習的に注意箇所を決定していく。

* Multi-HeadAttention
8個のScaled Dot-Productにより、Attensionの出力をconnectする。それぞれのヘッドが異なる種類の情報を収集する。


## 実装演習
* [Seq2Seqの実装](https://github.com/kcms2ll/AI-Study/blob/main/ETest/src/Seq2Seq.ipynb)  
* [Transformerの実装](https://github.com/kcms2ll/AI-Study/blob/main/ETest/src/Transformer.ipynb)