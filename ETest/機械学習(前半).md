# 【ラビットチャレンジ】　機械学習（前半）

以下は、JDLA E資格の認定プログラム「ラビットチャレンジ」における機械学習のレポートである。  
線形回帰モデルについてレポートにまとめた。
* 線形回帰モデル
* 非線形回帰モデル
* 学習について

***
## 機械学習モデリングプロセス
1. 問題設定  
どのような課題を機械学習で解決させるのか？必ずしも機械学習でなくてもよい。ルールベースのほうが向いていたりする場合もある。
1. データ選定  
どのようなデータを使うかを決定する。
1. データ前処理  
欠損値や外れ値などを処理する。
1. 機械学習モデルの選定  
どのモデルを利用するかを決定する。
1. モデルの学習（パラメータ推定）  
パラメータを決定する。
1. モデルの評価  
ハイパーパラメータの選定、モデルの制度を測る。

### そもそも機会学習とはなにか？
* コンピュータプログラムは、タスクT（アプリケーションにさせたいこと）を性能指標Pで測定し、その性能が経験E（データ）により改善される場合、タスクTおよび性能指標Pに関して、経験Eから学習すると言われている。

* 人がプログラムするのは認識の仕方ではなく、学習の仕方（数学で記述する）

## 線形回帰モデル
線形とは、ざっくり表現すると比例関係にあるということ。回帰問題を解くための機械学習モデルの１つ。教師あり学習で入力とm次元パラメータの線形結合を出力するモデル。  
※慣習として、予測値には、ハット（^）をつける。

* 回帰問題  
ある入力（離散あるいは連続値）から出力（連続値）を予想する問題。
直線で予測→線形回帰で、曲線で予測→非線形回帰となる。
    * 回帰で扱うデータ  
        * 入力（各要素を説明変数または特徴量と呼ぶ）、m次元のベクトル
        * 出力（目的変数と呼ぶ）、スカラー値

* 線形結合  
入力ベクトルと道のパラメータの各要素を掛け算し、足し合わせたもの。入力ベクトルとの線形結合に加え、切片も足し合わせる。出力は、１次元（スカラ）となる。

1. モデルパラメータ  
    モデルに含まれる推定すべき未知のパラメータ。 特徴量が予測値に対して、どのように影響を与えるか決定する重みの集合。  
正（負）の重みをつける場合、その特徴量の値を増加させると、予測値の値が増加（減少）する。重みが大きければ（0であれば）、その特徴量は予測に大きな影響力を持つ（全く影響しない）。切片は、y軸との交点との交点を表す。
<img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;\hat{y}&space;=&space;\mathbf{\omega}&space;^{T}&space;\mathbf{x}&space;&plus;&space;\omega&space;_{0}&space;=&space;\sum_{j=1}^{m}\omega&space;_{j}x_{j}&space;&plus;&space;\omega&space;_{0}}" title="{\color{White} \hat{y} = \mathbf{\omega} ^{T} \mathbf{x} + \omega _{0} = \sum_{j=1}^{m}\omega _{j}x_{j} + \omega _{0}}" />  
最小二乗法により、ωの値について推定する。
    * 説明変数が1次元の場合（m=1のとき）  
    単回帰モデルと言い、データは回帰直線に誤差が加わり観測されていると仮定する
    * 説明変数が多次元の場合（m>1のとき）  
    線形重回帰モデル。単回帰は直線であるが、重回帰は局面で表される。データは回帰局面に誤差が加わり観測されていると仮定する
    1. 線形回帰モデルのパタメータの推定方法  
         * 最小二乗法  
        学習データの平均二乗誤差を最小とするパラメータを探索。学習データの平均二乗誤差の最小化は、その勾配が0になる点を求めれば良い。  
        ※平均二乗誤差（残差平均）とは？  
        データとモデル出力の二乗誤差の和で、小さいほど直線とデータの距離が近い。パラメータのみに依存する関数で、データは既知の値でパラメータのみ未知である。  
        <img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;MSE_{train}&space;=&space;\frac{1}{n_{train}}\sum_{i=1}^{n_{train}}&space;\left&space;(&space;\hat{y_{_{i}}}^{(train)}-{y_{_{i}}}^{(train)}&space;\right&space;)}" title="{\color{White} MSE_{train} = \frac{1}{n_{train}}\sum_{i=1}^{n_{train}} \left ( \hat{y_{_{i}}}^{(train)}-{y_{_{i}}}^{(train)} \right )}" />より、  
        <img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;\hat{\mathbf{\omega}}&space;=&space;arg\;&space;\underset{\omega&space;\mathbb{\in&space;R^{&space;m&space;&plus;&space;1&space;}}}{min}\;&space;MES_{train}}" title="{\color{White} \hat{\mathbf{\omega}} = arg\; \underset{\omega \mathbb{\in R^{ m + 1 }}}{min}\; MES_{train}}" />  
        を最小にするようなω（m次元）を求めたいので、  
        <img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;\frac{\partial&space;}{\partial&space;\omega&space;}MSE_{train}&space;=&space;0}" title="{\color{White} \frac{\partial }{\partial \omega }MSE_{train} = 0}" />  
        MSEをωに関して微分したもをが0となるωの点を考える。（ωについて解く。）  
        <img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;\Leftrightarrow&space;\cdots&space;}" title="{\color{White} \Leftrightarrow \cdots }" />  （間の計算省略）  
        <img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}\Leftrightarrow&space;\hat{\omega&space;}&space;=&space;\left&space;(&space;X^{(train)T}X^{(train)}&space;\right&space;)^{-1}&space;X^{(train)T}y^{(train)}}" title="{\color{White}\Leftrightarrow \hat{\omega } = \left ( X^{(train)T}X^{(train)} \right )^{-1} X^{(train)T}y^{(train)}}" />  
        ωは回帰係数という。ここで、予測値は、次のように表せる。  
        <img src="https://latex.codecogs.com/png.latex?\inline&space;{\color{White}&space;\hat{y}&space;=&space;X\left(&space;X^{(train)T}X^{(train)}&space;\right&space;)^{-1}&space;X^{(train)T}y^{(train)}}" title="{\color{White} \hat{y} = X\left( X^{(train)T}X^{(train)} \right )^{-1} X^{(train)T}y^{(train)}}" />

1. データの分割
モデルを作成するにあたり、学習用データと検証用データに分割する。学習用データは、機械学習モデルの学習に利用し、検証用データは、学習済みモデルの制度を検証するためのデータ。
    * なぜデータを分割するのか？
    モデルの汎化性能を測定するため。学習データへの当てはまりのよさだけではなく、未知のデータに対してどれくらい精度が高いか測りたい。（後者のほうが重要）


1. [ハンズオンのpythonコード]()

## 非線形回帰モデル
回帰関数として、基底関数と呼ばれる既知の非線形関数をパラメータベクトルの線形結合を使用する。未知のパタメータは線形回帰モデルと同様に、最小二乗法や最尤法により推定する。

* よく使われる基底関数
    * 多項式関数
    * ガウス型基底関数
    * スプライン関数・Bスプライン関数

## 学習について
1. 未学習  
学習データに対し、十分小さな誤差が得られないモデル  
(対策1):モデルの表現力が低いため、表現力の高いモデルを利用する

1. 過学習  
小さな誤差は得られたが、テスト集合誤差との差が大きいモデル  
(対策1):学習データを減らす  
(対策2):不要な基底関数を削除して、表現力を抑制する  
ときたい問題に対し、基底関数を多く用意してしまうと、過学習の問題が起こるため、基底関数を用意する  
(対策3):正則化法を利用して表現力を抑止  
モデルの複雑さにともなって、その値が大きくなる正則化項（罰則項）を貸した関数を最小化する  
※正則化項は形状によっていくつも種類があり、それぞれの推定量の性質が異なる  
    * 正則化の方法
        * L2ノルム:Ridge推定を行う
        * L1ノルム:Lass推定を行う
* トレーニングにおける過学習の判断
    * 訓練誤差、テスト誤差がどちらも小さい  
    →汎化しているモデルの可能性
    * 訓練誤差は小さいが、テスト誤差が大きい  
    →過学習
    * 訓練誤差、テスト誤差どちらも小さくならない  
    →未学習

1. データの分割法
    * ホールドアウト法  
    有限のデータを学習用とテスト用の２つに分割し、予測精度や誤り率を推定するために使用。１度決めたら変更しない。
    * クロスバリデーション  
    学習用データとテストデータをk個に分割し、そのうち1つのkを学習データとして、残りのk-1個を訓練データに使用する。そのk個のデータが１回ずつテストデータに使われるように、k回学習を行い、精度の平均値を出す。

1. ハイパーパラメータの決定方法
    * グリッドサーチ  
    全てのチューニングパラメータの組み合わせで評価値を算出する